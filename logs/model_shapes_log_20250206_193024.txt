
==================================================
Starting main execution
==================================================

Calculating MACs and Parameters...
[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.
[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm2d'>.
[INFO] Register count_prelu() for <class 'torch.nn.modules.activation.PReLU'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pixelshuffle.PixelShuffle'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.padding.ZeroPad2d'>.

Model Input shape: torch.Size([1, 3, 256, 256]), range: [-4.568, 4.488]

ColorBalancePrior Input shape: torch.Size([1, 3, 256, 256]), range: [-4.568, 4.488]
--------------------------------------------------
ColorBalancePrior mean shape: torch.Size([1, 1, 256, 256]), range: [-2.787, 2.116]
--------------------------------------------------
ColorBalancePrior expanded mean shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]
--------------------------------------------------

NAFBlock Input shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]

LayerNorm2d forward Input shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]

LayerNormFunction forward Input shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-2.787, 2.116]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.000, 0.000]
LayerNormFunction forward normalized shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNormFunction forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNorm2d forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
After norm1 shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
After conv1 shape: torch.Size([1, 6, 256, 256]), range: [-0.213, 0.275]
After conv2 shape: torch.Size([1, 6, 256, 256]), range: [-0.169, 0.367]

SimpleGate Input shape: torch.Size([1, 6, 256, 256]), range: [-0.169, 0.367]
SimpleGate x1 shape: torch.Size([1, 3, 256, 256]), range: [-0.157, 0.367]
SimpleGate x2 shape: torch.Size([1, 3, 256, 256]), range: [-0.169, 0.180]
After sg shape: torch.Size([1, 3, 256, 256]), range: [-0.060, 0.048]
After sca shape: torch.Size([1, 3, 256, 256]), range: [-0.018, 0.023]
After conv3 shape: torch.Size([1, 3, 256, 256]), range: [-0.197, 0.454]
After dropout1 shape: torch.Size([1, 3, 256, 256]), range: [-0.197, 0.454]
After beta shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]

LayerNorm2d forward Input shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]

LayerNormFunction forward Input shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-2.787, 2.116]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.000, 0.000]
LayerNormFunction forward normalized shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNormFunction forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNorm2d forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
After conv4 shape: torch.Size([1, 6, 256, 256]), range: [-0.517, 0.562]

SimpleGate Input shape: torch.Size([1, 6, 256, 256]), range: [-0.517, 0.562]
SimpleGate x1 shape: torch.Size([1, 3, 256, 256]), range: [-0.327, 0.554]
SimpleGate x2 shape: torch.Size([1, 3, 256, 256]), range: [-0.517, 0.562]
After sg shape: torch.Size([1, 3, 256, 256]), range: [0.006, 0.311]
After conv5 shape: torch.Size([1, 3, 256, 256]), range: [-0.324, 0.425]
After dropout2 shape: torch.Size([1, 3, 256, 256]), range: [-0.324, 0.425]
NAFBlock output shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]
ColorBalancePrior output shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]
--------------------------------------------------
Prior output shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]

PriorGuidedRE Input shape: torch.Size([1, 3, 256, 256]), range: [-4.568, 4.488]
PriorGuidedRE Prior input shape: torch.Size([1, 3, 256, 256]), range: [-2.787, 2.116]

DetailRestorer Input shape: torch.Size([1, 3, 256, 256]), range: [-4.568, 4.488]

OverlapPatchEmbed Input shape: torch.Size([1, 3, 256, 256]), range: [-4.568, 4.488]

OverlapPatchEmbed output shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]
After embed shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]
After body shape: torch.Size([1, 16, 256, 256]), range: [-0.733, 0.742]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.733, 0.742]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.733, 0.742]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.733, 0.742]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-0.733, 0.742]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-0.733, 0.742]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-0.733, 0.742]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.319, 0.305]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.319, 0.305]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.070, 0.123]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.070, 0.123]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.070, 0.123]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.033, 0.025]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.726, 0.745]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.145, 0.745]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-2.823, 3.037]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.642, 0.765]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.025, 1.834]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-3.444, 3.536]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.444, 3.536]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.444, 3.536]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-3.444, 3.536]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.540, 2.495]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-2.014, 1.796]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.014, 1.796]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.800, 1.796]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.014, 1.783]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.940, 1.644]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.430, 0.337]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.285, 0.311]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.285, 0.311]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.642, 0.765]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.025, 1.834]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-3.444, 3.536]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.444, 3.536]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.444, 3.536]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.358, 2.634]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.358, 2.634]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.312, 2.634]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.358, 2.233]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.765, 2.796]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.368, 1.076]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.368, 1.076]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-2.986, 2.813]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 31.411]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]
After block1_1 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]
After body shape: torch.Size([1, 16, 256, 256]), range: [-1.431, 1.448]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.431, 1.448]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.431, 1.448]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.431, 1.448]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-1.431, 1.448]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-1.431, 1.448]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-1.431, 1.448]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.618, 0.664]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.618, 0.664]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.284, 0.319]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.284, 0.319]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.284, 0.319]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.083, 0.079]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.412, 1.424]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.282, 1.424]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-0.507, 12.783]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.162, 2.692]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.014, 13.219]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.856, 3.857]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.856, 3.857]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.856, 3.857]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-1.856, 3.857]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.287, 2.511]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-1.865, 1.806]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.865, 1.806]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.609, 1.806]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.865, 1.767]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.146, 1.928]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.473, 0.281]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.245, 0.348]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.245, 0.348]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.162, 2.692]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.014, 13.219]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.856, 3.857]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.856, 3.857]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.856, 3.857]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.455, 2.282]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.455, 2.282]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.455, 2.201]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.196, 2.282]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-3.107, 2.883]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.030, 1.089]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.030, 1.089]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 12.048]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 150.972]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 64.201]
After block1_2 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 64.201]

Aggreation Input shape: torch.Size([1, 32, 256, 256]), range: [-0.278, 64.201]

SelfAttention Input shape: torch.Size([1, 32, 256, 256]), range: [-0.278, 64.201]

SelfAttention Input shape: torch.Size([1, 32, 256, 256]), range: [-0.278, 64.201]

SelfAttention N: 1, C: 32, H: 256, W: 256

SelfAttention out shape: torch.Size([1, 32]), range: [-0.116, 19.200]

SelfAttention out shape: torch.Size([1, 4]), range: [0.000, 2.998]

SelfAttention out shape: torch.Size([1, 32, 1, 1]), range: [0.209, 0.892]

SelfAttention output shape: torch.Size([1, 32, 256, 256]), range: [-0.248, 44.103]

ConvLayer Input shape: torch.Size([1, 32, 256, 256]), range: [-0.248, 44.103]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-10.168, 9.083]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-5.726, 5.992]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]

Aggreation output shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]
After first blocks - x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]
After body shape: torch.Size([1, 16, 256, 256]), range: [-1.156, 1.118]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.156, 1.118]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.156, 1.118]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.156, 1.118]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-1.156, 1.118]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-1.156, 1.118]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-1.156, 1.118]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.454, 0.404]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.454, 0.404]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.253, 0.176]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.253, 0.176]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.253, 0.176]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.034, 0.045]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.153, 1.110]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.231, 1.110]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-1.405, 6.132]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.257, 1.155]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.017, 4.232]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.642, 3.822]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.642, 3.822]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.642, 3.822]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-2.642, 3.822]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.381, 2.274]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-1.832, 2.486]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.832, 2.486]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.832, 1.918]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.810, 2.486]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-3.045, 1.584]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.262, 0.391]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.271, 0.267]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.271, 0.267]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.257, 1.155]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.017, 4.232]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.642, 3.822]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.642, 3.822]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.642, 3.822]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.575, 2.514]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.575, 2.514]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.156, 2.229]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.575, 2.514]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.594, 2.768]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.127, 1.117]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.127, 1.117]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.432, 5.992]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 77.045]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]
After block2_1 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]
After body shape: torch.Size([1, 16, 256, 256]), range: [-4.969, 4.664]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-4.969, 4.664]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-4.969, 4.664]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-4.969, 4.664]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-4.969, 4.664]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-4.969, 4.664]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-4.969, 4.664]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.829, 1.647]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.829, 1.647]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-1.334, 1.819]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-1.334, 1.819]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-1.334, 1.819]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.530, 0.241]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-5.195, 4.659]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-1.039, 4.659]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-1.039, 26.737]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.043, 4.506]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.037, 59.185]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.634, 3.869]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.634, 3.869]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.634, 3.869]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-1.634, 3.869]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.105, 2.073]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-2.674, 1.096]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.674, 1.096]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.674, 1.034]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.338, 1.096]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.179, 1.506]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.092, 0.080]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.235, 0.270]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.235, 0.270]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.043, 4.506]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.037, 59.185]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.634, 3.869]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.634, 3.869]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.634, 3.869]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-1.870, 2.183]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.870, 2.183]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.870, 1.902]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.618, 2.183]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.894, 2.372]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.086, 0.812]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.086, 0.812]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 27.238]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 369.313]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 185.058]
After block2_2 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 185.058]

Aggreation Input shape: torch.Size([1, 48, 256, 256]), range: [-1.432, 185.058]

SelfAttention Input shape: torch.Size([1, 48, 256, 256]), range: [-1.432, 185.058]

SelfAttention Input shape: torch.Size([1, 48, 256, 256]), range: [-1.432, 185.058]

SelfAttention N: 1, C: 48, H: 256, W: 256

SelfAttention out shape: torch.Size([1, 48]), range: [-0.067, 74.835]

SelfAttention out shape: torch.Size([1, 6]), range: [0.000, 14.041]

SelfAttention out shape: torch.Size([1, 48, 1, 1]), range: [0.001, 0.998]

SelfAttention output shape: torch.Size([1, 48, 256, 256]), range: [-1.352, 169.254]

ConvLayer Input shape: torch.Size([1, 48, 256, 256]), range: [-1.352, 169.254]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-34.413, 33.638]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-7.295, 6.166]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]

Aggreation output shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]
After second blocks - x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]
After body shape: torch.Size([1, 16, 256, 256]), range: [-0.896, 0.959]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.896, 0.959]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.896, 0.959]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.896, 0.959]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-0.896, 0.959]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-0.896, 0.959]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-0.896, 0.959]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.266, 0.308]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.266, 0.308]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.195, 0.142]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.195, 0.142]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.195, 0.142]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.030, 0.041]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.855, 0.952]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.171, 0.952]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-1.751, 6.121]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.111, 1.430]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.007, 6.416]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.819, 3.770]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.819, 3.770]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.819, 3.770]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-2.819, 3.770]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.171, 2.326]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-2.029, 1.831]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.029, 1.831]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.666, 1.831]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.029, 1.724]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.136, 1.677]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.257, 0.200]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.288, 0.272]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.288, 0.272]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.111, 1.430]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.007, 6.416]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.819, 3.770]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.819, 3.770]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.819, 3.770]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.276, 2.222]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.276, 2.222]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.120, 2.144]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.276, 2.222]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.881, 2.571]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.080, 1.032]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.080, 1.032]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 6.166]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 88.538]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]
After block3_1 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]
After body shape: torch.Size([1, 16, 256, 256]), range: [-4.970, 5.525]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-4.970, 5.525]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-4.970, 5.525]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-4.970, 5.525]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-4.970, 5.525]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-4.970, 5.525]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-4.970, 5.525]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-2.311, 0.436]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-2.311, 0.436]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-1.218, 1.223]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-1.218, 1.223]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-1.218, 1.223]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.431, 0.547]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-5.108, 5.615]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-1.022, 5.615]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-1.268, 33.383]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [0.007, 9.448]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.068, 118.819]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.382, 3.813]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.382, 3.813]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.382, 3.813]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-1.382, 3.813]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.101, 2.268]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-1.766, 2.742]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.766, 2.742]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.180, 2.742]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.766, 1.762]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.319, 1.582]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.220, 0.317]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.330, 0.278]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.330, 0.278]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [0.007, 9.448]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.068, 118.819]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.382, 3.813]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.382, 3.813]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.382, 3.813]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.097, 2.021]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.097, 2.021]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.097, 2.021]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.919, 1.865]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.948, 2.599]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.132, 1.214]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.132, 1.214]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 33.522]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 585.063]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 193.009]
After block3_2 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 193.009]

Aggreation Input shape: torch.Size([1, 64, 256, 256]), range: [-1.824, 193.009]

SelfAttention Input shape: torch.Size([1, 64, 256, 256]), range: [-1.824, 193.009]

SelfAttention Input shape: torch.Size([1, 64, 256, 256]), range: [-1.824, 193.009]

SelfAttention N: 1, C: 64, H: 256, W: 256

SelfAttention out shape: torch.Size([1, 64]), range: [-0.042, 57.823]

SelfAttention out shape: torch.Size([1, 8]), range: [0.000, 6.127]

SelfAttention out shape: torch.Size([1, 64, 1, 1]), range: [0.021, 0.968]

SelfAttention output shape: torch.Size([1, 64, 256, 256]), range: [-1.528, 88.471]

ConvLayer Input shape: torch.Size([1, 64, 256, 256]), range: [-1.528, 88.471]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-25.380, 18.001]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-6.481, 6.740]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-1.620, 6.740]

Aggreation output shape: torch.Size([1, 16, 256, 256]), range: [-1.620, 6.740]
After third blocks - x3 shape: torch.Size([1, 16, 256, 256]), range: [-1.620, 6.740]

SPP Input shape: torch.Size([1, 16, 256, 256]), range: [-1.620, 6.740]

ConvLayer Input shape: torch.Size([1, 16, 64, 64]), range: [-1.092, 4.085]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-2.027, 1.927]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-0.507, 1.927]
SPP level 0 output shape: torch.Size([1, 16, 256, 256]), range: [-0.438, 1.752]

ConvLayer Input shape: torch.Size([1, 16, 32, 32]), range: [-0.652, 2.634]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-2.380, 1.364]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-0.595, 1.364]
SPP level 1 output shape: torch.Size([1, 16, 256, 256]), range: [-0.590, 1.344]

ConvLayer Input shape: torch.Size([1, 16, 16, 16]), range: [-0.205, 1.455]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-1.118, 0.934]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-0.279, 0.934]
SPP level 2 output shape: torch.Size([1, 16, 256, 256]), range: [-0.275, 0.927]

ConvLayer Input shape: torch.Size([1, 16, 8, 8]), range: [0.062, 0.759]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.601, 0.750]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.150, 0.750]
SPP level 3 output shape: torch.Size([1, 16, 256, 256]), range: [-0.149, 0.747]

SPP output length: 4, range: [-0.590, 1.752]
SPP level 0 output shape: torch.Size([1, 16, 256, 256]), range: [-0.438, 1.752]
SPP level 1 output shape: torch.Size([1, 16, 256, 256]), range: [-0.590, 1.344]
SPP level 2 output shape: torch.Size([1, 16, 256, 256]), range: [-0.275, 0.927]
SPP level 3 output shape: torch.Size([1, 16, 256, 256]), range: [-0.149, 0.747]
SPP level 4 output shape: torch.Size([1, 16, 256, 256]), range: [-1.620, 6.740]

ConvLayer Input shape: torch.Size([1, 80, 256, 256]), range: [-1.620, 6.740]

ConvLayer out shape: torch.Size([1, 3, 256, 256]), range: [-1.586, 2.019]

ConvLayer out shape: torch.Size([1, 3, 256, 256]), range: [-0.396, 2.019]

SPP output shape: torch.Size([1, 3, 256, 256]), range: [-0.396, 2.019]
DetailRestorer output shape: torch.Size([1, 3, 256, 256]), range: [-0.396, 2.019]
First DetailRestorer output shape: torch.Size([1, 3, 256, 256]), range: [-0.396, 2.019]
Down 1 output shape: torch.Size([1, 6, 128, 128]), range: [-1.366, 0.802]

DetailRestorer Input shape: torch.Size([1, 6, 128, 128]), range: [-1.366, 0.802]

OverlapPatchEmbed Input shape: torch.Size([1, 6, 128, 128]), range: [-1.366, 0.802]

OverlapPatchEmbed output shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]
After embed shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]
After body shape: torch.Size([1, 16, 128, 128]), range: [-0.153, 0.203]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.153, 0.203]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.153, 0.203]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.153, 0.203]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-0.153, 0.203]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-0.153, 0.203]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-0.153, 0.203]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.005, 0.077]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.005, 0.077]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.069, 0.112]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.069, 0.112]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.069, 0.112]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.015, 0.026]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.141, 0.198]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.028, 0.198]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-0.885, 0.672]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.057, 0.072]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.003, 0.151]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-3.062, 2.355]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.062, 2.355]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.062, 2.355]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-3.062, 2.355]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-1.961, 2.019]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-2.079, 2.193]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.079, 2.193]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.093, 2.193]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.079, 1.581]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-0.993, 0.620]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.232, 0.145]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.272, 0.245]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.272, 0.245]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.057, 0.072]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.003, 0.151]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-3.062, 2.355]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.062, 2.355]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.062, 2.355]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.208, 1.663]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.208, 1.663]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.208, 1.663]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.527, 1.414]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.322, 2.021]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-0.694, 0.635]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-0.694, 0.635]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.860, 0.643]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 8.014]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]
After block1_1 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]
After body shape: torch.Size([1, 16, 128, 128]), range: [-0.369, 0.595]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.369, 0.595]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.369, 0.595]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.369, 0.595]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-0.369, 0.595]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-0.369, 0.595]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-0.369, 0.595]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.129, 0.057]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.129, 0.057]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.059, 0.071]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.059, 0.071]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.059, 0.071]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.009, 0.007]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.369, 0.601]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.074, 0.601]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-0.332, 3.335]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.045, 0.554]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.002, 1.410]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.480, 3.408]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.480, 3.408]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.480, 3.408]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-2.480, 3.408]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.182, 2.129]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.478, 1.528]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.478, 1.528]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.250, 1.528]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.478, 0.923]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-0.913, 0.571]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.138, 0.122]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.211, 0.247]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.211, 0.247]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.045, 0.554]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.002, 1.410]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.480, 3.408]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.480, 3.408]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.480, 3.408]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-1.860, 2.286]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.860, 2.286]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.675, 2.051]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.860, 2.286]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-2.260, 2.379]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-0.926, 0.822]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-0.926, 0.822]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 3.409]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 41.668]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 21.608]
After block1_2 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 21.608]

Aggreation Input shape: torch.Size([1, 32, 128, 128]), range: [-0.278, 21.608]

SelfAttention Input shape: torch.Size([1, 32, 128, 128]), range: [-0.278, 21.608]

SelfAttention Input shape: torch.Size([1, 32, 128, 128]), range: [-0.278, 21.608]

SelfAttention N: 1, C: 32, H: 128, W: 128

SelfAttention out shape: torch.Size([1, 32]), range: [-0.211, 0.698]

SelfAttention out shape: torch.Size([1, 4]), range: [0.022, 0.214]

SelfAttention out shape: torch.Size([1, 32, 1, 1]), range: [0.374, 0.630]

SelfAttention output shape: torch.Size([1, 32, 128, 128]), range: [-0.175, 11.668]

ConvLayer Input shape: torch.Size([1, 32, 128, 128]), range: [-0.175, 11.668]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-3.594, 4.021]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-17.489, 16.354]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]

Aggreation output shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]
After first blocks - x1 shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]
After body shape: torch.Size([1, 16, 128, 128]), range: [-3.098, 2.774]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-3.098, 2.774]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-3.098, 2.774]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-3.098, 2.774]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-3.098, 2.774]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-3.098, 2.774]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-3.098, 2.774]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.290, 1.731]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.290, 1.731]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.257, 0.160]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.257, 0.160]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.257, 0.160]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.034, 0.051]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-3.128, 2.763]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.626, 2.763]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-3.154, 16.109]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.055, 4.542]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.006, 32.189]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.581, 3.815]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.581, 3.815]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.581, 3.815]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-2.581, 3.815]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.084, 2.383]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-2.311, 1.729]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.311, 1.729]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.311, 1.355]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.431, 1.729]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.095, 1.978]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.197, 0.195]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.295, 0.221]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.295, 0.221]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.055, 4.542]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.006, 32.189]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.581, 3.815]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.581, 3.815]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.581, 3.815]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.104, 1.763]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.104, 1.763]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.902, 1.763]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.104, 1.689]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-2.437, 1.738]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.007, 1.051]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.007, 1.051]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-4.372, 16.354]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 300.970]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]
After block2_1 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]
After body shape: torch.Size([1, 16, 128, 128]), range: [-8.466, 12.701]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-8.466, 12.701]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-8.466, 12.701]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-8.466, 12.701]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-8.466, 12.701]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-8.466, 12.701]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-8.466, 12.701]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-3.516, 0.856]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-3.516, 0.856]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.320, 0.405]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.320, 0.405]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.320, 0.405]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.071, 0.055]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-8.456, 12.689]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-1.691, 12.689]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-1.691, 140.012]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [0.049, 28.116]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.146, 1389.946]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-1.345, 3.680]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.345, 3.680]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.345, 3.680]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-1.345, 3.680]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-1.630, 1.785]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.250, 1.201]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.250, 1.201]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.250, 1.201]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.165, 1.148]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-0.873, 0.712]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.158, 0.095]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.233, 0.251]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.233, 0.251]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [0.049, 28.116]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.146, 1389.946]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-1.345, 3.680]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.345, 3.680]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.345, 3.680]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-1.950, 2.186]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.950, 2.186]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.357, 1.553]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.950, 2.186]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.483, 1.678]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-0.844, 0.820]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-0.844, 0.820]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 138.134]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 2107.205]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 1139.682]
After block2_2 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 1139.682]

Aggreation Input shape: torch.Size([1, 48, 128, 128]), range: [-4.372, 1139.682]

SelfAttention Input shape: torch.Size([1, 48, 128, 128]), range: [-4.372, 1139.682]

SelfAttention Input shape: torch.Size([1, 48, 128, 128]), range: [-4.372, 1139.682]

SelfAttention N: 1, C: 48, H: 128, W: 128

SelfAttention out shape: torch.Size([1, 48]), range: [-0.108, 58.174]

SelfAttention out shape: torch.Size([1, 6]), range: [0.000, 9.701]

SelfAttention out shape: torch.Size([1, 48, 1, 1]), range: [0.018, 0.988]

SelfAttention output shape: torch.Size([1, 48, 128, 128]), range: [-2.871, 746.113]

ConvLayer Input shape: torch.Size([1, 48, 128, 128]), range: [-2.871, 746.113]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-185.296, 157.162]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-16.628, 13.488]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]

Aggreation output shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]
After second blocks - x2 shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]
After body shape: torch.Size([1, 16, 128, 128]), range: [-4.776, 2.644]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-4.776, 2.644]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-4.776, 2.644]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-4.776, 2.644]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-4.776, 2.644]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-4.776, 2.644]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-4.776, 2.644]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.284, 1.140]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.284, 1.140]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.102, 0.057]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.102, 0.057]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.102, 0.057]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.018, 0.018]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-4.774, 2.656]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.955, 2.656]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-3.842, 14.322]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.490, 2.942]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.003, 38.587]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.490, 3.718]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.490, 3.718]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.490, 3.718]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-2.490, 3.718]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.058, 1.894]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.622, 1.411]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.622, 1.411]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.487, 1.411]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.622, 1.373]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.690, 1.379]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.331, 0.174]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.259, 0.195]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.259, 0.195]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.490, 2.942]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.003, 38.587]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.490, 3.718]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.490, 3.718]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.490, 3.718]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.202, 2.213]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.202, 2.213]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.688, 1.543]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.202, 2.213]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-2.112, 1.849]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-0.828, 0.788]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-0.828, 0.788]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-4.157, 13.488]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 214.501]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]
After block3_1 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]
After body shape: torch.Size([1, 16, 128, 128]), range: [-8.378, 8.035]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-8.378, 8.035]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-8.378, 8.035]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-8.378, 8.035]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-8.378, 8.035]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-8.378, 8.035]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-8.378, 8.035]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.919, 2.838]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.919, 2.838]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.001]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.001]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.757, 0.587]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.757, 0.587]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.757, 0.587]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.245, 0.157]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-8.369, 7.903]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-1.674, 7.903]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-1.283, 58.397]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.028, 12.274]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.020, 497.170]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-1.902, 3.536]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.902, 3.536]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.902, 3.536]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-1.902, 3.536]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-1.916, 2.203]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-2.290, 2.294]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.290, 2.294]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.290, 2.294]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.153, 1.457]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-0.828, 1.550]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.603, 0.348]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.253, 0.260]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.253, 0.260]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.028, 12.274]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.020, 497.170]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-1.902, 3.536]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.902, 3.536]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.902, 3.536]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.023, 1.690]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.023, 1.690]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.681, 1.628]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 1.690]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.538, 1.961]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-0.752, 0.925]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-0.752, 0.925]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 60.043]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 1039.103]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 597.284]
After block3_2 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 597.284]

Aggreation Input shape: torch.Size([1, 64, 128, 128]), range: [-4.372, 597.284]

SelfAttention Input shape: torch.Size([1, 64, 128, 128]), range: [-4.372, 597.284]

SelfAttention Input shape: torch.Size([1, 64, 128, 128]), range: [-4.372, 597.284]

SelfAttention N: 1, C: 64, H: 128, W: 128

SelfAttention out shape: torch.Size([1, 64]), range: [-0.188, 53.215]

SelfAttention out shape: torch.Size([1, 8]), range: [0.000, 10.882]

SelfAttention out shape: torch.Size([1, 64, 1, 1]), range: [0.000, 1.000]

SelfAttention output shape: torch.Size([1, 64, 128, 128]), range: [-3.620, 227.679]

ConvLayer Input shape: torch.Size([1, 64, 128, 128]), range: [-3.620, 227.679]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-39.519, 48.096]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-15.578, 13.830]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-3.895, 13.830]

Aggreation output shape: torch.Size([1, 16, 128, 128]), range: [-3.895, 13.830]
After third blocks - x3 shape: torch.Size([1, 16, 128, 128]), range: [-3.895, 13.830]

SPP Input shape: torch.Size([1, 16, 128, 128]), range: [-3.895, 13.830]

ConvLayer Input shape: torch.Size([1, 16, 32, 32]), range: [-2.495, 10.467]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-7.473, 3.437]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-1.868, 3.437]
SPP level 0 output shape: torch.Size([1, 16, 128, 128]), range: [-1.847, 3.270]

ConvLayer Input shape: torch.Size([1, 16, 16, 16]), range: [-2.022, 8.103]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-4.583, 2.820]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-1.146, 2.820]
SPP level 1 output shape: torch.Size([1, 16, 128, 128]), range: [-1.106, 2.738]

ConvLayer Input shape: torch.Size([1, 16, 8, 8]), range: [-0.689, 2.930]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-1.886, 1.466]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.471, 1.466]
SPP level 2 output shape: torch.Size([1, 16, 128, 128]), range: [-0.457, 1.431]

ConvLayer Input shape: torch.Size([1, 16, 4, 4]), range: [-0.111, 0.728]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.570, 0.522]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.143, 0.522]
SPP level 3 output shape: torch.Size([1, 16, 128, 128]), range: [-0.143, 0.522]

SPP output length: 4, range: [-1.847, 3.270]
SPP level 0 output shape: torch.Size([1, 16, 128, 128]), range: [-1.847, 3.270]
SPP level 1 output shape: torch.Size([1, 16, 128, 128]), range: [-1.106, 2.738]
SPP level 2 output shape: torch.Size([1, 16, 128, 128]), range: [-0.457, 1.431]
SPP level 3 output shape: torch.Size([1, 16, 128, 128]), range: [-0.143, 0.522]
SPP level 4 output shape: torch.Size([1, 16, 128, 128]), range: [-3.895, 13.830]

ConvLayer Input shape: torch.Size([1, 80, 128, 128]), range: [-3.895, 13.830]

ConvLayer out shape: torch.Size([1, 6, 128, 128]), range: [-3.115, 2.345]

ConvLayer out shape: torch.Size([1, 6, 128, 128]), range: [-0.779, 2.345]

SPP output shape: torch.Size([1, 6, 128, 128]), range: [-0.779, 2.345]
DetailRestorer output shape: torch.Size([1, 6, 128, 128]), range: [-0.779, 2.345]
DetailRestorer 1 output shape: torch.Size([1, 6, 128, 128]), range: [-0.779, 2.345]
Prior down 1 shape: torch.Size([1, 6, 128, 128]), range: [-2.338, 2.561]
Down 2 output shape: torch.Size([1, 12, 64, 64]), range: [-0.748, 0.700]

DetailRestorer Input shape: torch.Size([1, 12, 64, 64]), range: [-0.748, 0.700]

OverlapPatchEmbed Input shape: torch.Size([1, 12, 64, 64]), range: [-0.748, 0.700]

OverlapPatchEmbed output shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]
After embed shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]
After body shape: torch.Size([1, 16, 64, 64]), range: [-0.091, 0.049]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.091, 0.049]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.091, 0.049]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.091, 0.049]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-0.091, 0.049]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-0.091, 0.049]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-0.091, 0.049]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.012, 0.019]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.012, 0.019]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.032, 0.018]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.032, 0.018]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.032, 0.018]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.009, 0.008]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.094, 0.050]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.019, 0.050]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-0.360, 0.333]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.056, 0.006]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.001, 0.037]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-3.150, 2.894]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.150, 2.894]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.150, 2.894]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-3.150, 2.894]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.273, 1.807]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.416, 1.328]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.416, 1.328]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.296, 1.328]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.416, 0.905]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-0.659, 0.680]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.105, 0.114]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.229, 0.228]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.229, 0.228]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.056, 0.006]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.001, 0.037]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-3.150, 2.894]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.150, 2.894]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.150, 2.894]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-1.895, 2.081]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.895, 2.081]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.662, 2.081]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.895, 1.600]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.632, 1.524]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-0.673, 0.648]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-0.673, 0.648]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.375, 0.333]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 2.989]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]
After block1_1 shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]
After body shape: torch.Size([1, 16, 64, 64]), range: [-0.053, 0.061]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.053, 0.061]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.053, 0.061]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.053, 0.061]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-0.053, 0.061]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-0.053, 0.061]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-0.053, 0.061]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.014, 0.012]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.014, 0.012]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.020, 0.020]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.020, 0.020]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.020, 0.020]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.003, 0.003]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.050, 0.060]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.010, 0.060]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-0.180, 0.512]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [0.005, 0.070]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.002, 0.029]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.899, 3.055]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.899, 3.055]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.899, 3.055]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-2.899, 3.055]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-1.710, 2.016]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.668, 1.155]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.668, 1.155]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-0.780, 0.997]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.668, 1.155]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-0.672, 0.439]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.116, 0.093]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.183, 0.269]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.183, 0.269]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [0.005, 0.070]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.002, 0.029]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.899, 3.055]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.899, 3.055]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.899, 3.055]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.071, 1.700]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.071, 1.700]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-2.071, 1.700]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.916, 1.602]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.025, 1.494]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-0.691, 0.668]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-0.691, 0.668]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.179, 0.508]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 5.807]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 3.184]
After block1_2 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 3.184]

Aggreation Input shape: torch.Size([1, 32, 64, 64]), range: [-0.278, 3.184]

SelfAttention Input shape: torch.Size([1, 32, 64, 64]), range: [-0.278, 3.184]

SelfAttention Input shape: torch.Size([1, 32, 64, 64]), range: [-0.278, 3.184]

SelfAttention N: 1, C: 32, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 32]), range: [-0.270, 1.415]

SelfAttention out shape: torch.Size([1, 4]), range: [0.000, 0.105]

SelfAttention out shape: torch.Size([1, 32, 1, 1]), range: [0.371, 0.610]

SelfAttention output shape: torch.Size([1, 32, 64, 64]), range: [-0.170, 1.472]

ConvLayer Input shape: torch.Size([1, 32, 64, 64]), range: [-0.170, 1.472]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-0.382, 0.439]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-9.086, 7.160]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]

Aggreation output shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]
After first blocks - x1 shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]
After body shape: torch.Size([1, 16, 64, 64]), range: [-1.382, 1.063]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.382, 1.063]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.382, 1.063]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.382, 1.063]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-1.382, 1.063]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-1.382, 1.063]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-1.382, 1.063]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.081, 0.472]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.081, 0.472]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.213, 0.136]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.213, 0.136]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.213, 0.136]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.048, 0.025]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-1.369, 1.030]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.274, 1.030]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-2.272, 7.187]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.080, 1.397]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.008, 7.329]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-3.151, 3.699]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.151, 3.699]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.151, 3.699]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-3.151, 3.699]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.084, 2.296]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.723, 1.285]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.723, 1.285]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.718, 1.285]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.723, 1.279]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-0.884, 1.500]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.115, 0.177]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.248, 0.237]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.248, 0.237]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.080, 1.397]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.008, 7.329]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-3.151, 3.699]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.151, 3.699]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.151, 3.699]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.176, 2.114]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.176, 2.114]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-2.176, 2.011]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.823, 2.114]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.240, 3.037]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-1.273, 0.760]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-1.273, 0.760]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-2.271, 7.160]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 95.750]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]
After block2_1 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]
After body shape: torch.Size([1, 16, 64, 64]), range: [-6.936, 4.926]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-6.936, 4.926]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-6.936, 4.926]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-6.936, 4.926]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-6.936, 4.926]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-6.936, 4.926]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-6.936, 4.926]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [0.085, 3.713]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [0.085, 3.713]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.003]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.003]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-2.129, 1.723]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-2.129, 1.723]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-2.129, 1.723]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.827, 0.384]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-7.708, 4.844]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-1.542, 4.844]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-1.544, 62.550]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [0.158, 15.715]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.303, 411.109]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.074, 3.218]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.074, 3.218]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.074, 3.218]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-1.074, 3.218]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-1.843, 1.921]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.082, 1.770]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.082, 1.770]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.082, 1.770]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-0.859, 1.490]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-0.813, 0.981]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.107, 0.096]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.197, 0.255]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.197, 0.255]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [0.158, 15.715]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.303, 411.109]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.074, 3.218]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.074, 3.218]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.074, 3.218]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.042, 1.558]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.042, 1.558]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-2.042, 1.394]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.655, 1.558]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.460, 1.472]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-0.793, 0.686]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-0.793, 0.686]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 63.519]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 925.675]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 556.276]
After block2_2 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 556.276]

Aggreation Input shape: torch.Size([1, 48, 64, 64]), range: [-2.271, 556.276]

SelfAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.271, 556.276]

SelfAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.271, 556.276]

SelfAttention N: 1, C: 48, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 48]), range: [-0.079, 161.691]

SelfAttention out shape: torch.Size([1, 6]), range: [0.000, 33.481]

SelfAttention out shape: torch.Size([1, 48, 1, 1]), range: [0.000, 1.000]

SelfAttention output shape: torch.Size([1, 48, 64, 64]), range: [-1.653, 437.060]

ConvLayer Input shape: torch.Size([1, 48, 64, 64]), range: [-1.653, 437.060]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-74.826, 75.252]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-5.440, 6.297]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]

Aggreation output shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]
After second blocks - x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]
After body shape: torch.Size([1, 16, 64, 64]), range: [-1.718, 0.990]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.718, 0.990]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.718, 0.990]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.718, 0.990]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-1.718, 0.990]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-1.718, 0.990]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-1.718, 0.990]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.552, 0.109]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.552, 0.109]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.223, 0.141]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.223, 0.141]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.223, 0.141]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.034, 0.037]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-1.722, 0.998]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.344, 0.998]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-1.289, 6.483]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.113, 1.792]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.003, 5.493]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.427, 3.583]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.427, 3.583]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.427, 3.583]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-2.427, 3.583]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.080, 1.890]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.571, 1.739]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.571, 1.739]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.571, 1.728]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.314, 1.739]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-0.986, 1.371]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.170, 0.138]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.270, 0.234]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.270, 0.234]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.113, 1.792]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.003, 5.493]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.427, 3.583]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.427, 3.583]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.427, 3.583]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.050, 2.063]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.050, 2.063]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.774, 2.063]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-2.050, 1.889]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.396, 2.558]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-1.259, 0.912]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-1.259, 0.912]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-1.360, 6.297]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 125.243]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]
After block3_1 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]
After body shape: torch.Size([1, 16, 64, 64]), range: [-8.381, 4.284]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-8.381, 4.284]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-8.381, 4.284]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-8.381, 4.284]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-8.381, 4.284]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-8.381, 4.284]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-8.381, 4.284]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-2.487, 1.773]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-2.487, 1.773]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.001]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.001]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-2.358, 0.768]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-2.358, 0.768]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-2.358, 0.768]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.304, 0.146]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-8.321, 4.386]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-1.664, 4.386]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-1.863, 45.820]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [0.124, 12.146]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.134, 223.267]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.371, 3.125]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.371, 3.125]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.371, 3.125]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-1.371, 3.125]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-1.765, 1.992]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.894, 1.479]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.894, 1.479]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.419, 1.034]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.894, 1.479]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-0.685, 0.920]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.136, 0.066]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.262, 0.234]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.262, 0.234]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [0.124, 12.146]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.134, 223.267]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.371, 3.125]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.371, 3.125]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.371, 3.125]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-1.767, 1.741]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.767, 1.741]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.583, 1.579]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.767, 1.741]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.790, 2.071]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-1.109, 1.021]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-1.109, 1.021]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 46.901]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 868.998]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 323.455]
After block3_2 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 323.455]

Aggreation Input shape: torch.Size([1, 64, 64, 64]), range: [-2.271, 323.455]

SelfAttention Input shape: torch.Size([1, 64, 64, 64]), range: [-2.271, 323.455]

SelfAttention Input shape: torch.Size([1, 64, 64, 64]), range: [-2.271, 323.455]

SelfAttention N: 1, C: 64, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 64]), range: [-0.126, 83.741]

SelfAttention out shape: torch.Size([1, 8]), range: [0.000, 17.251]

SelfAttention out shape: torch.Size([1, 64, 1, 1]), range: [0.000, 1.000]

SelfAttention output shape: torch.Size([1, 64, 64, 64]), range: [-1.513, 322.064]

ConvLayer Input shape: torch.Size([1, 64, 64, 64]), range: [-1.513, 322.064]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-44.313, 32.160]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-6.573, 7.547]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-1.643, 7.547]

Aggreation output shape: torch.Size([1, 16, 64, 64]), range: [-1.643, 7.547]
After third blocks - x3 shape: torch.Size([1, 16, 64, 64]), range: [-1.643, 7.547]

SPP Input shape: torch.Size([1, 16, 64, 64]), range: [-1.643, 7.547]

ConvLayer Input shape: torch.Size([1, 16, 16, 16]), range: [-1.202, 4.291]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-3.518, 1.663]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-0.879, 1.663]
SPP level 0 output shape: torch.Size([1, 16, 64, 64]), range: [-0.859, 1.572]

ConvLayer Input shape: torch.Size([1, 16, 8, 8]), range: [-0.665, 2.961]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-1.380, 1.568]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.345, 1.568]
SPP level 1 output shape: torch.Size([1, 16, 64, 64]), range: [-0.337, 1.537]

ConvLayer Input shape: torch.Size([1, 16, 4, 4]), range: [-0.186, 1.061]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.642, 0.871]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.161, 0.871]
SPP level 2 output shape: torch.Size([1, 16, 64, 64]), range: [-0.156, 0.871]

ConvLayer Input shape: torch.Size([1, 16, 2, 2]), range: [0.035, 0.469]

ConvLayer out shape: torch.Size([1, 16, 2, 2]), range: [-0.378, 0.223]

ConvLayer out shape: torch.Size([1, 16, 2, 2]), range: [-0.094, 0.223]
SPP level 3 output shape: torch.Size([1, 16, 64, 64]), range: [-0.094, 0.223]

SPP output length: 4, range: [-0.859, 1.572]
SPP level 0 output shape: torch.Size([1, 16, 64, 64]), range: [-0.859, 1.572]
SPP level 1 output shape: torch.Size([1, 16, 64, 64]), range: [-0.337, 1.537]
SPP level 2 output shape: torch.Size([1, 16, 64, 64]), range: [-0.156, 0.871]
SPP level 3 output shape: torch.Size([1, 16, 64, 64]), range: [-0.094, 0.223]
SPP level 4 output shape: torch.Size([1, 16, 64, 64]), range: [-1.643, 7.547]

ConvLayer Input shape: torch.Size([1, 80, 64, 64]), range: [-1.643, 7.547]

ConvLayer out shape: torch.Size([1, 12, 64, 64]), range: [-1.685, 1.343]

ConvLayer out shape: torch.Size([1, 12, 64, 64]), range: [-0.421, 1.343]

SPP output shape: torch.Size([1, 12, 64, 64]), range: [-0.421, 1.343]
DetailRestorer output shape: torch.Size([1, 12, 64, 64]), range: [-0.421, 1.343]
DetailRestorer 2 output shape: torch.Size([1, 12, 64, 64]), range: [-0.421, 1.343]
Prior down 2 shape: torch.Size([1, 12, 64, 64]), range: [-1.248, 1.184]

FeatureContextualizer Input shape: torch.Size([1, 12, 64, 64]), range: [-0.421, 1.343]
FeatureContextualizer Prior input shape: torch.Size([1, 12, 64, 64]), range: [-1.248, 1.184]

OverlapPatchEmbed Input shape: torch.Size([1, 12, 64, 64]), range: [-0.421, 1.343]

OverlapPatchEmbed output shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]

OverlapPatchEmbed Input shape: torch.Size([1, 12, 64, 64]), range: [-1.248, 1.184]

OverlapPatchEmbed output shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
After embed shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.678, 0.620]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.678, 0.620]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.192, 4.169]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.192, 4.169]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.915, 0.916]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.915, 0.916]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.119, 3.742]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.119, 3.742]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.119, 3.742]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.119, 3.742]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.119, 3.742]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.315, 2.441]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-2.012, 1.614]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.864, 1.963]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.864, 1.963]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.012, 1.614]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.315, 2.441]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.070, 0.066]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.088, 0.097]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.900, 0.907]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.006, 0.043]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.186, 0.212]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.186, 0.212]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.196, 0.242]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.971, 0.902]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.971, 0.902]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.971, 0.902]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.971, 0.902]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.971, 0.902]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.971, 0.902]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.410, 3.044]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.410, 3.044]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.410, 3.044]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.410, 3.044]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-3.410, 3.044]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.591, 2.080]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.269, 1.880], [-2.648, 2.389]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.408, 0.807]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.234, 0.327]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.968, 1.047]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.915, 0.916]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.915, 0.916]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.119, 3.742]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.119, 3.742]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.119, 3.742]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.119, 3.742]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.678, 0.620]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.678, 0.620]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.192, 4.169]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.192, 4.169]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.119, 3.742]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-1.914, 1.885]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.914, 1.885]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.208, 1.889]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.208, 1.889]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.914, 1.885]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.815, 1.740]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.106, 0.077]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.065, 0.070]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.892, 0.882]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.006, 0.051]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.227, 0.159]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.227, 0.159]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.238, 0.180]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.726, 0.635]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.726, 0.635]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.726, 0.635]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.726, 0.635]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.726, 0.635]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.726, 0.635]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.976, 3.898]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.976, 3.898]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.976, 3.898]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.976, 3.898]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-3.976, 3.898]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.572, 2.509]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.138, 1.776], [-2.146, 1.808]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.713, 1.161]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.232, 0.259]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.853, 0.777]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.915, 0.916]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.915, 0.916]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.915, 0.916]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.119, 3.742]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.119, 3.742]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.119, 3.742]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.119, 3.742]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.119, 3.742]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-1.789, 2.434]
Q shape: torch.Size([1, 48, 64, 64]), range: [-1.538, 1.284]
K shape: torch.Size([1, 48, 64, 64]), range: [-1.789, 2.434]
V shape: torch.Size([1, 48, 64, 64]), range: [-1.735, 2.097]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.538, 1.284]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.789, 2.434]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.735, 2.097]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.065, 0.074]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.065, 0.064]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.958, 0.961]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.007, 0.045]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.203, 0.110]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.203, 0.110]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.269, 0.260]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-1.013, 0.973]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.013, 0.973]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.013, 0.973]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-1.013, 0.973]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-1.013, 0.973]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-1.013, 0.973]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.315, 2.881]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.315, 2.881]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.315, 2.881]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.315, 2.881]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-3.315, 2.881]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.179, 2.156]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.301, 2.181], [-1.709, 1.446]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.984, 0.741]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.242, 0.225]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.932, 0.948]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.278, 20.137]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 6.668]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 6.668]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.721, 5.672]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.721, 5.672]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 6.668]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 6.668]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.721, 5.672]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.721, 5.672]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-1.844, 2.732]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.844, 1.544]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.642, 2.181]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.642, 2.181]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.844, 1.544]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.660, 2.732]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.073, 0.074]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.072, 0.073]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.932, 0.948]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.006, 0.055]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.170, 0.296]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.170, 0.296]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.347, 0.247]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.528, 6.636]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.528, 6.636]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.528, 6.636]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.528, 6.636]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.528, 6.636]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.528, 6.636]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.210, 5.558]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.210, 5.558]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.210, 5.558]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.210, 5.558]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.210, 5.558]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.403, 2.429]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.949, 1.762], [-2.065, 1.826]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.960, 1.400]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.218, 0.259]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.628, 6.706]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 6.668]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 6.668]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.721, 5.672]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.721, 5.672]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 6.668]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 6.668]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.721, 5.672]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.721, 5.672]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.151, 2.365]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-2.151, 1.726]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-3.022, 1.674]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-3.022, 1.674]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.151, 1.726]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.421, 2.365]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.077, 0.073]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.070, 0.076]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.936, 0.954]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.006, 0.047]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.205, 0.155]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.205, 0.155]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.268, 0.247]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.491, 6.684]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.491, 6.684]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.491, 6.684]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.491, 6.684]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.491, 6.684]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.491, 6.684]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.153, 5.671]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.153, 5.671]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.153, 5.671]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.153, 5.671]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.153, 5.671]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.766, 2.370]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.219, 2.144], [-2.121, 1.571]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.917, 1.199]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.251, 0.268]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.630, 6.692]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 6.668]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 6.668]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 6.668]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.721, 5.672]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.721, 5.672]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.721, 5.672]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-1.941, 2.080]
Q shape: torch.Size([1, 48, 64, 64]), range: [-1.616, 2.080]
K shape: torch.Size([1, 48, 64, 64]), range: [-1.481, 1.865]
V shape: torch.Size([1, 48, 64, 64]), range: [-1.941, 1.742]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.616, 2.080]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.481, 1.865]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.941, 1.742]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.071, 0.068]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.074, 0.089]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.913, 0.926]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.007, 0.045]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.191, 0.182]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.191, 0.182]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.254, 0.243]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.505, 6.761]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.505, 6.761]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.505, 6.761]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.505, 6.761]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.505, 6.761]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.505, 6.761]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.853, 5.651]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.853, 5.651]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.853, 5.651]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.853, 5.651]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-1.853, 5.651]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.453, 2.509]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.086, 1.770], [-2.448, 1.964]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.640, 1.180]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.340, 0.289]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.694, 6.712]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.278, 207.135]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 102.046]

Aggreation Input shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 102.046]

SelfAttention Input shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 102.046]

SelfAttention Input shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 102.046]

SelfAttention N: 1, C: 96, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 96]), range: [-0.225, 11.333]

SelfAttention out shape: torch.Size([1, 12]), range: [0.000, 2.653]

SelfAttention out shape: torch.Size([1, 96, 1, 1]), range: [0.224, 0.773]

SelfAttention output shape: torch.Size([1, 96, 64, 64]), range: [-0.215, 74.136]

ConvLayer Input shape: torch.Size([1, 96, 64, 64]), range: [-0.215, 74.136]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-13.597, 19.075]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-8.137, 9.390]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]

Aggreation output shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]
After first blocks - x1 shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.678, 0.620]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.678, 0.620]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.192, 4.169]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.192, 4.169]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.034, 9.390]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.034, 9.390]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.385, 5.125]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.385, 5.125]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.385, 5.125]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.385, 5.125]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.385, 5.125]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.182, 2.319]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.633, 2.319]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.018, 1.728]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.018, 1.728]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.633, 2.319]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.182, 1.986]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.064, 0.071]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.073, 0.068]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.746, 0.733]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.009, 0.040]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.211, 0.218]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.211, 0.218]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.221, 0.193]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-2.087, 9.369]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.087, 9.369]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.087, 9.369]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.087, 9.369]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.087, 9.369]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.087, 9.369]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.318, 5.190]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.318, 5.190]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.318, 5.190]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.318, 5.190]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.318, 5.190]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.541, 2.934]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.388, 2.350], [-1.858, 1.746]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.315, 2.303]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.287, 0.377]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-2.122, 9.371]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.034, 9.390]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.034, 9.390]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.385, 5.125]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.385, 5.125]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.385, 5.125]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.385, 5.125]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.678, 0.620]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.678, 0.620]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.678, 0.620]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.192, 4.169]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.192, 4.169]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.385, 5.125]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.192, 4.169]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.050, 2.023]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.749, 2.023]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.308, 1.869]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.308, 1.869]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.749, 2.023]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.050, 1.702]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.079, 0.077]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.067, 0.067]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.799, 0.801]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.008, 0.044]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.303, 0.175]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.303, 0.175]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.318, 0.298]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.769, 0.654]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.769, 0.654]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.769, 0.654]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.769, 0.654]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.769, 0.654]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.769, 0.654]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.754, 3.906]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.754, 3.906]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.754, 3.906]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.754, 3.906]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-3.754, 3.906]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-3.127, 2.558]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.590, 1.944], [-1.821, 1.976]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.039, 1.013]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.240, 0.256]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.864, 0.689]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.034, 9.390]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.034, 9.390]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.034, 9.390]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.385, 5.125]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.385, 5.125]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.385, 5.125]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.385, 5.125]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.385, 5.125]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-2.373, 1.822]
Q shape: torch.Size([1, 48, 64, 64]), range: [-2.255, 1.822]
K shape: torch.Size([1, 48, 64, 64]), range: [-2.373, 1.787]
V shape: torch.Size([1, 48, 64, 64]), range: [-2.187, 1.754]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.255, 1.822]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.373, 1.787]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.187, 1.754]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.064, 0.067]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.063, 0.065]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.776, 0.719]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.009, 0.041]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.141, 0.220]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.141, 0.220]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.433, 0.336]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-2.146, 9.498]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.146, 9.498]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.146, 9.498]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.146, 9.498]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.146, 9.498]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.146, 9.498]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.626, 5.030]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.626, 5.030]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.626, 5.030]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.626, 5.030]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.626, 5.030]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.669, 2.643]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.257, 2.289], [-2.328, 2.032]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.626, 1.929]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.301, 0.308]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-2.112, 9.512]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.278, 421.629]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 251.582]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 251.582]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-0.895, 3.830]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-0.895, 3.830]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 251.582]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 251.582]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-0.895, 3.830]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-0.895, 3.830]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-1.757, 2.055]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.757, 1.879]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.573, 1.584]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.573, 1.584]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.757, 1.879]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.408, 2.055]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.113, 0.066]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.080, 0.080]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.991, 0.992]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.005, 0.048]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.195, 0.135]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.195, 0.135]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.221, 0.168]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.448, 251.606]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.448, 251.606]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.448, 251.606]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.448, 251.606]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.448, 251.606]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.448, 251.606]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-0.893, 3.832]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-0.893, 3.832]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-0.893, 3.832]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-0.893, 3.832]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-0.893, 3.832]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-1.866, 1.679]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.636, 1.579], [-2.479, 1.479]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.131, 0.604]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.229, 0.188]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.439, 251.664]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 251.582]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 251.582]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-0.895, 3.830]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-0.895, 3.830]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 251.582]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 251.582]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-0.895, 3.830]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-0.895, 3.830]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.156, 1.704]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-2.156, 1.704]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.662, 1.562]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.662, 1.562]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.156, 1.704]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.852, 1.580]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.079, 0.097]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.089, 0.080]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.993, 0.993]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.005, 0.049]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.126, 0.197]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.126, 0.197]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.194, 0.163]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.442, 251.481]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.442, 251.481]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.442, 251.481]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.442, 251.481]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.442, 251.481]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.442, 251.481]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-0.902, 3.824]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-0.902, 3.824]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-0.902, 3.824]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-0.902, 3.824]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-0.902, 3.824]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.179, 1.907]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.563, 1.329], [-1.463, 1.510]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.951, 0.674]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.198, 0.174]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.534, 251.568]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 251.582]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 251.582]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 251.582]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-0.895, 3.830]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-0.895, 3.830]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-0.895, 3.830]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-1.719, 1.861]
Q shape: torch.Size([1, 48, 64, 64]), range: [-1.085, 1.645]
K shape: torch.Size([1, 48, 64, 64]), range: [-1.518, 1.861]
V shape: torch.Size([1, 48, 64, 64]), range: [-1.719, 1.366]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.085, 1.645]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.518, 1.861]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.719, 1.366]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.074, 0.096]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.071, 0.079]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.987, 0.991]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.006, 0.041]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.213, 0.034]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.213, 0.034]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.324, 0.381]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.570, 251.731]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.570, 251.731]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.570, 251.731]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.570, 251.731]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.570, 251.731]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.570, 251.731]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-0.918, 3.839]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-0.918, 3.839]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-0.918, 3.839]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-0.918, 3.839]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-0.918, 3.839]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.222, 2.255]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.703, 1.784], [-1.486, 1.630]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.660, 0.733]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.194, 0.181]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.605, 251.666]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.222, 11649.058]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 10431.975]

Aggreation Input shape: torch.Size([1, 144, 64, 64]), range: [-2.034, 10431.975]

SelfAttention Input shape: torch.Size([1, 144, 64, 64]), range: [-2.034, 10431.975]

SelfAttention Input shape: torch.Size([1, 144, 64, 64]), range: [-2.034, 10431.975]

SelfAttention N: 1, C: 144, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 144]), range: [-0.035, 1581.796]

SelfAttention out shape: torch.Size([1, 18]), range: [0.000, 205.294]

SelfAttention out shape: torch.Size([1, 144, 1, 1]), range: [0.000, 1.000]

SelfAttention output shape: torch.Size([1, 144, 64, 64]), range: [-1.946, 7722.003]

ConvLayer Input shape: torch.Size([1, 144, 64, 64]), range: [-1.946, 7722.003]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-1996.126, 1498.347]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-9.524, 9.515]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-2.381, 9.515]

Aggreation output shape: torch.Size([1, 48, 64, 64]), range: [-2.381, 9.515]
After second blocks - x2 shape: torch.Size([1, 48, 64, 64]), range: [-2.381, 9.515]

SPP Input shape: torch.Size([1, 48, 64, 64]), range: [-2.381, 9.515]

ConvLayer Input shape: torch.Size([1, 48, 16, 16]), range: [-1.863, 7.468]

ConvLayer out shape: torch.Size([1, 48, 16, 16]), range: [-5.336, 6.376]

ConvLayer out shape: torch.Size([1, 48, 16, 16]), range: [-1.334, 6.376]
SPP level 0 output shape: torch.Size([1, 48, 64, 64]), range: [-1.266, 6.029]

ConvLayer Input shape: torch.Size([1, 48, 8, 8]), range: [-1.199, 4.743]

ConvLayer out shape: torch.Size([1, 48, 8, 8]), range: [-4.136, 3.080]

ConvLayer out shape: torch.Size([1, 48, 8, 8]), range: [-1.034, 3.080]
SPP level 1 output shape: torch.Size([1, 48, 64, 64]), range: [-0.998, 2.956]

ConvLayer Input shape: torch.Size([1, 48, 4, 4]), range: [-0.208, 1.421]

ConvLayer out shape: torch.Size([1, 48, 4, 4]), range: [-0.862, 1.257]

ConvLayer out shape: torch.Size([1, 48, 4, 4]), range: [-0.216, 1.257]
SPP level 2 output shape: torch.Size([1, 48, 64, 64]), range: [-0.215, 1.254]

ConvLayer Input shape: torch.Size([1, 48, 2, 2]), range: [-0.009, 0.578]

ConvLayer out shape: torch.Size([1, 48, 2, 2]), range: [-0.539, 0.580]

ConvLayer out shape: torch.Size([1, 48, 2, 2]), range: [-0.135, 0.580]
SPP level 3 output shape: torch.Size([1, 48, 64, 64]), range: [-0.135, 0.580]

SPP output length: 4, range: [-1.266, 6.029]
SPP level 0 output shape: torch.Size([1, 48, 64, 64]), range: [-1.266, 6.029]
SPP level 1 output shape: torch.Size([1, 48, 64, 64]), range: [-0.998, 2.956]
SPP level 2 output shape: torch.Size([1, 48, 64, 64]), range: [-0.215, 1.254]
SPP level 3 output shape: torch.Size([1, 48, 64, 64]), range: [-0.135, 0.580]
SPP level 4 output shape: torch.Size([1, 48, 64, 64]), range: [-2.381, 9.515]

ConvLayer Input shape: torch.Size([1, 240, 64, 64]), range: [-2.381, 9.515]

ConvLayer out shape: torch.Size([1, 24, 64, 64]), range: [-3.405, 5.319]

ConvLayer out shape: torch.Size([1, 24, 64, 64]), range: [-0.851, 5.319]

SPP output shape: torch.Size([1, 24, 64, 64]), range: [-0.851, 5.319]
FeatureContextualizer output shape: torch.Size([1, 24, 64, 64]), range: [-0.851, 5.319]
FeatureContextualizer output shape: torch.Size([1, 24, 64, 64]), range: [-0.851, 5.319]

ScaleHarmonizer Input shape: torch.Size([1, 24, 64, 64]), range: [-0.851, 5.319]

Condition Input shape: torch.Size([1, 24, 64, 64]), range: [-0.851, 5.319]
Condition conv1 output shape: torch.Size([1, 32, 30, 30]), range: [0.000, 1.728]
Condition conv2 output shape: torch.Size([1, 32, 15, 15]), range: [0.000, 0.488]
Condition conv3 output shape: torch.Size([1, 32, 8, 8]), range: [0.000, 0.121]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.075]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.075]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.163, 0.184]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.200, 0.193]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.196, 0.180]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.178, 0.196]
ScaleHarmonizer Scale3 shape: torch.Size([1, 12]), range: [-0.167, 0.137]
ScaleHarmonizer Shift3 shape: torch.Size([1, 12]), range: [-0.134, 0.139]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 64, 64]), range: [-2.378, 1.848]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 64, 64]), range: [-2.629, 1.737]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 64, 64]), range: [0.000, 1.737]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 64, 64]), range: [-0.740, 0.852]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 64, 64]), range: [-0.725, 0.752]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 64, 64]), range: [0.000, 0.752]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 12, 64, 64]), range: [-0.193, 0.142]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 12, 64, 64]), range: [-0.295, 0.232]
First fusion output shape: torch.Size([1, 12, 64, 64]), range: [-0.295, 0.232]
Upsampling 1 output shape: torch.Size([1, 6, 128, 128]), range: [-0.691, 0.681]
Fusion 1 input shape: torch.Size([1, 12, 128, 128]), range: [-0.779, 2.345]

ScaleHarmonizer Input shape: torch.Size([1, 12, 128, 128]), range: [-0.779, 2.345]

Condition Input shape: torch.Size([1, 12, 128, 128]), range: [-0.779, 2.345]
Condition conv1 output shape: torch.Size([1, 32, 62, 62]), range: [0.000, 0.564]
Condition conv2 output shape: torch.Size([1, 32, 31, 31]), range: [0.000, 0.212]
Condition conv3 output shape: torch.Size([1, 32, 16, 16]), range: [0.000, 0.104]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.050]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.050]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.178, 0.184]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.176, 0.160]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.176, 0.176]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.165, 0.167]
ScaleHarmonizer Scale3 shape: torch.Size([1, 6]), range: [-0.150, 0.125]
ScaleHarmonizer Shift3 shape: torch.Size([1, 6]), range: [-0.102, 0.155]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 128, 128]), range: [-1.086, 1.009]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 128, 128]), range: [-1.122, 0.957]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 128, 128]), range: [0.000, 0.957]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 128, 128]), range: [-0.483, 0.514]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 128, 128]), range: [-0.486, 0.550]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 128, 128]), range: [0.000, 0.550]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 6, 128, 128]), range: [-0.078, 0.237]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 6, 128, 128]), range: [-0.153, 0.286]
Fusion 1 output shape: torch.Size([1, 6, 128, 128]), range: [-0.153, 0.286]
Upsampling 0 output shape: torch.Size([1, 3, 256, 256]), range: [-0.135, 0.109]
Fusion 0 input shape: torch.Size([1, 6, 256, 256]), range: [-0.396, 2.019]

ScaleHarmonizer Input shape: torch.Size([1, 6, 256, 256]), range: [-0.396, 2.019]

Condition Input shape: torch.Size([1, 6, 256, 256]), range: [-0.396, 2.019]
Condition conv1 output shape: torch.Size([1, 32, 126, 126]), range: [0.000, 0.749]
Condition conv2 output shape: torch.Size([1, 32, 63, 63]), range: [0.000, 0.269]
Condition conv3 output shape: torch.Size([1, 32, 32, 32]), range: [0.000, 0.133]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.090]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.090]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.198, 0.165]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.172, 0.186]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.196, 0.185]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.176, 0.209]
ScaleHarmonizer Scale3 shape: torch.Size([1, 3]), range: [-0.070, 0.113]
ScaleHarmonizer Shift3 shape: torch.Size([1, 3]), range: [0.024, 0.068]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 256, 256]), range: [-1.042, 1.170]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-1.228, 1.348]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 1.348]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 256, 256]), range: [-0.686, 0.523]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-0.586, 0.625]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 0.625]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 3, 256, 256]), range: [-0.283, 0.102]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 3, 256, 256]), range: [-0.281, 0.120]
Fusion 0 output shape: torch.Size([1, 3, 256, 256]), range: [-0.281, 0.120]
Final concatenation shape: torch.Size([1, 9, 256, 256]), range: [torch.Size([1, 9, 256, 256]), range: [-4.568, 4.488]

ScaleHarmonizer Input shape: torch.Size([1, 9, 256, 256]), range: [-4.568, 4.488]

Condition Input shape: torch.Size([1, 9, 256, 256]), range: [-4.568, 4.488]
Condition conv1 output shape: torch.Size([1, 32, 126, 126]), range: [0.000, 1.824]
Condition conv2 output shape: torch.Size([1, 32, 63, 63]), range: [0.000, 0.636]
Condition conv3 output shape: torch.Size([1, 32, 32, 32]), range: [0.000, 0.290]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.135]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.135]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.194, 0.189]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.190, 0.182]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.206, 0.198]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.198, 0.181]
ScaleHarmonizer Scale3 shape: torch.Size([1, 3]), range: [-0.084, 0.121]
ScaleHarmonizer Shift3 shape: torch.Size([1, 3]), range: [-0.113, 0.019]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 256, 256]), range: [-2.820, 3.214]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-2.837, 3.701]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 3.701]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 256, 256]), range: [-1.241, 1.375]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-1.442, 1.510]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 1.510]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 3, 256, 256]), range: [-0.327, 0.318]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 3, 256, 256]), range: [-0.392, 0.374]
Final output shape: torch.Size([1, 3, 256, 256]), range: [0.403, 0.592]
Model final output shape: torch.Size([1, 3, 256, 256]), range: [0.403, 0.592]
MACs: 10.053G, Params: 1.145M

Running model test...

==================================================
Starting model test
==================================================

Model initialized on device: cuda
Input tensor created with shape: torch.Size([1, 3, 256, 256])

Running forward pass...

Model Input shape: torch.Size([1, 3, 256, 256]), range: [-4.386, 4.279]

ColorBalancePrior Input shape: torch.Size([1, 3, 256, 256]), range: [-4.386, 4.279]
--------------------------------------------------
ColorBalancePrior mean shape: torch.Size([1, 1, 256, 256]), range: [-2.470, 2.372]
--------------------------------------------------
ColorBalancePrior expanded mean shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]
--------------------------------------------------

NAFBlock Input shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]

LayerNorm2d forward Input shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]

LayerNormFunction forward Input shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-2.470, 2.372]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.000, 0.000]
LayerNormFunction forward normalized shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNormFunction forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNorm2d forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
After norm1 shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
After conv1 shape: torch.Size([1, 6, 256, 256]), range: [-0.497, 0.485]
After conv2 shape: torch.Size([1, 6, 256, 256]), range: [-0.482, 0.557]

SimpleGate Input shape: torch.Size([1, 6, 256, 256]), range: [-0.482, 0.557]
SimpleGate x1 shape: torch.Size([1, 3, 256, 256]), range: [-0.371, 0.557]
SimpleGate x2 shape: torch.Size([1, 3, 256, 256]), range: [-0.482, 0.467]
After sg shape: torch.Size([1, 3, 256, 256]), range: [0.002, 0.198]
After sca shape: torch.Size([1, 3, 256, 256]), range: [-0.074, 0.030]
After conv3 shape: torch.Size([1, 3, 256, 256]), range: [-0.209, 0.374]
After dropout1 shape: torch.Size([1, 3, 256, 256]), range: [-0.209, 0.374]
After beta shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]

LayerNorm2d forward Input shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]

LayerNormFunction forward Input shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-2.470, 2.372]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.000, 0.000]
LayerNormFunction forward normalized shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNormFunction forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNorm2d forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
After conv4 shape: torch.Size([1, 6, 256, 256]), range: [-0.489, 0.471]

SimpleGate Input shape: torch.Size([1, 6, 256, 256]), range: [-0.489, 0.471]
SimpleGate x1 shape: torch.Size([1, 3, 256, 256]), range: [-0.489, 0.471]
SimpleGate x2 shape: torch.Size([1, 3, 256, 256]), range: [-0.458, 0.090]
After sg shape: torch.Size([1, 3, 256, 256]), range: [-0.089, 0.224]
After conv5 shape: torch.Size([1, 3, 256, 256]), range: [-0.457, 0.437]
After dropout2 shape: torch.Size([1, 3, 256, 256]), range: [-0.457, 0.437]
NAFBlock output shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]
ColorBalancePrior output shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]
--------------------------------------------------
Prior output shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]

PriorGuidedRE Input shape: torch.Size([1, 3, 256, 256]), range: [-4.386, 4.279]
PriorGuidedRE Prior input shape: torch.Size([1, 3, 256, 256]), range: [-2.470, 2.372]

DetailRestorer Input shape: torch.Size([1, 3, 256, 256]), range: [-4.386, 4.279]

OverlapPatchEmbed Input shape: torch.Size([1, 3, 256, 256]), range: [-4.386, 4.279]

OverlapPatchEmbed output shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]
After embed shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]
After body shape: torch.Size([1, 16, 256, 256]), range: [-0.767, 0.755]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.767, 0.755]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.767, 0.755]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.767, 0.755]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-0.767, 0.755]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-0.767, 0.755]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-0.767, 0.755]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.388, 0.308]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.388, 0.308]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.135, 0.118]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.135, 0.118]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.135, 0.118]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.036, 0.033]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.791, 0.734]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.158, 0.734]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-2.863, 3.021]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.598, 0.607]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.019, 1.783]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-3.379, 3.400]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.379, 3.400]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.379, 3.400]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-3.379, 3.400]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.277, 2.335]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-1.627, 1.812]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.627, 1.812]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.507, 1.736]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.627, 1.812]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.559, 1.107]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.221, 0.396]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.277, 0.310]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.277, 0.310]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.598, 0.607]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.019, 1.783]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-3.379, 3.400]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.379, 3.400]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.379, 3.400]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.423, 2.570]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.423, 2.570]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.423, 2.570]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.421, 2.423]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-3.316, 4.047]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.555, 1.375]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.555, 1.375]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-2.969, 2.917]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 33.885]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]
After block1_1 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]
After body shape: torch.Size([1, 16, 256, 256]), range: [-0.823, 0.809]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.823, 0.809]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.823, 0.809]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.823, 0.809]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-0.823, 0.809]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-0.823, 0.809]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-0.823, 0.809]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.390, 0.382]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.390, 0.382]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.131, 0.113]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.131, 0.113]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.131, 0.113]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.028, 0.020]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.830, 0.812]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.166, 0.812]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-0.438, 5.298]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.190, 1.715]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.011, 3.779]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.503, 3.845]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.503, 3.845]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.503, 3.845]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-2.503, 3.845]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.451, 2.174]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-2.156, 1.935]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.156, 1.935]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.829, 1.935]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.156, 1.885]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.841, 1.794]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.275, 0.309]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.307, 0.282]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.307, 0.282]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.190, 1.715]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.011, 3.779]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.503, 3.845]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.503, 3.845]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.503, 3.845]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.420, 2.567]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.420, 2.567]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.420, 2.567]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.304, 2.110]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-3.447, 3.674]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.533, 1.164]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.533, 1.164]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 5.232]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 65.713]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 6.718]
After block1_2 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 6.718]

Aggreation Input shape: torch.Size([1, 32, 256, 256]), range: [-0.278, 6.718]

SelfAttention Input shape: torch.Size([1, 32, 256, 256]), range: [-0.278, 6.718]

SelfAttention Input shape: torch.Size([1, 32, 256, 256]), range: [-0.278, 6.718]

SelfAttention N: 1, C: 32, H: 256, W: 256

SelfAttention out shape: torch.Size([1, 32]), range: [0.202, 0.205]

SelfAttention out shape: torch.Size([1, 4]), range: [0.000, 0.153]

SelfAttention out shape: torch.Size([1, 32, 1, 1]), range: [0.375, 0.610]

SelfAttention output shape: torch.Size([1, 32, 256, 256]), range: [-0.170, 3.607]

ConvLayer Input shape: torch.Size([1, 32, 256, 256]), range: [-0.170, 3.607]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-1.118, 1.464]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-6.743, 6.581]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]

Aggreation output shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]
After first blocks - x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]
After body shape: torch.Size([1, 16, 256, 256]), range: [-0.926, 1.117]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.926, 1.117]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.926, 1.117]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.926, 1.117]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-0.926, 1.117]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-0.926, 1.117]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-0.926, 1.117]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.411, 0.295]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.411, 0.295]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.080, 0.101]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.080, 0.101]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.080, 0.101]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.013, 0.015]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.931, 1.115]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.186, 1.115]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-1.790, 6.624]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.210, 1.664]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.014, 7.032]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.678, 3.797]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.678, 3.797]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.678, 3.797]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-2.678, 3.797]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.643, 2.288]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-2.043, 1.966]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.043, 1.966]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.043, 1.896]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.739, 1.966]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.142, 1.852]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.346, 0.361]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.320, 0.346]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.320, 0.346]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.210, 1.664]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.014, 7.032]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.678, 3.797]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.678, 3.797]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.678, 3.797]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.614, 2.498]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.614, 2.498]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.614, 2.498]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.508, 2.428]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-3.473, 3.423]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.424, 1.194]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.424, 1.194]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.686, 6.581]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 78.657]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]
After block2_1 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]
After body shape: torch.Size([1, 16, 256, 256]), range: [-0.995, 1.214]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.995, 1.214]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.995, 1.214]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.995, 1.214]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-0.995, 1.214]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-0.995, 1.214]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-0.995, 1.214]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.581, 0.312]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.581, 0.312]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.123, 0.146]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.123, 0.146]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.123, 0.146]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.010, 0.012]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.997, 1.216]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.199, 1.216]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-0.444, 7.489]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.181, 1.528]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.009, 6.125]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.235, 3.812]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.235, 3.812]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.235, 3.812]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-2.235, 3.812]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.768, 2.317]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-2.290, 1.867]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.290, 1.867]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.973, 1.867]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.290, 1.821]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.795, 1.583]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.232, 0.289]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.259, 0.302]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.259, 0.302]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.181, 1.528]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.009, 6.125]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.235, 3.812]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.235, 3.812]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.235, 3.812]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.341, 2.371]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.341, 2.371]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.226, 2.278]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.341, 2.371]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-3.056, 2.607]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-0.991, 1.366]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-0.991, 1.366]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 7.547]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 114.382]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 10.107]
After block2_2 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 10.107]

Aggreation Input shape: torch.Size([1, 48, 256, 256]), range: [-1.686, 10.107]

SelfAttention Input shape: torch.Size([1, 48, 256, 256]), range: [-1.686, 10.107]

SelfAttention Input shape: torch.Size([1, 48, 256, 256]), range: [-1.686, 10.107]

SelfAttention N: 1, C: 48, H: 256, W: 256

SelfAttention out shape: torch.Size([1, 48]), range: [0.182, 0.296]

SelfAttention out shape: torch.Size([1, 6]), range: [0.000, 0.101]

SelfAttention out shape: torch.Size([1, 48, 1, 1]), range: [0.398, 0.599]

SelfAttention output shape: torch.Size([1, 48, 256, 256]), range: [-0.860, 5.831]

ConvLayer Input shape: torch.Size([1, 48, 256, 256]), range: [-0.860, 5.831]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-1.793, 1.533]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-9.523, 8.588]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]

Aggreation output shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]
After second blocks - x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]
After body shape: torch.Size([1, 16, 256, 256]), range: [-1.196, 1.575]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.196, 1.575]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.196, 1.575]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.196, 1.575]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-1.196, 1.575]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-1.196, 1.575]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-1.196, 1.575]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.474, 0.338]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.474, 0.338]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.111, 0.178]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.111, 0.178]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.111, 0.178]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.020, 0.018]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.216, 1.575]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.243, 1.575]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-2.418, 8.991]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.222, 2.243]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.014, 8.949]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.552, 3.827]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.552, 3.827]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.552, 3.827]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-2.552, 3.827]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.504, 2.330]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-1.824, 1.795]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.824, 1.795]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.813, 1.795]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.824, 1.719]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.002, 1.532]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.281, 0.218]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.287, 0.249]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.287, 0.249]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.222, 2.243]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.014, 8.949]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.552, 3.827]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.552, 3.827]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.552, 3.827]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.183, 2.411]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.183, 2.411]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.170, 2.348]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.183, 2.411]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-3.248, 2.972]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.139, 1.348]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.139, 1.348]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-2.381, 8.588]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 133.827]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]
After block3_1 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]
After body shape: torch.Size([1, 16, 256, 256]), range: [-1.550, 1.807]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.550, 1.807]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.550, 1.807]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.550, 1.807]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-1.550, 1.807]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-1.550, 1.807]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-1.550, 1.807]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.632, 0.382]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.632, 0.382]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.116, 0.102]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.116, 0.102]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.116, 0.102]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.032, 0.024]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.558, 1.828]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.312, 1.828]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-0.483, 10.982]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.171, 3.083]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.012, 13.285]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.124, 3.828]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.124, 3.828]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.124, 3.828]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-2.124, 3.828]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.607, 2.314]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-2.008, 2.022]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.008, 2.022]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.692, 1.732]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.008, 2.022]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.628, 1.350]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.243, 0.275]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.298, 0.274]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.298, 0.274]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.171, 3.083]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.012, 13.285]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.124, 3.828]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.124, 3.828]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.124, 3.828]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.354, 2.456]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.354, 2.456]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.354, 2.227]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.341, 2.456]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.681, 3.032]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.636, 1.207]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.636, 1.207]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 11.013]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 194.294]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 15.672]
After block3_2 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 15.672]

Aggreation Input shape: torch.Size([1, 64, 256, 256]), range: [-2.381, 15.672]

SelfAttention Input shape: torch.Size([1, 64, 256, 256]), range: [-2.381, 15.672]

SelfAttention Input shape: torch.Size([1, 64, 256, 256]), range: [-2.381, 15.672]

SelfAttention N: 1, C: 64, H: 256, W: 256

SelfAttention out shape: torch.Size([1, 64]), range: [0.148, 0.296]

SelfAttention out shape: torch.Size([1, 8]), range: [0.000, 0.087]

SelfAttention out shape: torch.Size([1, 64, 1, 1]), range: [0.416, 0.594]

SelfAttention output shape: torch.Size([1, 64, 256, 256]), range: [-1.389, 8.593]

ConvLayer Input shape: torch.Size([1, 64, 256, 256]), range: [-1.389, 8.593]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-2.432, 2.919]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-11.796, 12.819]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-2.949, 12.819]

Aggreation output shape: torch.Size([1, 16, 256, 256]), range: [-2.949, 12.819]
After third blocks - x3 shape: torch.Size([1, 16, 256, 256]), range: [-2.949, 12.819]

SPP Input shape: torch.Size([1, 16, 256, 256]), range: [-2.949, 12.819]

ConvLayer Input shape: torch.Size([1, 16, 64, 64]), range: [-1.516, 6.281]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-2.795, 2.599]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-0.699, 2.599]
SPP level 0 output shape: torch.Size([1, 16, 256, 256]), range: [-0.619, 2.289]

ConvLayer Input shape: torch.Size([1, 16, 32, 32]), range: [-1.057, 4.664]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-1.794, 0.629]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-0.449, 0.629]
SPP level 1 output shape: torch.Size([1, 16, 256, 256]), range: [-0.406, 0.624]

ConvLayer Input shape: torch.Size([1, 16, 16, 16]), range: [-0.102, 1.250]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-0.576, 0.481]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-0.144, 0.481]
SPP level 2 output shape: torch.Size([1, 16, 256, 256]), range: [-0.138, 0.462]

ConvLayer Input shape: torch.Size([1, 16, 8, 8]), range: [0.080, 0.695]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.534, 0.278]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.134, 0.278]
SPP level 3 output shape: torch.Size([1, 16, 256, 256]), range: [-0.133, 0.277]

SPP output length: 4, range: [-0.619, 2.289]
SPP level 0 output shape: torch.Size([1, 16, 256, 256]), range: [-0.619, 2.289]
SPP level 1 output shape: torch.Size([1, 16, 256, 256]), range: [-0.406, 0.624]
SPP level 2 output shape: torch.Size([1, 16, 256, 256]), range: [-0.138, 0.462]
SPP level 3 output shape: torch.Size([1, 16, 256, 256]), range: [-0.133, 0.277]
SPP level 4 output shape: torch.Size([1, 16, 256, 256]), range: [-2.949, 12.819]

ConvLayer Input shape: torch.Size([1, 80, 256, 256]), range: [-2.949, 12.819]

ConvLayer out shape: torch.Size([1, 3, 256, 256]), range: [-1.754, 1.326]

ConvLayer out shape: torch.Size([1, 3, 256, 256]), range: [-0.439, 1.326]

SPP output shape: torch.Size([1, 3, 256, 256]), range: [-0.439, 1.326]
DetailRestorer output shape: torch.Size([1, 3, 256, 256]), range: [-0.439, 1.326]
First DetailRestorer output shape: torch.Size([1, 3, 256, 256]), range: [-0.439, 1.326]
Down 1 output shape: torch.Size([1, 6, 128, 128]), range: [-0.727, 0.881]

DetailRestorer Input shape: torch.Size([1, 6, 128, 128]), range: [-0.727, 0.881]

OverlapPatchEmbed Input shape: torch.Size([1, 6, 128, 128]), range: [-0.727, 0.881]

OverlapPatchEmbed output shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]
After embed shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]
After body shape: torch.Size([1, 16, 128, 128]), range: [-0.085, 0.086]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.085, 0.086]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.085, 0.086]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.085, 0.086]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-0.085, 0.086]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-0.085, 0.086]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-0.085, 0.086]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.034, 0.024]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.034, 0.024]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.033, 0.034]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.033, 0.034]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.033, 0.034]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.009, 0.005]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.080, 0.081]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.016, 0.081]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-0.456, 0.472]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.102, 0.077]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.002, 0.038]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-3.003, 2.963]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.003, 2.963]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.003, 2.963]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-3.003, 2.963]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.019, 1.898]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.418, 1.192]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.418, 1.192]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.418, 1.192]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.044, 1.148]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.006, 0.844]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.204, 0.250]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.261, 0.274]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.261, 0.274]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.102, 0.077]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.002, 0.038]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-3.003, 2.963]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.003, 2.963]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.003, 2.963]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.212, 2.374]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.212, 2.374]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.962, 2.374]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.212, 1.871]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-2.224, 2.592]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.086, 0.863]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.086, 0.863]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.458, 0.408]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 4.915]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]
After block1_1 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]
After body shape: torch.Size([1, 16, 128, 128]), range: [-0.574, 0.745]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.574, 0.745]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.574, 0.745]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.574, 0.745]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-0.574, 0.745]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-0.574, 0.745]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-0.574, 0.745]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.286, 0.264]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.286, 0.264]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.107, 0.082]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.107, 0.082]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.107, 0.082]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.014, 0.024]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.576, 0.743]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.115, 0.743]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-0.377, 5.363]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.167, 1.168]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.010, 3.057]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.363, 3.820]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.363, 3.820]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.363, 3.820]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-2.363, 3.820]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.304, 2.203]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-2.058, 1.894]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.058, 1.894]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.058, 1.894]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.566, 1.512]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.723, 1.621]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.210, 0.217]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.270, 0.288]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.270, 0.288]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.167, 1.168]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.010, 3.057]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.363, 3.820]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.363, 3.820]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.363, 3.820]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.279, 2.190]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.279, 2.190]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.196, 2.185]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.279, 2.190]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-3.086, 3.530]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.118, 1.263]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.118, 1.263]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 5.200]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 78.431]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 6.866]
After block1_2 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 6.866]

Aggreation Input shape: torch.Size([1, 32, 128, 128]), range: [-0.278, 6.866]

SelfAttention Input shape: torch.Size([1, 32, 128, 128]), range: [-0.278, 6.866]

SelfAttention Input shape: torch.Size([1, 32, 128, 128]), range: [-0.278, 6.866]

SelfAttention N: 1, C: 32, H: 128, W: 128

SelfAttention out shape: torch.Size([1, 32]), range: [0.192, 0.206]

SelfAttention out shape: torch.Size([1, 4]), range: [0.025, 0.247]

SelfAttention out shape: torch.Size([1, 32, 1, 1]), range: [0.381, 0.602]

SelfAttention output shape: torch.Size([1, 32, 128, 128]), range: [-0.168, 3.400]

ConvLayer Input shape: torch.Size([1, 32, 128, 128]), range: [-0.168, 3.400]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-1.355, 1.514]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-7.309, 7.529]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]

Aggreation output shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]
After first blocks - x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]
After body shape: torch.Size([1, 16, 128, 128]), range: [-1.124, 1.374]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.124, 1.374]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.124, 1.374]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.124, 1.374]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-1.124, 1.374]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-1.124, 1.374]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-1.124, 1.374]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.423, 0.630]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.423, 0.630]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.175, 0.220]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.175, 0.220]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.175, 0.220]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.046, 0.044]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-1.170, 1.343]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.234, 1.343]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-1.440, 7.696]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.170, 1.175]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.009, 4.928]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.523, 3.817]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.523, 3.817]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.523, 3.817]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-2.523, 3.817]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.218, 2.472]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.853, 2.188]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.853, 2.188]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.853, 2.020]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.845, 2.188]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.952, 1.733]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.291, 0.349]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.258, 0.278]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.258, 0.278]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.170, 1.175]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.009, 4.928]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.523, 3.817]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.523, 3.817]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.523, 3.817]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.301, 2.279]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.301, 2.279]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.175, 2.234]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.301, 2.279]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-2.401, 3.311]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.025, 1.132]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.025, 1.132]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-1.827, 7.529]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 96.239]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]
After block2_1 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]
After body shape: torch.Size([1, 16, 128, 128]), range: [-1.251, 0.928]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.251, 0.928]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.251, 0.928]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.251, 0.928]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-1.251, 0.928]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-1.251, 0.928]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-1.251, 0.928]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.297, 0.293]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.297, 0.293]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.083, 0.046]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.083, 0.046]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.083, 0.046]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.012, 0.011]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-1.258, 0.916]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.252, 0.916]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-0.474, 7.688]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.125, 2.032]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.014, 6.620]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-1.982, 3.774]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.982, 3.774]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.982, 3.774]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-1.982, 3.774]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.230, 2.285]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-2.027, 2.288]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.027, 2.288]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.027, 2.288]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.763, 1.799]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-2.004, 2.363]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.224, 0.203]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.302, 0.273]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.302, 0.273]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.125, 2.032]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.014, 6.620]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-1.982, 3.774]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.982, 3.774]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.982, 3.774]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.392, 2.390]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.392, 2.390]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.104, 2.355]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.392, 2.390]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-3.276, 2.382]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.008, 1.186]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.008, 1.186]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.347]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 136.190]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 9.021]
After block2_2 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 9.021]

Aggreation Input shape: torch.Size([1, 48, 128, 128]), range: [-1.827, 9.021]

SelfAttention Input shape: torch.Size([1, 48, 128, 128]), range: [-1.827, 9.021]

SelfAttention Input shape: torch.Size([1, 48, 128, 128]), range: [-1.827, 9.021]

SelfAttention N: 1, C: 48, H: 128, W: 128

SelfAttention out shape: torch.Size([1, 48]), range: [0.152, 0.296]

SelfAttention out shape: torch.Size([1, 6]), range: [0.000, 0.149]

SelfAttention out shape: torch.Size([1, 48, 1, 1]), range: [0.369, 0.624]

SelfAttention output shape: torch.Size([1, 48, 128, 128]), range: [-0.905, 5.387]

ConvLayer Input shape: torch.Size([1, 48, 128, 128]), range: [-0.905, 5.387]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-1.528, 1.575]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-8.092, 7.910]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]

Aggreation output shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]
After second blocks - x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]
After body shape: torch.Size([1, 16, 128, 128]), range: [-2.010, 2.145]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.010, 2.145]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.010, 2.145]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.010, 2.145]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-2.010, 2.145]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-2.010, 2.145]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-2.010, 2.145]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.177, 1.329]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.177, 1.329]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.165, 0.243]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.165, 0.243]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.165, 0.243]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.049, 0.069]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-2.010, 2.141]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.402, 2.141]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-2.105, 8.469]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.178, 1.667]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.011, 5.889]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-3.322, 3.791]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.322, 3.791]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.322, 3.791]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-3.322, 3.791]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.309, 2.184]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.863, 1.743]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.863, 1.743]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.583, 1.743]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.863, 1.617]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.318, 1.699]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.183, 0.278]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.285, 0.169]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.285, 0.169]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.178, 1.667]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.011, 5.889]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-3.322, 3.791]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.322, 3.791]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.322, 3.791]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.428, 2.878]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.428, 2.878]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.244, 2.202]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.428, 2.878]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-3.267, 3.273]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.087, 1.187]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.087, 1.187]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-2.023, 7.910]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 122.575]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]
After block3_1 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]
After body shape: torch.Size([1, 16, 128, 128]), range: [-1.241, 1.163]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.241, 1.163]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.241, 1.163]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-1.241, 1.163]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-1.241, 1.163]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-1.241, 1.163]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-1.241, 1.163]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.276, 0.298]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.276, 0.298]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.177, 0.081]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.177, 0.081]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.177, 0.081]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.025, 0.023]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-1.234, 1.155]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.247, 1.155]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-0.493, 7.628]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.127, 2.371]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.007, 7.531]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.302, 3.760]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.302, 3.760]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.302, 3.760]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-2.302, 3.760]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.170, 2.229]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.661, 1.998]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.661, 1.998]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.610, 1.536]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.661, 1.998]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.988, 1.490]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.255, 0.394]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.302, 0.291]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.302, 0.291]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.127, 2.371]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.007, 7.531]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.302, 3.760]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.302, 3.760]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.302, 3.760]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.061, 2.201]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.061, 2.201]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.033, 2.060]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.061, 2.201]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-2.465, 2.540]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.090, 1.006]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.090, 1.006]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 7.639]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 145.527]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 9.403]
After block3_2 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 9.403]

Aggreation Input shape: torch.Size([1, 64, 128, 128]), range: [-2.023, 9.403]

SelfAttention Input shape: torch.Size([1, 64, 128, 128]), range: [-2.023, 9.403]

SelfAttention Input shape: torch.Size([1, 64, 128, 128]), range: [-2.023, 9.403]

SelfAttention N: 1, C: 64, H: 128, W: 128

SelfAttention out shape: torch.Size([1, 64]), range: [0.149, 0.296]

SelfAttention out shape: torch.Size([1, 8]), range: [0.000, 0.172]

SelfAttention out shape: torch.Size([1, 64, 1, 1]), range: [0.407, 0.596]

SelfAttention output shape: torch.Size([1, 64, 128, 128]), range: [-1.206, 5.355]

ConvLayer Input shape: torch.Size([1, 64, 128, 128]), range: [-1.206, 5.355]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-1.960, 1.694]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-9.124, 7.746]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-2.281, 7.746]

Aggreation output shape: torch.Size([1, 16, 128, 128]), range: [-2.281, 7.746]
After third blocks - x3 shape: torch.Size([1, 16, 128, 128]), range: [-2.281, 7.746]

SPP Input shape: torch.Size([1, 16, 128, 128]), range: [-2.281, 7.746]

ConvLayer Input shape: torch.Size([1, 16, 32, 32]), range: [-1.343, 4.356]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-1.250, 2.233]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-0.313, 2.233]
SPP level 0 output shape: torch.Size([1, 16, 128, 128]), range: [-0.287, 1.933]

ConvLayer Input shape: torch.Size([1, 16, 16, 16]), range: [-0.632, 1.957]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-1.046, 0.892]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-0.262, 0.892]
SPP level 1 output shape: torch.Size([1, 16, 128, 128]), range: [-0.242, 0.868]

ConvLayer Input shape: torch.Size([1, 16, 8, 8]), range: [-0.240, 1.103]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.609, 0.666]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.152, 0.666]
SPP level 2 output shape: torch.Size([1, 16, 128, 128]), range: [-0.150, 0.661]

ConvLayer Input shape: torch.Size([1, 16, 4, 4]), range: [0.036, 0.620]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.460, 0.478]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.115, 0.478]
SPP level 3 output shape: torch.Size([1, 16, 128, 128]), range: [-0.115, 0.478]

SPP output length: 4, range: [-0.287, 1.933]
SPP level 0 output shape: torch.Size([1, 16, 128, 128]), range: [-0.287, 1.933]
SPP level 1 output shape: torch.Size([1, 16, 128, 128]), range: [-0.242, 0.868]
SPP level 2 output shape: torch.Size([1, 16, 128, 128]), range: [-0.150, 0.661]
SPP level 3 output shape: torch.Size([1, 16, 128, 128]), range: [-0.115, 0.478]
SPP level 4 output shape: torch.Size([1, 16, 128, 128]), range: [-2.281, 7.746]

ConvLayer Input shape: torch.Size([1, 80, 128, 128]), range: [-2.281, 7.746]

ConvLayer out shape: torch.Size([1, 6, 128, 128]), range: [-1.030, 1.043]

ConvLayer out shape: torch.Size([1, 6, 128, 128]), range: [-0.258, 1.043]

SPP output shape: torch.Size([1, 6, 128, 128]), range: [-0.258, 1.043]
DetailRestorer output shape: torch.Size([1, 6, 128, 128]), range: [-0.258, 1.043]
DetailRestorer 1 output shape: torch.Size([1, 6, 128, 128]), range: [-0.258, 1.043]
Prior down 1 shape: torch.Size([1, 6, 128, 128]), range: [-2.333, 1.537]
Down 2 output shape: torch.Size([1, 12, 64, 64]), range: [-0.439, 0.500]

DetailRestorer Input shape: torch.Size([1, 12, 64, 64]), range: [-0.439, 0.500]

OverlapPatchEmbed Input shape: torch.Size([1, 12, 64, 64]), range: [-0.439, 0.500]

OverlapPatchEmbed output shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]
After embed shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]
After body shape: torch.Size([1, 16, 64, 64]), range: [-0.065, 0.051]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.065, 0.051]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.065, 0.051]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.065, 0.051]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-0.065, 0.051]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-0.065, 0.051]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-0.065, 0.051]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.018, 0.012]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.018, 0.012]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.031, 0.026]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.031, 0.026]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.031, 0.026]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.005, 0.005]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.063, 0.052]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.013, 0.052]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-0.268, 0.200]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.076, -0.001]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.001, 0.011]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-3.254, 3.278]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.254, 3.278]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.254, 3.278]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-3.254, 3.278]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-1.891, 2.005]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.361, 1.385]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.361, 1.385]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.361, 1.372]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.163, 1.385]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-0.699, 1.071]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.184, 0.273]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.276, 0.230]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.276, 0.230]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.076, -0.001]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.001, 0.011]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-3.254, 3.278]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.254, 3.278]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-3.254, 3.278]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.602, 1.890]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.602, 1.890]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-2.602, 1.890]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.802, 1.823]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.694, 3.129]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-0.947, 0.849]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-0.947, 0.849]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.267, 0.204]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 2.413]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]
After block1_1 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]
After body shape: torch.Size([1, 16, 64, 64]), range: [-0.660, 0.592]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.660, 0.592]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.660, 0.592]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.660, 0.592]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-0.660, 0.592]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-0.660, 0.592]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-0.660, 0.592]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.236, 0.277]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.236, 0.277]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.112, 0.074]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.112, 0.074]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.112, 0.074]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.025, 0.021]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.669, 0.574]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.134, 0.574]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-0.383, 4.707]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.125, 0.893]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.016, 2.027]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.929, 3.701]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.929, 3.701]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.929, 3.701]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-1.929, 3.701]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.478, 2.393]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.682, 1.752]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.682, 1.752]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.593, 1.752]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.682, 1.490]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.458, 1.427]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.336, 0.326]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.272, 0.306]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.272, 0.306]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.125, 0.893]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.016, 2.027]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.929, 3.701]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.929, 3.701]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.929, 3.701]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.181, 2.220]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.181, 2.220]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-2.151, 2.100]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-2.181, 2.220]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-3.184, 1.860]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-1.141, 0.937]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-1.141, 0.937]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.688]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 51.583]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.549]
After block1_2 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.549]

Aggreation Input shape: torch.Size([1, 32, 64, 64]), range: [-0.278, 4.688]

SelfAttention Input shape: torch.Size([1, 32, 64, 64]), range: [-0.278, 4.688]

SelfAttention Input shape: torch.Size([1, 32, 64, 64]), range: [-0.278, 4.688]

SelfAttention N: 1, C: 32, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 32]), range: [0.200, 0.206]

SelfAttention out shape: torch.Size([1, 4]), range: [0.000, 0.223]

SelfAttention out shape: torch.Size([1, 32, 1, 1]), range: [0.405, 0.643]

SelfAttention output shape: torch.Size([1, 32, 64, 64]), range: [-0.179, 2.754]

ConvLayer Input shape: torch.Size([1, 32, 64, 64]), range: [-0.179, 2.754]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-0.848, 0.944]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-4.345, 4.408]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]

Aggreation output shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]
After first blocks - x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]
After body shape: torch.Size([1, 16, 64, 64]), range: [-0.875, 0.869]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.875, 0.869]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.875, 0.869]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.875, 0.869]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-0.875, 0.869]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-0.875, 0.869]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-0.875, 0.869]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.598, 0.252]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.598, 0.252]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.212, 0.203]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.212, 0.203]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.212, 0.203]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.025, 0.044]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.833, 0.878]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.167, 0.878]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-1.055, 4.389]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.134, 1.083]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.020, 1.909]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.312, 3.743]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.312, 3.743]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.312, 3.743]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-2.312, 3.743]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.169, 2.108]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.919, 1.624]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.919, 1.624]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.543, 1.545]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.919, 1.624]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.249, 1.557]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.257, 0.271]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.304, 0.281]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.304, 0.281]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.134, 1.083]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.020, 1.909]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.312, 3.743]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.312, 3.743]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.312, 3.743]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.274, 2.308]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.274, 2.308]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-2.274, 2.148]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.911, 2.308]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.805, 2.521]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-1.144, 1.031]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-1.144, 1.031]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-1.086, 4.408]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 68.386]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]
After block2_1 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]
After body shape: torch.Size([1, 16, 64, 64]), range: [-0.651, 0.875]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.651, 0.875]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.651, 0.875]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.651, 0.875]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-0.651, 0.875]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-0.651, 0.875]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-0.651, 0.875]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.193, 0.251]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.193, 0.251]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.101, 0.133]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.101, 0.133]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.101, 0.133]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.011, 0.030]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.656, 0.864]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.131, 0.864]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-0.370, 5.201]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.124, 1.449]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.014, 2.546]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.813, 3.683]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.813, 3.683]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.813, 3.683]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-1.813, 3.683]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.160, 2.201]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.850, 1.798]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.850, 1.798]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.640, 1.798]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.850, 1.377]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.810, 1.186]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.129, 0.137]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.261, 0.236]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.261, 0.236]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.124, 1.449]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.014, 2.546]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.813, 3.683]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.813, 3.683]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.813, 3.683]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.218, 2.052]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.218, 2.052]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-2.218, 1.888]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-2.068, 2.052]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.479, 2.321]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-1.011, 0.815]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-1.011, 0.815]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 4.980]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 89.271]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.085]
After block2_2 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.085]

Aggreation Input shape: torch.Size([1, 48, 64, 64]), range: [-1.086, 6.085]

SelfAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.086, 6.085]

SelfAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.086, 6.085]

SelfAttention N: 1, C: 48, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 48]), range: [0.191, 0.300]

SelfAttention out shape: torch.Size([1, 6]), range: [0.000, 0.335]

SelfAttention out shape: torch.Size([1, 48, 1, 1]), range: [0.373, 0.628]

SelfAttention output shape: torch.Size([1, 48, 64, 64]), range: [-0.543, 3.670]

ConvLayer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.543, 3.670]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-0.981, 1.438]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-5.788, 5.967]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]

Aggreation output shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]
After second blocks - x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]
After body shape: torch.Size([1, 16, 64, 64]), range: [-1.344, 0.808]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.344, 0.808]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.344, 0.808]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.344, 0.808]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-1.344, 0.808]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-1.344, 0.808]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-1.344, 0.808]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.393, 0.226]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.393, 0.226]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.273, 0.201]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.273, 0.201]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.273, 0.201]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.023, 0.042]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-1.351, 0.823]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.270, 0.823]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-1.462, 6.455]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.136, 1.591]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.023, 3.719]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.211, 3.738]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.211, 3.738]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.211, 3.738]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-2.211, 3.738]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.076, 2.297]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.646, 1.788]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.646, 1.788]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.556, 1.788]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.646, 1.347]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.710, 1.191]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.306, 0.323]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.284, 0.300]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.284, 0.300]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.136, 1.591]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.023, 3.719]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.211, 3.738]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.211, 3.738]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.211, 3.738]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.137, 2.202]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.137, 2.202]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-2.029, 2.202]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-2.137, 2.087]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.786, 3.022]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-1.333, 1.257]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-1.333, 1.257]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-1.447, 5.967]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 88.822]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]
After block3_1 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]
After body shape: torch.Size([1, 16, 64, 64]), range: [-1.182, 1.127]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.182, 1.127]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.182, 1.127]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.182, 1.127]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-1.182, 1.127]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-1.182, 1.127]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-1.182, 1.127]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.177, 0.581]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.177, 0.581]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.099, 0.109]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.099, 0.109]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.099, 0.109]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.018, 0.015]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-1.176, 1.110]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.235, 1.110]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-0.446, 6.846]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.137, 1.409]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.013, 4.813]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.196, 3.821]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.196, 3.821]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.196, 3.821]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-2.196, 3.821]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.263, 2.046]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.824, 1.763]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.824, 1.763]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.720, 1.619]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.824, 1.763]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.103, 1.266]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.230, 0.416]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.296, 0.293]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.296, 0.293]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.137, 1.409]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.013, 4.813]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.196, 3.821]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.196, 3.821]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.196, 3.821]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-1.946, 2.187]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.946, 2.187]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.895, 2.096]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.946, 2.187]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.819, 2.465]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-1.184, 0.948]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-1.184, 0.948]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 6.242]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 120.121]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 7.942]
After block3_2 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 7.942]

Aggreation Input shape: torch.Size([1, 64, 64, 64]), range: [-1.447, 7.942]

SelfAttention Input shape: torch.Size([1, 64, 64, 64]), range: [-1.447, 7.942]

SelfAttention Input shape: torch.Size([1, 64, 64, 64]), range: [-1.447, 7.942]

SelfAttention N: 1, C: 64, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 64]), range: [0.151, 0.300]

SelfAttention out shape: torch.Size([1, 8]), range: [0.000, 0.104]

SelfAttention out shape: torch.Size([1, 64, 1, 1]), range: [0.403, 0.602]

SelfAttention output shape: torch.Size([1, 64, 64, 64]), range: [-0.840, 4.463]

ConvLayer Input shape: torch.Size([1, 64, 64, 64]), range: [-0.840, 4.463]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-1.077, 1.382]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-5.456, 7.281]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-1.364, 7.281]

Aggreation output shape: torch.Size([1, 16, 64, 64]), range: [-1.364, 7.281]
After third blocks - x3 shape: torch.Size([1, 16, 64, 64]), range: [-1.364, 7.281]

SPP Input shape: torch.Size([1, 16, 64, 64]), range: [-1.364, 7.281]

ConvLayer Input shape: torch.Size([1, 16, 16, 16]), range: [-0.705, 2.808]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-2.080, 2.263]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-0.520, 2.263]
SPP level 0 output shape: torch.Size([1, 16, 64, 64]), range: [-0.431, 2.137]

ConvLayer Input shape: torch.Size([1, 16, 8, 8]), range: [-0.268, 1.572]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.992, 0.858]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.248, 0.858]
SPP level 1 output shape: torch.Size([1, 16, 64, 64]), range: [-0.237, 0.824]

ConvLayer Input shape: torch.Size([1, 16, 4, 4]), range: [0.021, 0.814]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.491, 0.562]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.123, 0.562]
SPP level 2 output shape: torch.Size([1, 16, 64, 64]), range: [-0.123, 0.562]

ConvLayer Input shape: torch.Size([1, 16, 2, 2]), range: [0.106, 0.448]

ConvLayer out shape: torch.Size([1, 16, 2, 2]), range: [-0.613, 0.513]

ConvLayer out shape: torch.Size([1, 16, 2, 2]), range: [-0.153, 0.513]
SPP level 3 output shape: torch.Size([1, 16, 64, 64]), range: [-0.153, 0.513]

SPP output length: 4, range: [-0.431, 2.137]
SPP level 0 output shape: torch.Size([1, 16, 64, 64]), range: [-0.431, 2.137]
SPP level 1 output shape: torch.Size([1, 16, 64, 64]), range: [-0.237, 0.824]
SPP level 2 output shape: torch.Size([1, 16, 64, 64]), range: [-0.123, 0.562]
SPP level 3 output shape: torch.Size([1, 16, 64, 64]), range: [-0.153, 0.513]
SPP level 4 output shape: torch.Size([1, 16, 64, 64]), range: [-1.364, 7.281]

ConvLayer Input shape: torch.Size([1, 80, 64, 64]), range: [-1.364, 7.281]

ConvLayer out shape: torch.Size([1, 12, 64, 64]), range: [-1.261, 1.433]

ConvLayer out shape: torch.Size([1, 12, 64, 64]), range: [-0.315, 1.433]

SPP output shape: torch.Size([1, 12, 64, 64]), range: [-0.315, 1.433]
DetailRestorer output shape: torch.Size([1, 12, 64, 64]), range: [-0.315, 1.433]
DetailRestorer 2 output shape: torch.Size([1, 12, 64, 64]), range: [-0.315, 1.433]
Prior down 2 shape: torch.Size([1, 12, 64, 64]), range: [-0.824, 0.916]

FeatureContextualizer Input shape: torch.Size([1, 12, 64, 64]), range: [-0.315, 1.433]
FeatureContextualizer Prior input shape: torch.Size([1, 12, 64, 64]), range: [-0.824, 0.916]

OverlapPatchEmbed Input shape: torch.Size([1, 12, 64, 64]), range: [-0.315, 1.433]

OverlapPatchEmbed output shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]

OverlapPatchEmbed Input shape: torch.Size([1, 12, 64, 64]), range: [-0.824, 0.916]

OverlapPatchEmbed output shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
After embed shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.724, 0.558]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.724, 0.558]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.334, 4.332]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.334, 4.332]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.909, 0.613]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.909, 0.613]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.908, 4.330]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.908, 4.330]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.908, 4.330]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.908, 4.330]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-3.908, 4.330]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.646, 2.145]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-2.646, 1.858]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.882, 1.542]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.882, 1.542]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.646, 1.858]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.506, 2.145]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.061, 0.080]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.065, 0.074]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.887, 0.911]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.007, 0.050]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.215, 0.145]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.215, 0.145]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.211, 0.174]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.900, 0.670]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.900, 0.670]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.900, 0.670]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.900, 0.670]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.900, 0.670]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.900, 0.670]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.667, 3.788]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.667, 3.788]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.667, 3.788]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.667, 3.788]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-3.667, 3.788]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.422, 2.334]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.851, 1.803], [-2.037, 1.701]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.559, 0.754]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.335, 0.271]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.857, 0.700]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.909, 0.613]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.909, 0.613]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.908, 4.330]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.908, 4.330]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.908, 4.330]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.908, 4.330]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.724, 0.558]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.724, 0.558]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.334, 4.332]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.334, 4.332]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-3.908, 4.330]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-1.934, 2.004]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.664, 2.004]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.003, 2.240]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.003, 2.240]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.664, 2.004]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.934, 1.651]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.074, 0.068]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.064, 0.064]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.956, 0.924]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.006, 0.049]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.252, 0.116]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.252, 0.116]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.182, 0.196]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.772, 0.617]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.772, 0.617]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.772, 0.617]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.772, 0.617]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.772, 0.617]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.772, 0.617]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.309, 4.339]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.309, 4.339]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.309, 4.339]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.309, 4.339]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-4.309, 4.339]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.336, 2.608]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.892, 2.600], [-1.887, 2.817]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-2.799, 2.244]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.364, 0.403]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.748, 0.712]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.909, 0.613]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.909, 0.613]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.909, 0.613]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.908, 4.330]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.908, 4.330]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.908, 4.330]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.908, 4.330]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-3.908, 4.330]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-2.485, 2.132]
Q shape: torch.Size([1, 48, 64, 64]), range: [-2.187, 1.672]
K shape: torch.Size([1, 48, 64, 64]), range: [-2.485, 1.788]
V shape: torch.Size([1, 48, 64, 64]), range: [-1.941, 2.132]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.187, 1.672]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.485, 1.788]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.941, 2.132]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.063, 0.068]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.068, 0.069]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.877, 0.858]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.008, 0.046]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.192, 0.184]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.192, 0.184]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.366, 0.282]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.957, 0.692]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.957, 0.692]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.957, 0.692]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.957, 0.692]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.957, 0.692]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.957, 0.692]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.562, 3.224]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.562, 3.224]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.562, 3.224]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.562, 3.224]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-3.562, 3.224]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.270, 2.385]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.017, 1.709], [-1.667, 1.727]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.885, 1.185]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.237, 0.270]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.989, 0.680]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.278, 18.308]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 7.797]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 7.797]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.408, 5.714]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.408, 5.714]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 7.797]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 7.797]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.408, 5.714]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.408, 5.714]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.135, 2.212]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-2.135, 1.983]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.018, 2.205]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.018, 2.205]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.135, 1.983]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.081, 2.212]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.074, 0.071]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.067, 0.066]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.640, 0.614]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.010, 0.037]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.257, 0.205]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.257, 0.205]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.374, 0.257]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.621, 7.902]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.621, 7.902]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.621, 7.902]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.621, 7.902]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.621, 7.902]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.621, 7.902]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.803, 5.706]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.803, 5.706]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.803, 5.706]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.803, 5.706]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-1.803, 5.706]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.701, 2.629]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.113, 1.813], [-1.881, 1.975]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.284, 1.524]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.300, 0.293]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.774, 7.882]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 7.797]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 7.797]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.408, 5.714]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.408, 5.714]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 7.797]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 7.797]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.408, 5.714]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.408, 5.714]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.304, 2.281]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-2.304, 2.281]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.035, 2.047]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.035, 2.047]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.304, 2.281]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.084, 2.013]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.070, 0.069]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.067, 0.066]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.634, 0.644]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.010, 0.039]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.238, 0.171]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.238, 0.171]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.279, 0.219]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.530, 7.882]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.530, 7.882]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.530, 7.882]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.530, 7.882]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.530, 7.882]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.530, 7.882]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.737, 5.665]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.737, 5.665]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.737, 5.665]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.737, 5.665]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-1.737, 5.665]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.740, 2.523]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.413, 2.317], [-1.962, 2.053]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.419, 1.769]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.326, 0.277]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.617, 7.949]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 7.797]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 7.797]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 7.797]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.408, 5.714]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.408, 5.714]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.408, 5.714]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-1.909, 1.969]
Q shape: torch.Size([1, 48, 64, 64]), range: [-1.814, 1.969]
K shape: torch.Size([1, 48, 64, 64]), range: [-1.909, 1.958]
V shape: torch.Size([1, 48, 64, 64]), range: [-1.861, 1.929]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.814, 1.969]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.909, 1.958]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.861, 1.929]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.068, 0.076]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.062, 0.065]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.608, 0.664]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.011, 0.038]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.256, 0.102]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.256, 0.102]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.440, 0.301]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.628, 7.655]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.628, 7.655]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.628, 7.655]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.628, 7.655]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.628, 7.655]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.628, 7.655]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.028, 5.718]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.028, 5.718]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.028, 5.718]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.028, 5.718]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.028, 5.718]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.594, 2.611]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.296, 1.921], [-1.810, 2.223]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.794, 1.615]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.308, 0.302]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.647, 7.640]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.278, 300.676]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.057]

Aggreation Input shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 11.057]

SelfAttention Input shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 11.057]

SelfAttention Input shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 11.057]

SelfAttention N: 1, C: 96, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 96]), range: [0.135, 0.206]

SelfAttention out shape: torch.Size([1, 12]), range: [0.000, 0.220]

SelfAttention out shape: torch.Size([1, 96, 1, 1]), range: [0.422, 0.582]

SelfAttention output shape: torch.Size([1, 96, 64, 64]), range: [-0.162, 6.097]

ConvLayer Input shape: torch.Size([1, 96, 64, 64]), range: [-0.162, 6.097]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-2.737, 2.841]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-11.098, 10.840]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]

Aggreation output shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]
After first blocks - x1 shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.724, 0.558]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.724, 0.558]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.334, 4.332]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.334, 4.332]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.775, 10.840]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.775, 10.840]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.352, 5.309]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.352, 5.309]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.352, 5.309]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.352, 5.309]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.352, 5.309]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.061, 2.467]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.982, 2.230]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.810, 2.020]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.810, 2.020]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.982, 2.230]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.061, 2.467]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.070, 0.066]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.074, 0.067]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.808, 0.793]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.008, 0.041]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.219, 0.252]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.219, 0.252]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.235, 0.275]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-2.700, 10.945]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.700, 10.945]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.700, 10.945]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.700, 10.945]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.700, 10.945]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.700, 10.945]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.403, 5.292]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.403, 5.292]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.403, 5.292]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.403, 5.292]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.403, 5.292]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.749, 2.545]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.292, 2.294], [-2.049, 2.376]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.851, 1.864]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.362, 0.324]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-2.780, 10.815]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.775, 10.840]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.775, 10.840]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.352, 5.309]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.352, 5.309]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.352, 5.309]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.352, 5.309]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.724, 0.558]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.724, 0.558]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.724, 0.558]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-4.334, 4.332]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-4.334, 4.332]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.352, 5.309]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.334, 4.332]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-1.918, 2.333]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.453, 2.333]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.030, 2.291]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.030, 2.291]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.453, 2.333]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.918, 1.725]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.080, 0.072]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.067, 0.070]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.779, 0.804]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.008, 0.040]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.188, 0.262]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.188, 0.262]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.183, 0.276]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.659, 0.585]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.659, 0.585]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.659, 0.585]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.659, 0.585]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.659, 0.585]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.659, 0.585]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.969, 4.009]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.969, 4.009]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.969, 4.009]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.969, 4.009]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-3.969, 4.009]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.402, 2.677]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.772, 1.888], [-1.714, 1.913]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.299, 1.485]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.281, 0.312]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.686, 0.647]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.775, 10.840]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.775, 10.840]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.775, 10.840]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.352, 5.309]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.352, 5.309]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.352, 5.309]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.352, 5.309]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.352, 5.309]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-2.130, 2.202]
Q shape: torch.Size([1, 48, 64, 64]), range: [-2.130, 1.613]
K shape: torch.Size([1, 48, 64, 64]), range: [-1.952, 1.568]
V shape: torch.Size([1, 48, 64, 64]), range: [-1.971, 2.202]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.130, 1.613]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.952, 1.568]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.971, 2.202]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.066, 0.065]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.067, 0.066]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.620, 0.683]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.011, 0.039]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.177, 0.237]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.177, 0.237]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.417, 0.362]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-2.808, 10.742]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.808, 10.742]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.808, 10.742]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.808, 10.742]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.808, 10.742]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.808, 10.742]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.260, 5.255]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.260, 5.255]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.260, 5.255]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.260, 5.255]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.260, 5.255]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.513, 2.664]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.918, 2.023], [-2.038, 1.854]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.669, 1.771]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.277, 0.319]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-2.798, 10.655]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.278, 408.539]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.983]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.983]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.840, 6.146]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.840, 6.146]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.983]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.983]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.840, 6.146]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.840, 6.146]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.399, 2.082]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-2.399, 2.082]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.737, 1.912]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.737, 1.912]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.399, 2.082]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.932, 2.000]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.066, 0.074]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.067, 0.070]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.786, 0.795]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.008, 0.045]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.169, 0.204]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.169, 0.204]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.220, 0.268]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.482, 12.014]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.482, 12.014]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.482, 12.014]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.482, 12.014]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.482, 12.014]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.482, 12.014]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.376, 6.097]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.376, 6.097]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.376, 6.097]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.376, 6.097]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.376, 6.097]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.801, 2.547]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.964, 2.219], [-2.202, 2.149]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.345, 1.738]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.291, 0.300]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.600, 12.009]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.983]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.983]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.840, 6.146]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.840, 6.146]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.983]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.983]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.840, 6.146]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.840, 6.146]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.227, 2.347]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-2.227, 2.347]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.015, 2.186]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.015, 2.186]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.227, 2.347]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.147, 2.125]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.078, 0.066]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.070, 0.066]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.781, 0.729]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.009, 0.039]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.204, 0.211]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.204, 0.211]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.244, 0.277]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.481, 11.830]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.481, 11.830]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.481, 11.830]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.481, 11.830]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.481, 11.830]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.481, 11.830]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.649, 6.141]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.649, 6.141]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.649, 6.141]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.649, 6.141]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.649, 6.141]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.696, 2.500]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.039, 2.116], [-2.658, 1.887]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.529, 1.892]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.332, 0.270]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.639, 11.862]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.983]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.983]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.983]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.840, 6.146]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.840, 6.146]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.840, 6.146]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-2.112, 1.854]
Q shape: torch.Size([1, 48, 64, 64]), range: [-1.835, 1.817]
K shape: torch.Size([1, 48, 64, 64]), range: [-1.926, 1.699]
V shape: torch.Size([1, 48, 64, 64]), range: [-2.112, 1.854]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.835, 1.817]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.926, 1.699]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.112, 1.854]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.063, 0.073]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.065, 0.066]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.798, 0.716]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.008, 0.041]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.154, 0.227]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.154, 0.227]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.390, 0.353]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.523, 11.842]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.523, 11.842]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.523, 11.842]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.523, 11.842]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.523, 11.842]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.523, 11.842]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.263, 6.020]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.263, 6.020]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.263, 6.020]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.263, 6.020]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.263, 6.020]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.498, 2.423]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.981, 1.804], [-2.179, 2.282]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.205, 1.826]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.313, 0.272]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.615, 11.813]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.278, 823.593]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 12.874]

Aggreation Input shape: torch.Size([1, 144, 64, 64]), range: [-2.775, 12.874]

SelfAttention Input shape: torch.Size([1, 144, 64, 64]), range: [-2.775, 12.874]

SelfAttention Input shape: torch.Size([1, 144, 64, 64]), range: [-2.775, 12.874]

SelfAttention N: 1, C: 144, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 144]), range: [0.093, 0.296]

SelfAttention out shape: torch.Size([1, 18]), range: [0.000, 0.261]

SelfAttention out shape: torch.Size([1, 144, 1, 1]), range: [0.412, 0.579]

SelfAttention output shape: torch.Size([1, 144, 64, 64]), range: [-1.393, 7.228]

ConvLayer Input shape: torch.Size([1, 144, 64, 64]), range: [-1.393, 7.228]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-4.239, 5.016]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-12.239, 12.547]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-3.060, 12.547]

Aggreation output shape: torch.Size([1, 48, 64, 64]), range: [-3.060, 12.547]
After second blocks - x2 shape: torch.Size([1, 48, 64, 64]), range: [-3.060, 12.547]

SPP Input shape: torch.Size([1, 48, 64, 64]), range: [-3.060, 12.547]

ConvLayer Input shape: torch.Size([1, 48, 16, 16]), range: [-2.089, 8.620]

ConvLayer out shape: torch.Size([1, 48, 16, 16]), range: [-4.429, 4.893]

ConvLayer out shape: torch.Size([1, 48, 16, 16]), range: [-1.107, 4.893]
SPP level 0 output shape: torch.Size([1, 48, 64, 64]), range: [-0.907, 4.268]

ConvLayer Input shape: torch.Size([1, 48, 8, 8]), range: [-1.098, 4.329]

ConvLayer out shape: torch.Size([1, 48, 8, 8]), range: [-2.635, 1.998]

ConvLayer out shape: torch.Size([1, 48, 8, 8]), range: [-0.659, 1.998]
SPP level 1 output shape: torch.Size([1, 48, 64, 64]), range: [-0.589, 1.774]

ConvLayer Input shape: torch.Size([1, 48, 4, 4]), range: [-0.173, 1.207]

ConvLayer out shape: torch.Size([1, 48, 4, 4]), range: [-0.686, 0.752]

ConvLayer out shape: torch.Size([1, 48, 4, 4]), range: [-0.171, 0.752]
SPP level 2 output shape: torch.Size([1, 48, 64, 64]), range: [-0.171, 0.752]

ConvLayer Input shape: torch.Size([1, 48, 2, 2]), range: [-0.038, 0.421]

ConvLayer out shape: torch.Size([1, 48, 2, 2]), range: [-0.361, 0.305]

ConvLayer out shape: torch.Size([1, 48, 2, 2]), range: [-0.090, 0.305]
SPP level 3 output shape: torch.Size([1, 48, 64, 64]), range: [-0.090, 0.305]

SPP output length: 4, range: [-0.907, 4.268]
SPP level 0 output shape: torch.Size([1, 48, 64, 64]), range: [-0.907, 4.268]
SPP level 1 output shape: torch.Size([1, 48, 64, 64]), range: [-0.589, 1.774]
SPP level 2 output shape: torch.Size([1, 48, 64, 64]), range: [-0.171, 0.752]
SPP level 3 output shape: torch.Size([1, 48, 64, 64]), range: [-0.090, 0.305]
SPP level 4 output shape: torch.Size([1, 48, 64, 64]), range: [-3.060, 12.547]

ConvLayer Input shape: torch.Size([1, 240, 64, 64]), range: [-3.060, 12.547]

ConvLayer out shape: torch.Size([1, 24, 64, 64]), range: [-3.291, 3.314]

ConvLayer out shape: torch.Size([1, 24, 64, 64]), range: [-0.823, 3.314]

SPP output shape: torch.Size([1, 24, 64, 64]), range: [-0.823, 3.314]
FeatureContextualizer output shape: torch.Size([1, 24, 64, 64]), range: [-0.823, 3.314]
FeatureContextualizer output shape: torch.Size([1, 24, 64, 64]), range: [-0.823, 3.314]

ScaleHarmonizer Input shape: torch.Size([1, 24, 64, 64]), range: [-0.823, 3.314]

Condition Input shape: torch.Size([1, 24, 64, 64]), range: [-0.823, 3.314]
Condition conv1 output shape: torch.Size([1, 32, 30, 30]), range: [0.000, 0.936]
Condition conv2 output shape: torch.Size([1, 32, 15, 15]), range: [0.000, 0.351]
Condition conv3 output shape: torch.Size([1, 32, 8, 8]), range: [0.000, 0.123]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.069]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.069]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.172, 0.184]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.185, 0.185]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.207, 0.191]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.189, 0.198]
ScaleHarmonizer Scale3 shape: torch.Size([1, 12]), range: [-0.173, 0.162]
ScaleHarmonizer Shift3 shape: torch.Size([1, 12]), range: [-0.187, 0.145]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 64, 64]), range: [-1.594, 1.400]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 64, 64]), range: [-1.444, 1.589]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 64, 64]), range: [0.000, 1.589]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 64, 64]), range: [-0.599, 0.607]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 64, 64]), range: [-0.705, 0.517]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 64, 64]), range: [0.000, 0.517]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 12, 64, 64]), range: [-0.213, 0.340]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 12, 64, 64]), range: [-0.393, 0.322]
First fusion output shape: torch.Size([1, 12, 64, 64]), range: [-0.393, 0.322]
Upsampling 1 output shape: torch.Size([1, 6, 128, 128]), range: [-0.578, 0.752]
Fusion 1 input shape: torch.Size([1, 12, 128, 128]), range: [-0.578, 1.043]

ScaleHarmonizer Input shape: torch.Size([1, 12, 128, 128]), range: [-0.578, 1.043]

Condition Input shape: torch.Size([1, 12, 128, 128]), range: [-0.578, 1.043]
Condition conv1 output shape: torch.Size([1, 32, 62, 62]), range: [0.000, 0.411]
Condition conv2 output shape: torch.Size([1, 32, 31, 31]), range: [0.000, 0.192]
Condition conv3 output shape: torch.Size([1, 32, 16, 16]), range: [0.000, 0.096]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.061]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.061]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.188, 0.192]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.183, 0.162]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.174, 0.168]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.183, 0.192]
ScaleHarmonizer Scale3 shape: torch.Size([1, 6]), range: [-0.174, 0.103]
ScaleHarmonizer Shift3 shape: torch.Size([1, 6]), range: [-0.158, 0.183]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 128, 128]), range: [-0.924, 0.621]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 128, 128]), range: [-0.939, 0.771]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 128, 128]), range: [0.000, 0.771]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 128, 128]), range: [-0.347, 0.469]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 128, 128]), range: [-0.470, 0.491]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 128, 128]), range: [0.000, 0.491]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 6, 128, 128]), range: [-0.212, 0.194]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 6, 128, 128]), range: [-0.261, 0.327]
Fusion 1 output shape: torch.Size([1, 6, 128, 128]), range: [-0.261, 0.327]
Upsampling 0 output shape: torch.Size([1, 3, 256, 256]), range: [-0.130, 0.230]
Fusion 0 input shape: torch.Size([1, 6, 256, 256]), range: [-0.439, 1.326]

ScaleHarmonizer Input shape: torch.Size([1, 6, 256, 256]), range: [-0.439, 1.326]

Condition Input shape: torch.Size([1, 6, 256, 256]), range: [-0.439, 1.326]
Condition conv1 output shape: torch.Size([1, 32, 126, 126]), range: [0.000, 0.527]
Condition conv2 output shape: torch.Size([1, 32, 63, 63]), range: [0.000, 0.139]
Condition conv3 output shape: torch.Size([1, 32, 32, 32]), range: [0.000, 0.105]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.074]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.074]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.188, 0.163]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.183, 0.191]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.185, 0.207]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.199, 0.184]
ScaleHarmonizer Scale3 shape: torch.Size([1, 3]), range: [-0.002, 0.129]
ScaleHarmonizer Shift3 shape: torch.Size([1, 3]), range: [-0.039, 0.224]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 256, 256]), range: [-1.112, 0.905]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-0.806, 0.968]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 0.968]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 256, 256]), range: [-0.545, 0.647]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-0.612, 0.660]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 0.660]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 3, 256, 256]), range: [-0.135, 0.157]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 3, 256, 256]), range: [-0.174, 0.401]
Fusion 0 output shape: torch.Size([1, 3, 256, 256]), range: [-0.174, 0.401]
Final concatenation shape: torch.Size([1, 9, 256, 256]), range: [torch.Size([1, 9, 256, 256]), range: [-4.386, 4.279]

ScaleHarmonizer Input shape: torch.Size([1, 9, 256, 256]), range: [-4.386, 4.279]

Condition Input shape: torch.Size([1, 9, 256, 256]), range: [-4.386, 4.279]
Condition conv1 output shape: torch.Size([1, 32, 126, 126]), range: [0.000, 1.940]
Condition conv2 output shape: torch.Size([1, 32, 63, 63]), range: [0.000, 0.685]
Condition conv3 output shape: torch.Size([1, 32, 32, 32]), range: [0.000, 0.283]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.113]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.113]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.201, 0.148]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.199, 0.209]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.180, 0.179]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.231, 0.200]
ScaleHarmonizer Scale3 shape: torch.Size([1, 3]), range: [-0.060, 0.127]
ScaleHarmonizer Shift3 shape: torch.Size([1, 3]), range: [-0.157, 0.010]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 256, 256]), range: [-3.206, 3.338]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-2.995, 3.334]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 3.334]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 256, 256]), range: [-1.634, 1.321]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-1.914, 1.227]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 1.227]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 3, 256, 256]), range: [-0.341, 0.252]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 3, 256, 256]), range: [-0.311, 0.128]
Final output shape: torch.Size([1, 3, 256, 256]), range: [0.423, 0.532]
Model final output shape: torch.Size([1, 3, 256, 256]), range: [0.423, 0.532]

==================================================
Test completed!
Final output shape: torch.Size([1, 3, 256, 256])
==================================================


Running all tests...
=== Running Tests on Model ===

Test: Model Summary

Model Input shape: torch.Size([1, 3, 256, 256]), range: [0.000, 1.000]

ColorBalancePrior Input shape: torch.Size([1, 3, 256, 256]), range: [0.000, 1.000]
--------------------------------------------------
ColorBalancePrior mean shape: torch.Size([1, 1, 256, 256]), range: [0.010, 0.986]
--------------------------------------------------
ColorBalancePrior expanded mean shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]
--------------------------------------------------

NAFBlock Input shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]

LayerNorm2d forward Input shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]

LayerNormFunction forward Input shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [0.010, 0.986]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.000, 0.000]
LayerNormFunction forward normalized shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNormFunction forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNorm2d forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
After norm1 shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
After conv1 shape: torch.Size([1, 6, 256, 256]), range: [-0.526, 0.140]
After conv2 shape: torch.Size([1, 6, 256, 256]), range: [-0.584, 0.620]

SimpleGate Input shape: torch.Size([1, 6, 256, 256]), range: [-0.584, 0.620]
SimpleGate x1 shape: torch.Size([1, 3, 256, 256]), range: [-0.584, 0.325]
SimpleGate x2 shape: torch.Size([1, 3, 256, 256]), range: [-0.442, 0.620]
After sg shape: torch.Size([1, 3, 256, 256]), range: [-0.176, 0.043]
After sca shape: torch.Size([1, 3, 256, 256]), range: [-0.013, 0.066]
After conv3 shape: torch.Size([1, 3, 256, 256]), range: [0.381, 0.590]
After dropout1 shape: torch.Size([1, 3, 256, 256]), range: [0.381, 0.590]
After beta shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]

LayerNorm2d forward Input shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]

LayerNormFunction forward Input shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [0.010, 0.986]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.000, 0.000]
LayerNormFunction forward normalized shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNormFunction forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
LayerNorm2d forward output shape: torch.Size([1, 3, 256, 256]), range: [-0.000, 0.000]
After conv4 shape: torch.Size([1, 6, 256, 256]), range: [-0.453, 0.396]

SimpleGate Input shape: torch.Size([1, 6, 256, 256]), range: [-0.453, 0.396]
SimpleGate x1 shape: torch.Size([1, 3, 256, 256]), range: [-0.453, 0.381]
SimpleGate x2 shape: torch.Size([1, 3, 256, 256]), range: [0.081, 0.396]
After sg shape: torch.Size([1, 3, 256, 256]), range: [-0.179, 0.048]
After conv5 shape: torch.Size([1, 3, 256, 256]), range: [-0.211, 0.195]
After dropout2 shape: torch.Size([1, 3, 256, 256]), range: [-0.211, 0.195]
NAFBlock output shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]
ColorBalancePrior output shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]
--------------------------------------------------
Prior output shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]

PriorGuidedRE Input shape: torch.Size([1, 3, 256, 256]), range: [0.000, 1.000]
PriorGuidedRE Prior input shape: torch.Size([1, 3, 256, 256]), range: [0.010, 0.986]

DetailRestorer Input shape: torch.Size([1, 3, 256, 256]), range: [0.000, 1.000]

OverlapPatchEmbed Input shape: torch.Size([1, 3, 256, 256]), range: [0.000, 1.000]

OverlapPatchEmbed output shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]
After embed shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]
After body shape: torch.Size([1, 16, 256, 256]), range: [-0.168, 0.199]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.168, 0.199]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.168, 0.199]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.168, 0.199]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-0.168, 0.199]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-0.168, 0.199]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-0.168, 0.199]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.087, 0.050]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.087, 0.050]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.036, 0.049]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.036, 0.049]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.036, 0.049]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.007, 0.007]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.173, 0.199]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.035, 0.199]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-1.127, 1.118]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.100, 0.220]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.016, 0.222]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-3.179, 2.940]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.179, 2.940]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.179, 2.940]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-3.179, 2.940]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-1.985, 2.109]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-1.635, 1.604]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.635, 1.604]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.224, 1.242]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.635, 1.604]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.056, 0.943]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.105, 0.168]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.245, 0.250]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.245, 0.250]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.100, 0.220]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.016, 0.222]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-3.179, 2.940]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.179, 2.940]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.179, 2.940]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-1.848, 2.377]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.848, 2.377]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.848, 1.984]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.701, 2.377]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.730, 3.112]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-0.979, 0.981]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-0.979, 0.981]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.120, 1.123]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 14.685]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]
After block1_1 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]
After body shape: torch.Size([1, 16, 256, 256]), range: [-0.568, 0.527]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.568, 0.527]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.568, 0.527]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.568, 0.527]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-0.568, 0.527]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-0.568, 0.527]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-0.568, 0.527]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.246, 0.176]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.246, 0.176]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.123, 0.181]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.123, 0.181]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.123, 0.181]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.024, 0.030]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.563, 0.546]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.113, 0.546]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-0.376, 4.666]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.069, 0.697]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.023, 2.038]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.671, 3.767]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.671, 3.767]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.671, 3.767]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-1.671, 3.767]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.218, 1.909]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-1.302, 1.408]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.302, 1.408]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.220, 1.408]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.302, 1.275]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-0.867, 0.992]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.179, 0.119]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.269, 0.278]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.269, 0.278]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.069, 0.697]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.023, 2.038]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.671, 3.767]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.671, 3.767]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.671, 3.767]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-1.956, 1.992]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.956, 1.992]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.802, 1.992]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.956, 1.989]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.749, 1.967]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-0.873, 0.962]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-0.873, 0.962]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 4.509]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 50.584]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 25.566]
After block1_2 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 25.566]

Aggreation Input shape: torch.Size([1, 32, 256, 256]), range: [-0.278, 25.566]

SelfAttention Input shape: torch.Size([1, 32, 256, 256]), range: [-0.278, 25.566]

SelfAttention Input shape: torch.Size([1, 32, 256, 256]), range: [-0.278, 25.566]

SelfAttention N: 1, C: 32, H: 256, W: 256

SelfAttention out shape: torch.Size([1, 32]), range: [-0.245, 11.708]

SelfAttention out shape: torch.Size([1, 4]), range: [0.000, 1.322]

SelfAttention out shape: torch.Size([1, 32, 1, 1]), range: [0.303, 0.683]

SelfAttention output shape: torch.Size([1, 32, 256, 256]), range: [-0.190, 11.122]

ConvLayer Input shape: torch.Size([1, 32, 256, 256]), range: [-0.190, 11.122]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-3.007, 2.880]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-4.753, 5.005]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]

Aggreation output shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]
After first blocks - x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]
After body shape: torch.Size([1, 16, 256, 256]), range: [-0.998, 0.784]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.998, 0.784]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.998, 0.784]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.998, 0.784]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-0.998, 0.784]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-0.998, 0.784]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-0.998, 0.784]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.392, 0.238]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.392, 0.238]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.158, 0.089]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.158, 0.089]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.158, 0.089]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.021, 0.028]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.001, 0.812]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.200, 0.812]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-1.245, 5.119]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.246, 1.400]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.014, 3.033]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-3.261, 3.824]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.261, 3.824]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.261, 3.824]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-3.261, 3.824]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.344, 2.475]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-2.098, 2.038]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.098, 2.038]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.098, 2.038]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.965, 1.744]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.975, 1.414]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.290, 0.220]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.252, 0.351]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.252, 0.351]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.246, 1.400]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.014, 3.033]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-3.261, 3.824]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.261, 3.824]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-3.261, 3.824]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.073, 2.222]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.073, 2.222]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.993, 2.169]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.073, 2.222]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.445, 2.706]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.083, 1.043]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.083, 1.043]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.188, 5.005]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 82.897]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]
After block2_1 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]
After body shape: torch.Size([1, 16, 256, 256]), range: [-7.228, 7.615]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-7.228, 7.615]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-7.228, 7.615]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-7.228, 7.615]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-7.228, 7.615]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-7.228, 7.615]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-7.228, 7.615]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-2.375, 1.691]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-2.375, 1.691]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-2.561, 2.885]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-2.561, 2.885]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-2.561, 2.885]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.437, 0.453]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-7.019, 7.773]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-1.404, 7.773]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-1.441, 53.798]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [0.276, 11.539]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.374, 275.917]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.278, 3.422]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.278, 3.422]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.278, 3.422]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-1.278, 3.422]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-1.717, 2.371]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-1.439, 1.087]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.439, 1.087]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.082, 0.960]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.439, 1.087]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-0.780, 1.145]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.227, 0.067]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.284, 0.276]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.284, 0.276]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [0.276, 11.539]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.374, 275.917]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.278, 3.422]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.278, 3.422]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.278, 3.422]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-1.773, 1.706]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.773, 1.706]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.773, 1.706]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.758, 1.598]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.734, 1.386]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-0.910, 1.002]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-0.910, 1.002]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 48.425]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 1003.908]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 450.588]
After block2_2 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 450.588]

Aggreation Input shape: torch.Size([1, 48, 256, 256]), range: [-1.188, 450.588]

SelfAttention Input shape: torch.Size([1, 48, 256, 256]), range: [-1.188, 450.588]

SelfAttention Input shape: torch.Size([1, 48, 256, 256]), range: [-1.188, 450.588]

SelfAttention N: 1, C: 48, H: 256, W: 256

SelfAttention out shape: torch.Size([1, 48]), range: [-0.035, 174.541]

SelfAttention out shape: torch.Size([1, 6]), range: [0.000, 21.529]

SelfAttention out shape: torch.Size([1, 48, 1, 1]), range: [0.000, 1.000]

SelfAttention output shape: torch.Size([1, 48, 256, 256]), range: [-1.044, 281.621]

ConvLayer Input shape: torch.Size([1, 48, 256, 256]), range: [-1.044, 281.621]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-29.449, 37.635]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-8.500, 7.235]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]

Aggreation output shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]
After second blocks - x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]
After body shape: torch.Size([1, 16, 256, 256]), range: [-1.747, 1.679]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.747, 1.679]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.747, 1.679]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-1.747, 1.679]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-1.747, 1.679]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-1.747, 1.679]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-1.747, 1.679]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-0.661, 0.121]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-0.661, 0.121]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.133, 0.196]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.133, 0.196]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.133, 0.196]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.033, 0.053]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-1.773, 1.652]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-0.355, 1.652]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-2.065, 7.993]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.138, 2.213]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.006, 9.724]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.895, 3.819]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.895, 3.819]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.895, 3.819]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-2.895, 3.819]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-2.331, 2.235]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-2.021, 2.322]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.021, 2.322]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.021, 1.579]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.870, 2.322]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.635, 1.237]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.243, 0.313]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.301, 0.250]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.301, 0.250]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.138, 2.213]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.006, 9.724]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-2.895, 3.819]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.895, 3.819]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-2.895, 3.819]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.219, 2.407]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.219, 2.407]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-2.219, 2.407]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.102, 2.071]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.478, 2.953]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.339, 1.439]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.339, 1.439]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-2.125, 7.235]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 201.860]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]
After block3_1 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]

QBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]

RCB Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]
After body shape: torch.Size([1, 16, 256, 256]), range: [-13.144, 16.679]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-13.144, 16.679]

ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-13.144, 16.679]
ContextBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-13.144, 16.679]
ContextBlock Input_x shape: torch.Size([1, 16, 256, 256]), range: [-13.144, 16.679]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 65536]), range: [-13.144, 16.679]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 65536]), range: [-13.144, 16.679]
ContextBlock Context mask shape: torch.Size([1, 1, 256, 256]), range: [-1.784, 1.207]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 65536]), range: [-1.784, 1.207]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 65536]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 65536, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-2.220, 2.153]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-2.220, 2.153]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-2.220, 2.153]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.385, 0.575]
ContextBlock output shape: torch.Size([1, 16, 256, 256]), range: [-12.761, 17.183]
After GCNet shape: torch.Size([1, 16, 256, 256]), range: [-2.552, 17.183]
RCB output shape: torch.Size([1, 16, 256, 256]), range: [-2.552, 75.549]

NAFBlock Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.021, 22.836]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.105, 695.267]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.346, 3.832]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.346, 3.832]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.346, 3.832]
After norm1 shape: torch.Size([1, 16, 256, 256]), range: [-1.346, 3.832]
After conv1 shape: torch.Size([1, 32, 256, 256]), range: [-1.948, 1.868]
After conv2 shape: torch.Size([1, 32, 256, 256]), range: [-1.794, 2.268]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-1.794, 2.268]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.599, 1.409]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-1.794, 2.268]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-1.204, 1.019]
After sca shape: torch.Size([1, 16, 256, 256]), range: [-0.201, 0.222]
After conv3 shape: torch.Size([1, 16, 256, 256]), range: [-0.280, 0.279]
After dropout1 shape: torch.Size([1, 16, 256, 256]), range: [-0.280, 0.279]
After beta shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]

LayerNorm2d forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]

LayerNormFunction forward Input shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]
LayerNormFunction forward mean shape: torch.Size([1, 1, 256, 256]), range: [-0.021, 22.836]
LayerNormFunction forward variance shape: torch.Size([1, 1, 256, 256]), range: [0.105, 695.267]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 256, 256]), range: [-1.346, 3.832]
LayerNormFunction forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.346, 3.832]
LayerNorm2d forward output shape: torch.Size([1, 16, 256, 256]), range: [-1.346, 3.832]
After conv4 shape: torch.Size([1, 32, 256, 256]), range: [-2.146, 2.233]

SimpleGate Input shape: torch.Size([1, 32, 256, 256]), range: [-2.146, 2.233]
SimpleGate x1 shape: torch.Size([1, 16, 256, 256]), range: [-1.618, 2.036]
SimpleGate x2 shape: torch.Size([1, 16, 256, 256]), range: [-2.146, 2.233]
After sg shape: torch.Size([1, 16, 256, 256]), range: [-2.106, 1.941]
After conv5 shape: torch.Size([1, 16, 256, 256]), range: [-1.367, 0.983]
After dropout2 shape: torch.Size([1, 16, 256, 256]), range: [-1.367, 0.983]
NAFBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 77.837]
After branches - shapes: x1: torch.Size([1, 16, 256, 256]), x2: torch.Size([1, 16, 256, 256])
After concat shape: torch.Size([1, 64, 256, 256])
After QCNN shape: torch.Size([1, 64, 256, 256]), range: [-0.278, 1868.278]
QBlock output shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 877.602]
After block3_2 shape: torch.Size([1, 16, 256, 256]), range: [-0.278, 877.602]

Aggreation Input shape: torch.Size([1, 64, 256, 256]), range: [-2.125, 877.602]

SelfAttention Input shape: torch.Size([1, 64, 256, 256]), range: [-2.125, 877.602]

SelfAttention Input shape: torch.Size([1, 64, 256, 256]), range: [-2.125, 877.602]

SelfAttention N: 1, C: 64, H: 256, W: 256

SelfAttention out shape: torch.Size([1, 64]), range: [-0.070, 137.224]

SelfAttention out shape: torch.Size([1, 8]), range: [0.000, 16.481]

SelfAttention out shape: torch.Size([1, 64, 1, 1]), range: [0.002, 0.998]

SelfAttention output shape: torch.Size([1, 64, 256, 256]), range: [-2.042, 288.435]

ConvLayer Input shape: torch.Size([1, 64, 256, 256]), range: [-2.042, 288.435]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-53.108, 30.001]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-9.965, 9.497]

ConvLayer out shape: torch.Size([1, 16, 256, 256]), range: [-2.491, 9.497]

Aggreation output shape: torch.Size([1, 16, 256, 256]), range: [-2.491, 9.497]
After third blocks - x3 shape: torch.Size([1, 16, 256, 256]), range: [-2.491, 9.497]

SPP Input shape: torch.Size([1, 16, 256, 256]), range: [-2.491, 9.497]

ConvLayer Input shape: torch.Size([1, 16, 64, 64]), range: [-1.840, 6.786]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-2.726, 2.959]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-0.681, 2.959]
SPP level 0 output shape: torch.Size([1, 16, 256, 256]), range: [-0.619, 2.653]

ConvLayer Input shape: torch.Size([1, 16, 32, 32]), range: [-0.981, 4.622]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-1.956, 1.575]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-0.489, 1.575]
SPP level 1 output shape: torch.Size([1, 16, 256, 256]), range: [-0.448, 1.424]

ConvLayer Input shape: torch.Size([1, 16, 16, 16]), range: [-0.187, 1.824]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-0.875, 1.399]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-0.219, 1.399]
SPP level 2 output shape: torch.Size([1, 16, 256, 256]), range: [-0.214, 1.351]

ConvLayer Input shape: torch.Size([1, 16, 8, 8]), range: [0.006, 0.864]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.530, 0.481]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.132, 0.481]
SPP level 3 output shape: torch.Size([1, 16, 256, 256]), range: [-0.132, 0.477]

SPP output length: 4, range: [-0.619, 2.653]
SPP level 0 output shape: torch.Size([1, 16, 256, 256]), range: [-0.619, 2.653]
SPP level 1 output shape: torch.Size([1, 16, 256, 256]), range: [-0.448, 1.424]
SPP level 2 output shape: torch.Size([1, 16, 256, 256]), range: [-0.214, 1.351]
SPP level 3 output shape: torch.Size([1, 16, 256, 256]), range: [-0.132, 0.477]
SPP level 4 output shape: torch.Size([1, 16, 256, 256]), range: [-2.491, 9.497]

ConvLayer Input shape: torch.Size([1, 80, 256, 256]), range: [-2.491, 9.497]

ConvLayer out shape: torch.Size([1, 3, 256, 256]), range: [-0.727, 1.941]

ConvLayer out shape: torch.Size([1, 3, 256, 256]), range: [-0.182, 1.941]

SPP output shape: torch.Size([1, 3, 256, 256]), range: [-0.182, 1.941]
DetailRestorer output shape: torch.Size([1, 3, 256, 256]), range: [-0.182, 1.941]
First DetailRestorer output shape: torch.Size([1, 3, 256, 256]), range: [-0.182, 1.941]
Down 1 output shape: torch.Size([1, 6, 128, 128]), range: [-0.999, 0.982]

DetailRestorer Input shape: torch.Size([1, 6, 128, 128]), range: [-0.999, 0.982]

OverlapPatchEmbed Input shape: torch.Size([1, 6, 128, 128]), range: [-0.999, 0.982]

OverlapPatchEmbed output shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]
After embed shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]
After body shape: torch.Size([1, 16, 128, 128]), range: [-0.118, 0.147]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.118, 0.147]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.118, 0.147]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.118, 0.147]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-0.118, 0.147]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-0.118, 0.147]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-0.118, 0.147]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.059, 0.012]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.059, 0.012]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.026, 0.017]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.026, 0.017]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.026, 0.017]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.004, 0.003]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.115, 0.147]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.023, 0.147]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-0.582, 0.812]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.071, 0.118]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.001, 0.107]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-3.291, 3.202]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.291, 3.202]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.291, 3.202]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-3.291, 3.202]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.188, 2.546]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.432, 1.896]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.432, 1.896]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.432, 1.845]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.382, 1.896]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.157, 1.377]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.188, 0.311]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.269, 0.271]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.269, 0.271]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.071, 0.118]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.001, 0.107]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-3.291, 3.202]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.291, 3.202]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.291, 3.202]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-1.874, 2.234]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.874, 2.234]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.874, 1.975]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.646, 2.234]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.886, 2.349]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.252, 0.934]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.252, 0.934]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.577, 0.744]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 8.269]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]
After block1_1 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]
After body shape: torch.Size([1, 16, 128, 128]), range: [-0.322, 0.433]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.322, 0.433]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.322, 0.433]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.322, 0.433]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-0.322, 0.433]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-0.322, 0.433]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-0.322, 0.433]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.099, 0.150]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.099, 0.150]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.045, 0.064]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.045, 0.064]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.045, 0.064]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.021, 0.010]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.333, 0.426]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.067, 0.426]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-0.306, 2.892]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.032, 0.627]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.004, 0.681]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.721, 3.464]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.721, 3.464]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.721, 3.464]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-2.721, 3.464]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.377, 2.025]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.461, 2.427]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.461, 2.427]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.152, 2.139]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.461, 2.427]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-0.698, 4.157]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-1.723, 0.212]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.511, 0.441]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.511, 0.441]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.032, 0.627]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.004, 0.681]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.721, 3.464]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.721, 3.464]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.721, 3.464]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-1.986, 1.847]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.986, 1.847]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.928, 1.847]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.986, 1.825]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.731, 1.855]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.102, 0.777]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.102, 0.777]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 2.772]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 35.322]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 17.654]
After block1_2 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 17.654]

Aggreation Input shape: torch.Size([1, 32, 128, 128]), range: [-0.278, 17.654]

SelfAttention Input shape: torch.Size([1, 32, 128, 128]), range: [-0.278, 17.654]

SelfAttention Input shape: torch.Size([1, 32, 128, 128]), range: [-0.278, 17.654]

SelfAttention N: 1, C: 32, H: 128, W: 128

SelfAttention out shape: torch.Size([1, 32]), range: [-0.251, 2.166]

SelfAttention out shape: torch.Size([1, 4]), range: [0.000, 0.181]

SelfAttention out shape: torch.Size([1, 32, 1, 1]), range: [0.386, 0.617]

SelfAttention output shape: torch.Size([1, 32, 128, 128]), range: [-0.167, 7.707]

ConvLayer Input shape: torch.Size([1, 32, 128, 128]), range: [-0.167, 7.707]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-2.196, 2.908]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-14.133, 13.475]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]

Aggreation output shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]
After first blocks - x1 shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]
After body shape: torch.Size([1, 16, 128, 128]), range: [-2.220, 2.997]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.220, 2.997]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.220, 2.997]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.220, 2.997]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-2.220, 2.997]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-2.220, 2.997]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-2.220, 2.997]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.458, 1.214]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.458, 1.214]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.182, 0.191]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.182, 0.191]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.182, 0.191]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.036, 0.030]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-2.232, 3.003]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.446, 3.003]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-3.535, 13.878]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.057, 4.117]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.005, 28.424]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.427, 3.773]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.427, 3.773]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.427, 3.773]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-2.427, 3.773]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.420, 2.465]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.832, 1.800]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.832, 1.800]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.582, 1.800]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.832, 1.679]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.450, 1.370]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.230, 0.285]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 0.279]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 0.279]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.057, 4.117]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.005, 28.424]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-2.427, 3.773]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.427, 3.773]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-2.427, 3.773]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.100, 2.401]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.100, 2.401]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.100, 2.170]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.077, 2.401]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-3.435, 2.602]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.381, 1.202]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.381, 1.202]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-3.533, 13.475]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 301.232]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]
After block2_1 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]
After body shape: torch.Size([1, 16, 128, 128]), range: [-6.705, 9.622]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-6.705, 9.622]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-6.705, 9.622]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-6.705, 9.622]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-6.705, 9.622]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-6.705, 9.622]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-6.705, 9.622]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.167, 4.052]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.167, 4.052]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.003]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.003]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.655, 0.924]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.655, 0.924]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.655, 0.924]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.209, 0.214]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-6.858, 9.467]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-1.372, 9.467]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-1.246, 56.173]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.155, 13.124]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.015, 361.216]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-1.299, 3.863]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.299, 3.863]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.299, 3.863]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-1.299, 3.863]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-1.856, 1.851]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.544, 1.528]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.544, 1.528]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.207, 1.528]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.544, 1.142]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.169, 0.690]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.103, 0.123]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.225, 0.260]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.225, 0.260]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.155, 13.124]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.015, 361.216]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-1.299, 3.863]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.299, 3.863]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.299, 3.863]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.040, 1.990]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.040, 1.990]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.645, 1.990]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.040, 1.685]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-2.019, 1.701]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-0.794, 0.901]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-0.794, 0.901]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 56.215]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 1096.963]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 348.030]
After block2_2 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 348.030]

Aggreation Input shape: torch.Size([1, 48, 128, 128]), range: [-3.533, 348.030]

SelfAttention Input shape: torch.Size([1, 48, 128, 128]), range: [-3.533, 348.030]

SelfAttention Input shape: torch.Size([1, 48, 128, 128]), range: [-3.533, 348.030]

SelfAttention N: 1, C: 48, H: 128, W: 128

SelfAttention out shape: torch.Size([1, 48]), range: [-0.124, 24.578]

SelfAttention out shape: torch.Size([1, 6]), range: [0.000, 4.891]

SelfAttention out shape: torch.Size([1, 48, 1, 1]), range: [0.073, 0.907]

SelfAttention output shape: torch.Size([1, 48, 128, 128]), range: [-1.998, 102.895]

ConvLayer Input shape: torch.Size([1, 48, 128, 128]), range: [-1.998, 102.895]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-53.856, 13.856]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-12.746, 11.069]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]

Aggreation output shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]
After second blocks - x2 shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]
After body shape: torch.Size([1, 16, 128, 128]), range: [-2.053, 2.246]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.053, 2.246]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.053, 2.246]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-2.053, 2.246]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-2.053, 2.246]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-2.053, 2.246]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-2.053, 2.246]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.543, 0.506]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.543, 0.506]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.123, 0.126]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.123, 0.126]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.123, 0.126]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.017, 0.020]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-2.068, 2.246]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.414, 2.246]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-3.227, 10.844]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.646, 1.330]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.006, 15.325]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-3.256, 3.822]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.256, 3.822]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.256, 3.822]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-3.256, 3.822]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.367, 2.263]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.727, 2.538]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.727, 2.538]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.727, 1.819]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.607, 2.538]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.579, 1.666]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.184, 0.226]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.284, 0.274]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.284, 0.274]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.646, 1.330]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.006, 15.325]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-3.256, 3.822]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.256, 3.822]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-3.256, 3.822]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-2.388, 2.220]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-2.388, 2.220]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-2.388, 2.220]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-2.246, 2.154]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-2.528, 2.699]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-1.263, 1.328]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-1.263, 1.328]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-3.186, 11.069]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 107.031]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]
After block3_1 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]

QBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]

RCB Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]
After body shape: torch.Size([1, 16, 128, 128]), range: [-4.061, 3.107]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-4.061, 3.107]

ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-4.061, 3.107]
ContextBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-4.061, 3.107]
ContextBlock Input_x shape: torch.Size([1, 16, 128, 128]), range: [-4.061, 3.107]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 16384]), range: [-4.061, 3.107]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 16384]), range: [-4.061, 3.107]
ContextBlock Context mask shape: torch.Size([1, 1, 128, 128]), range: [-0.660, 1.660]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 16384]), range: [-0.660, 1.660]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 16384]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 16384, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-1.201, 0.677]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-1.201, 0.677]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-1.201, 0.677]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.429, 0.183]
ContextBlock output shape: torch.Size([1, 16, 128, 128]), range: [-4.121, 2.917]
After GCNet shape: torch.Size([1, 16, 128, 128]), range: [-0.824, 2.917]
RCB output shape: torch.Size([1, 16, 128, 128]), range: [-0.903, 27.030]

NAFBlock Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.161, 5.497]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.017, 77.128]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-1.648, 3.868]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.648, 3.868]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.648, 3.868]
After norm1 shape: torch.Size([1, 16, 128, 128]), range: [-1.648, 3.868]
After conv1 shape: torch.Size([1, 32, 128, 128]), range: [-2.156, 1.908]
After conv2 shape: torch.Size([1, 32, 128, 128]), range: [-1.907, 1.743]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.907, 1.743]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.110, 1.743]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.907, 1.666]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.106, 1.884]
After sca shape: torch.Size([1, 16, 128, 128]), range: [-0.118, 0.383]
After conv3 shape: torch.Size([1, 16, 128, 128]), range: [-0.247, 0.250]
After dropout1 shape: torch.Size([1, 16, 128, 128]), range: [-0.247, 0.250]
After beta shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]

LayerNorm2d forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]

LayerNormFunction forward Input shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]
LayerNormFunction forward mean shape: torch.Size([1, 1, 128, 128]), range: [-0.161, 5.497]
LayerNormFunction forward variance shape: torch.Size([1, 1, 128, 128]), range: [0.017, 77.128]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 128, 128]), range: [-1.648, 3.868]
LayerNormFunction forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.648, 3.868]
LayerNorm2d forward output shape: torch.Size([1, 16, 128, 128]), range: [-1.648, 3.868]
After conv4 shape: torch.Size([1, 32, 128, 128]), range: [-1.808, 1.873]

SimpleGate Input shape: torch.Size([1, 32, 128, 128]), range: [-1.808, 1.873]
SimpleGate x1 shape: torch.Size([1, 16, 128, 128]), range: [-1.574, 1.873]
SimpleGate x2 shape: torch.Size([1, 16, 128, 128]), range: [-1.808, 1.748]
After sg shape: torch.Size([1, 16, 128, 128]), range: [-1.938, 1.883]
After conv5 shape: torch.Size([1, 16, 128, 128]), range: [-0.537, 0.819]
After dropout2 shape: torch.Size([1, 16, 128, 128]), range: [-0.537, 0.819]
NAFBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 27.702]
After branches - shapes: x1: torch.Size([1, 16, 128, 128]), x2: torch.Size([1, 16, 128, 128])
After concat shape: torch.Size([1, 64, 128, 128])
After QCNN shape: torch.Size([1, 64, 128, 128]), range: [-0.278, 367.897]
QBlock output shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 187.040]
After block3_2 shape: torch.Size([1, 16, 128, 128]), range: [-0.278, 187.040]

Aggreation Input shape: torch.Size([1, 64, 128, 128]), range: [-3.533, 187.040]

SelfAttention Input shape: torch.Size([1, 64, 128, 128]), range: [-3.533, 187.040]

SelfAttention Input shape: torch.Size([1, 64, 128, 128]), range: [-3.533, 187.040]

SelfAttention N: 1, C: 64, H: 128, W: 128

SelfAttention out shape: torch.Size([1, 64]), range: [-0.116, 60.676]

SelfAttention out shape: torch.Size([1, 8]), range: [0.000, 12.607]

SelfAttention out shape: torch.Size([1, 64, 1, 1]), range: [0.007, 0.997]

SelfAttention output shape: torch.Size([1, 64, 128, 128]), range: [-2.830, 165.593]

ConvLayer Input shape: torch.Size([1, 64, 128, 128]), range: [-2.830, 165.593]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-26.236, 27.720]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-7.939, 6.754]

ConvLayer out shape: torch.Size([1, 16, 128, 128]), range: [-1.985, 6.754]

Aggreation output shape: torch.Size([1, 16, 128, 128]), range: [-1.985, 6.754]
After third blocks - x3 shape: torch.Size([1, 16, 128, 128]), range: [-1.985, 6.754]

SPP Input shape: torch.Size([1, 16, 128, 128]), range: [-1.985, 6.754]

ConvLayer Input shape: torch.Size([1, 16, 32, 32]), range: [-1.038, 4.354]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-2.748, 1.745]

ConvLayer out shape: torch.Size([1, 16, 32, 32]), range: [-0.687, 1.745]
SPP level 0 output shape: torch.Size([1, 16, 128, 128]), range: [-0.677, 1.542]

ConvLayer Input shape: torch.Size([1, 16, 16, 16]), range: [-0.612, 2.445]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-1.816, 1.398]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-0.454, 1.398]
SPP level 1 output shape: torch.Size([1, 16, 128, 128]), range: [-0.434, 1.352]

ConvLayer Input shape: torch.Size([1, 16, 8, 8]), range: [-0.257, 1.087]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.854, 0.978]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.213, 0.978]
SPP level 2 output shape: torch.Size([1, 16, 128, 128]), range: [-0.204, 0.934]

ConvLayer Input shape: torch.Size([1, 16, 4, 4]), range: [-0.018, 0.744]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.725, 0.365]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.181, 0.365]
SPP level 3 output shape: torch.Size([1, 16, 128, 128]), range: [-0.181, 0.365]

SPP output length: 4, range: [-0.677, 1.542]
SPP level 0 output shape: torch.Size([1, 16, 128, 128]), range: [-0.677, 1.542]
SPP level 1 output shape: torch.Size([1, 16, 128, 128]), range: [-0.434, 1.352]
SPP level 2 output shape: torch.Size([1, 16, 128, 128]), range: [-0.204, 0.934]
SPP level 3 output shape: torch.Size([1, 16, 128, 128]), range: [-0.181, 0.365]
SPP level 4 output shape: torch.Size([1, 16, 128, 128]), range: [-1.985, 6.754]

ConvLayer Input shape: torch.Size([1, 80, 128, 128]), range: [-1.985, 6.754]

ConvLayer out shape: torch.Size([1, 6, 128, 128]), range: [-1.348, 1.321]

ConvLayer out shape: torch.Size([1, 6, 128, 128]), range: [-0.337, 1.321]

SPP output shape: torch.Size([1, 6, 128, 128]), range: [-0.337, 1.321]
DetailRestorer output shape: torch.Size([1, 6, 128, 128]), range: [-0.337, 1.321]
DetailRestorer 1 output shape: torch.Size([1, 6, 128, 128]), range: [-0.337, 1.321]
Prior down 1 shape: torch.Size([1, 6, 128, 128]), range: [-0.684, 1.491]
Down 2 output shape: torch.Size([1, 12, 64, 64]), range: [-0.634, 0.847]

DetailRestorer Input shape: torch.Size([1, 12, 64, 64]), range: [-0.634, 0.847]

OverlapPatchEmbed Input shape: torch.Size([1, 12, 64, 64]), range: [-0.634, 0.847]

OverlapPatchEmbed output shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]
After embed shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]
After body shape: torch.Size([1, 16, 64, 64]), range: [-0.072, 0.068]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.072, 0.068]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.072, 0.068]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.072, 0.068]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-0.072, 0.068]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-0.072, 0.068]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-0.072, 0.068]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.020, 0.023]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.020, 0.023]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.017, 0.029]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.017, 0.029]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.017, 0.029]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.005, 0.006]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.070, 0.066]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.014, 0.066]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-0.347, 0.442]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.045, 0.073]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.002, 0.029]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.754, 2.874]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.754, 2.874]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.754, 2.874]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-2.754, 2.874]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-1.746, 1.956]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.856, 1.521]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.856, 1.521]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.856, 1.033]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-0.954, 1.521]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.066, 1.016]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.151, 0.428]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.274, 0.278]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.274, 0.278]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.045, 0.073]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.002, 0.029]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.754, 2.874]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.754, 2.874]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.754, 2.874]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.183, 1.774]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.183, 1.774]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-2.183, 1.774]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.848, 1.663]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.680, 1.866]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-0.673, 1.059]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-0.673, 1.059]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.361, 0.449]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 5.081]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]
After block1_1 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]
After body shape: torch.Size([1, 16, 64, 64]), range: [-0.246, 0.139]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.246, 0.139]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.246, 0.139]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.246, 0.139]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-0.246, 0.139]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-0.246, 0.139]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-0.246, 0.139]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.080, 0.050]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.080, 0.050]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.053, 0.023]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.053, 0.023]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.053, 0.023]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.014, 0.004]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.256, 0.141]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.051, 0.141]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-0.314, 1.597]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.064, 0.252]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.001, 0.320]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.600, 3.386]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.600, 3.386]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.600, 3.386]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-2.600, 3.386]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-1.794, 1.933]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.543, 1.688]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.543, 1.688]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.093, 1.612]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.543, 1.688]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.433, 0.771]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.217, 0.319]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.188, 0.247]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.188, 0.247]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.064, 0.252]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.001, 0.320]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.600, 3.386]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.600, 3.386]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.600, 3.386]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-1.934, 1.931]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.934, 1.931]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.692, 1.634]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.934, 1.931]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.712, 1.824]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-0.702, 0.820]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-0.702, 0.820]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 1.611]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 14.233]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 11.253]
After block1_2 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 11.253]

Aggreation Input shape: torch.Size([1, 32, 64, 64]), range: [-0.278, 11.253]

SelfAttention Input shape: torch.Size([1, 32, 64, 64]), range: [-0.278, 11.253]

SelfAttention Input shape: torch.Size([1, 32, 64, 64]), range: [-0.278, 11.253]

SelfAttention N: 1, C: 32, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 32]), range: [-0.196, 0.167]

SelfAttention out shape: torch.Size([1, 4]), range: [0.000, 0.242]

SelfAttention out shape: torch.Size([1, 32, 1, 1]), range: [0.390, 0.628]

SelfAttention output shape: torch.Size([1, 32, 64, 64]), range: [-0.170, 7.038]

ConvLayer Input shape: torch.Size([1, 32, 64, 64]), range: [-0.170, 7.038]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-1.617, 1.865]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-17.167, 15.826]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]

Aggreation output shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]
After first blocks - x1 shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]
After body shape: torch.Size([1, 16, 64, 64]), range: [-3.550, 2.377]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-3.550, 2.377]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-3.550, 2.377]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-3.550, 2.377]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-3.550, 2.377]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-3.550, 2.377]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-3.550, 2.377]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.212, 1.521]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.212, 1.521]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.001]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.001]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.115, 0.104]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.115, 0.104]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.115, 0.104]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.009, 0.017]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-3.548, 2.373]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.710, 2.373]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-4.588, 16.351]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.023, 3.077]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.012, 48.170]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.288, 3.640]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.288, 3.640]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.288, 3.640]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-2.288, 3.640]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-1.958, 1.987]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.814, 1.674]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.814, 1.674]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.305, 1.167]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.814, 1.674]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.040, 1.205]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.131, 0.202]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.260, 0.276]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.260, 0.276]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.023, 3.077]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.012, 48.170]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.288, 3.640]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.288, 3.640]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.288, 3.640]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-1.918, 2.193]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.918, 2.193]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.918, 2.193]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.836, 1.998]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.138, 2.034]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-1.307, 0.905]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-1.307, 0.905]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-4.292, 15.826]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 282.524]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]
After block2_1 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]
After body shape: torch.Size([1, 16, 64, 64]), range: [-25.191, 18.780]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-25.191, 18.780]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-25.191, 18.780]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-25.191, 18.780]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-25.191, 18.780]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-25.191, 18.780]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-25.191, 18.780]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-2.896, 7.034]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-2.896, 7.034]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.095]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.095]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-10.853, 6.291]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-10.853, 6.291]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-10.853, 6.291]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-1.444, 1.820]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-23.959, 18.554]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-4.792, 18.554]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-4.792, 105.260]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [0.170, 24.263]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.083, 1063.276]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.465, 3.396]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.465, 3.396]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.465, 3.396]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-1.465, 3.396]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.255, 1.697]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.515, 1.733]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.515, 1.733]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.515, 0.777]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-0.887, 1.733]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-0.705, 0.521]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.140, 0.079]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.243, 0.247]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.243, 0.247]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [0.170, 24.263]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.083, 1063.276]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.465, 3.396]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.465, 3.396]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.465, 3.396]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-1.587, 1.956]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.587, 1.956]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.573, 1.605]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.587, 1.956]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.006, 1.002]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-0.826, 0.972]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-0.826, 0.972]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 97.394]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 1852.552]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 706.800]
After block2_2 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 706.800]

Aggreation Input shape: torch.Size([1, 48, 64, 64]), range: [-4.292, 706.800]

SelfAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.292, 706.800]

SelfAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-4.292, 706.800]

SelfAttention N: 1, C: 48, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 48]), range: [-0.106, 57.971]

SelfAttention out shape: torch.Size([1, 6]), range: [0.000, 1.247]

SelfAttention out shape: torch.Size([1, 48, 1, 1]), range: [0.322, 0.669]

SelfAttention output shape: torch.Size([1, 48, 64, 64]), range: [-2.252, 417.136]

ConvLayer Input shape: torch.Size([1, 48, 64, 64]), range: [-2.252, 417.136]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-89.577, 73.478]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-13.458, 13.894]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]

Aggreation output shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]
After second blocks - x2 shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]
After body shape: torch.Size([1, 16, 64, 64]), range: [-1.521, 1.576]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.521, 1.576]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.521, 1.576]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-1.521, 1.576]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-1.521, 1.576]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-1.521, 1.576]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-1.521, 1.576]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-0.479, 0.464]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-0.479, 0.464]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.000]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.000]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.060, 0.048]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.060, 0.048]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.060, 0.048]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.016, 0.013]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-1.510, 1.560]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.302, 1.560]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-3.406, 14.767]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.063, 1.850]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.003, 33.468]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.126, 3.723]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.126, 3.723]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.126, 3.723]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-2.126, 3.723]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.247, 2.239]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-1.489, 2.503]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.489, 2.503]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.489, 2.503]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.434, 1.700]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.382, 1.129]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.293, 0.236]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.294, 0.282]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.294, 0.282]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.063, 1.850]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.003, 33.468]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-2.126, 3.723]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.126, 3.723]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-2.126, 3.723]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-2.034, 1.874]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.034, 1.874]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.757, 1.849]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-2.034, 1.874]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-2.017, 2.181]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-0.841, 0.962]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-0.841, 0.962]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-3.365, 13.894]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 166.096]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]
After block3_1 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]

QBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]

RCB Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]
After body shape: torch.Size([1, 16, 64, 64]), range: [-4.295, 4.630]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-4.295, 4.630]

ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-4.295, 4.630]
ContextBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-4.295, 4.630]
ContextBlock Input_x shape: torch.Size([1, 16, 64, 64]), range: [-4.295, 4.630]
ContextBlock Input_x reshaped shape: torch.Size([1, 16, 4096]), range: [-4.295, 4.630]
ContextBlock Input_x unsqueezed shape: torch.Size([1, 1, 16, 4096]), range: [-4.295, 4.630]
ContextBlock Context mask shape: torch.Size([1, 1, 64, 64]), range: [-1.119, 1.837]
ContextBlock Context mask reshaped shape: torch.Size([1, 1, 4096]), range: [-1.119, 1.837]
ContextBlock Context mask softmax shape: torch.Size([1, 1, 4096]), range: [0.000, 0.001]
ContextBlock Context mask unsqueezed shape: torch.Size([1, 1, 4096, 1]), range: [0.000, 0.001]
ContextBlock Context shape: torch.Size([1, 1, 16, 1]), range: [-0.545, 0.613]
ContextBlock Context reshaped shape: torch.Size([1, 16, 1, 1]), range: [-0.545, 0.613]
ContextBlock Context shape: torch.Size([1, 16, 1, 1]), range: [-0.545, 0.613]
ContextBlock Channel add term shape: torch.Size([1, 16, 1, 1]), range: [-0.173, 0.135]
ContextBlock output shape: torch.Size([1, 16, 64, 64]), range: [-4.160, 4.713]
After GCNet shape: torch.Size([1, 16, 64, 64]), range: [-0.832, 4.713]
RCB output shape: torch.Size([1, 16, 64, 64]), range: [-1.072, 72.201]

NAFBlock Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.112, 11.113]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.031, 351.604]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.398, 3.780]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.398, 3.780]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.398, 3.780]
After norm1 shape: torch.Size([1, 16, 64, 64]), range: [-1.398, 3.780]
After conv1 shape: torch.Size([1, 32, 64, 64]), range: [-2.116, 1.916]
After conv2 shape: torch.Size([1, 32, 64, 64]), range: [-2.138, 1.468]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-2.138, 1.468]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.241, 1.468]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-2.138, 1.267]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-0.645, 0.890]
After sca shape: torch.Size([1, 16, 64, 64]), range: [-0.151, 0.160]
After conv3 shape: torch.Size([1, 16, 64, 64]), range: [-0.282, 0.222]
After dropout1 shape: torch.Size([1, 16, 64, 64]), range: [-0.282, 0.222]
After beta shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]

LayerNorm2d forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]

LayerNormFunction forward Input shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]
LayerNormFunction forward mean shape: torch.Size([1, 1, 64, 64]), range: [-0.112, 11.113]
LayerNormFunction forward variance shape: torch.Size([1, 1, 64, 64]), range: [0.031, 351.604]
LayerNormFunction forward normalized shape: torch.Size([1, 16, 64, 64]), range: [-1.398, 3.780]
LayerNormFunction forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.398, 3.780]
LayerNorm2d forward output shape: torch.Size([1, 16, 64, 64]), range: [-1.398, 3.780]
After conv4 shape: torch.Size([1, 32, 64, 64]), range: [-1.701, 1.737]

SimpleGate Input shape: torch.Size([1, 32, 64, 64]), range: [-1.701, 1.737]
SimpleGate x1 shape: torch.Size([1, 16, 64, 64]), range: [-1.701, 1.676]
SimpleGate x2 shape: torch.Size([1, 16, 64, 64]), range: [-1.677, 1.737]
After sg shape: torch.Size([1, 16, 64, 64]), range: [-1.487, 1.861]
After conv5 shape: torch.Size([1, 16, 64, 64]), range: [-0.771, 0.836]
After dropout2 shape: torch.Size([1, 16, 64, 64]), range: [-0.771, 0.836]
NAFBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 68.832]
After branches - shapes: x1: torch.Size([1, 16, 64, 64]), x2: torch.Size([1, 16, 64, 64])
After concat shape: torch.Size([1, 64, 64, 64])
After QCNN shape: torch.Size([1, 64, 64, 64]), range: [-0.278, 876.922]
QBlock output shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 265.431]
After block3_2 shape: torch.Size([1, 16, 64, 64]), range: [-0.278, 265.431]

Aggreation Input shape: torch.Size([1, 64, 64, 64]), range: [-4.292, 265.431]

SelfAttention Input shape: torch.Size([1, 64, 64, 64]), range: [-4.292, 265.431]

SelfAttention Input shape: torch.Size([1, 64, 64, 64]), range: [-4.292, 265.431]

SelfAttention N: 1, C: 64, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 64]), range: [-0.167, 21.835]

SelfAttention out shape: torch.Size([1, 8]), range: [0.000, 1.927]

SelfAttention out shape: torch.Size([1, 64, 1, 1]), range: [0.185, 0.867]

SelfAttention output shape: torch.Size([1, 64, 64, 64]), range: [-2.600, 128.459]

ConvLayer Input shape: torch.Size([1, 64, 64, 64]), range: [-2.600, 128.459]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-21.627, 28.838]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-11.714, 11.895]

ConvLayer out shape: torch.Size([1, 16, 64, 64]), range: [-2.928, 11.895]

Aggreation output shape: torch.Size([1, 16, 64, 64]), range: [-2.928, 11.895]
After third blocks - x3 shape: torch.Size([1, 16, 64, 64]), range: [-2.928, 11.895]

SPP Input shape: torch.Size([1, 16, 64, 64]), range: [-2.928, 11.895]

ConvLayer Input shape: torch.Size([1, 16, 16, 16]), range: [-1.908, 7.733]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-4.220, 6.376]

ConvLayer out shape: torch.Size([1, 16, 16, 16]), range: [-1.055, 6.376]
SPP level 0 output shape: torch.Size([1, 16, 64, 64]), range: [-0.965, 5.686]

ConvLayer Input shape: torch.Size([1, 16, 8, 8]), range: [-1.025, 4.281]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-3.059, 4.025]

ConvLayer out shape: torch.Size([1, 16, 8, 8]), range: [-0.765, 4.025]
SPP level 1 output shape: torch.Size([1, 16, 64, 64]), range: [-0.698, 3.741]

ConvLayer Input shape: torch.Size([1, 16, 4, 4]), range: [-0.392, 1.953]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-1.593, 1.309]

ConvLayer out shape: torch.Size([1, 16, 4, 4]), range: [-0.398, 1.309]
SPP level 2 output shape: torch.Size([1, 16, 64, 64]), range: [-0.386, 1.274]

ConvLayer Input shape: torch.Size([1, 16, 2, 2]), range: [-0.032, 0.531]

ConvLayer out shape: torch.Size([1, 16, 2, 2]), range: [-0.313, 0.560]

ConvLayer out shape: torch.Size([1, 16, 2, 2]), range: [-0.078, 0.560]
SPP level 3 output shape: torch.Size([1, 16, 64, 64]), range: [-0.078, 0.560]

SPP output length: 4, range: [-0.965, 5.686]
SPP level 0 output shape: torch.Size([1, 16, 64, 64]), range: [-0.965, 5.686]
SPP level 1 output shape: torch.Size([1, 16, 64, 64]), range: [-0.698, 3.741]
SPP level 2 output shape: torch.Size([1, 16, 64, 64]), range: [-0.386, 1.274]
SPP level 3 output shape: torch.Size([1, 16, 64, 64]), range: [-0.078, 0.560]
SPP level 4 output shape: torch.Size([1, 16, 64, 64]), range: [-2.928, 11.895]

ConvLayer Input shape: torch.Size([1, 80, 64, 64]), range: [-2.928, 11.895]

ConvLayer out shape: torch.Size([1, 12, 64, 64]), range: [-2.646, 3.902]

ConvLayer out shape: torch.Size([1, 12, 64, 64]), range: [-0.661, 3.902]

SPP output shape: torch.Size([1, 12, 64, 64]), range: [-0.661, 3.902]
DetailRestorer output shape: torch.Size([1, 12, 64, 64]), range: [-0.661, 3.902]
DetailRestorer 2 output shape: torch.Size([1, 12, 64, 64]), range: [-0.661, 3.902]
Prior down 2 shape: torch.Size([1, 12, 64, 64]), range: [-0.665, 0.818]

FeatureContextualizer Input shape: torch.Size([1, 12, 64, 64]), range: [-0.661, 3.902]
FeatureContextualizer Prior input shape: torch.Size([1, 12, 64, 64]), range: [-0.665, 0.818]

OverlapPatchEmbed Input shape: torch.Size([1, 12, 64, 64]), range: [-0.661, 3.902]

OverlapPatchEmbed output shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]

OverlapPatchEmbed Input shape: torch.Size([1, 12, 64, 64]), range: [-0.665, 0.818]

OverlapPatchEmbed output shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
After embed shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.441, 0.442]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.441, 0.442]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.036, 3.001]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.036, 3.001]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-1.613, 1.908]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-1.613, 1.908]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.287, 3.514]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.287, 3.514]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.287, 3.514]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.287, 3.514]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-3.287, 3.514]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.572, 2.437]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.791, 2.437]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.617, 1.761]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.617, 1.761]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.791, 2.437]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.572, 1.765]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.089, 0.085]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.074, 0.095]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.972, 0.971]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.006, 0.044]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.169, 0.155]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.169, 0.155]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.198, 0.204]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-1.607, 1.982]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.607, 1.982]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.607, 1.982]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-1.607, 1.982]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-1.607, 1.982]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-1.607, 1.982]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.886, 3.372]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.886, 3.372]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.886, 3.372]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.886, 3.372]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.886, 3.372]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.583, 2.456]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.024, 2.293], [-1.800, 2.191]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.670, 0.925]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.219, 0.209]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-1.564, 2.050]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-1.613, 1.908]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-1.613, 1.908]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.287, 3.514]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.287, 3.514]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.287, 3.514]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.287, 3.514]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.441, 0.442]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.441, 0.442]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.036, 3.001]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.036, 3.001]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-3.287, 3.514]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-1.751, 2.005]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.560, 2.005]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.695, 2.049]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.695, 2.049]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.560, 2.005]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.751, 1.856]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.080, 0.091]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.087, 0.077]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.972, 0.961]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.005, 0.047]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.139, 0.100]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.139, 0.100]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.176, 0.180]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.462, 0.486]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.462, 0.486]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.462, 0.486]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.462, 0.486]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.462, 0.486]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.462, 0.486]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.821, 3.268]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.821, 3.268]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.821, 3.268]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.821, 3.268]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.821, 3.268]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.384, 2.073]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.613, 1.330], [-1.515, 1.821]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.648, 0.695]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.196, 0.198]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.567, 0.564]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-1.613, 1.908]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-1.613, 1.908]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-1.613, 1.908]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.287, 3.514]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.287, 3.514]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.287, 3.514]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.287, 3.514]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-3.287, 3.514]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-2.368, 2.249]
Q shape: torch.Size([1, 48, 64, 64]), range: [-2.368, 1.749]
K shape: torch.Size([1, 48, 64, 64]), range: [-1.637, 2.249]
V shape: torch.Size([1, 48, 64, 64]), range: [-1.695, 1.450]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.368, 1.749]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.637, 2.249]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.695, 1.450]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.066, 0.089]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.070, 0.070]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.957, 0.960]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.006, 0.049]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.118, 0.117]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.118, 0.117]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.312, 0.181]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-1.710, 1.858]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.710, 1.858]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-1.710, 1.858]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-1.710, 1.858]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-1.710, 1.858]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-1.710, 1.858]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.240, 2.968]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.240, 2.968]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.240, 2.968]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.240, 2.968]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-3.240, 2.968]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.083, 2.118]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.830, 1.608], [-2.078, 2.617]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.933, 1.123]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.256, 0.213]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-1.711, 1.880]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.278, 24.446]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.159]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.159]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.772, 5.329]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.772, 5.329]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.159]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.159]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.772, 5.329]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.772, 5.329]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.304, 2.011]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-2.304, 1.439]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.455, 1.948]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.455, 1.948]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.304, 1.439]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.656, 2.011]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.097, 0.099]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.094, 0.084]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.974, 0.979]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.006, 0.045]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.172, 0.213]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.172, 0.213]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.178, 0.231]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.449, 11.092]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.449, 11.092]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.449, 11.092]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.449, 11.092]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.449, 11.092]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.449, 11.092]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.941, 5.255]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.941, 5.255]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.941, 5.255]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.941, 5.255]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-1.941, 5.255]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.425, 2.145]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-3.024, 2.153], [-1.637, 2.303]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.962, 1.155]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.246, 0.219]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.506, 11.025]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.159]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.159]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.772, 5.329]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.772, 5.329]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.159]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.159]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.772, 5.329]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.772, 5.329]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-1.823, 2.295]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.582, 1.919]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.615, 2.089]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.615, 2.089]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.582, 1.919]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.823, 2.295]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.095, 0.108]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.094, 0.103]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.982, 0.983]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.005, 0.045]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.158, 0.142]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.158, 0.142]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.240, 0.203]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.492, 11.242]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.492, 11.242]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.492, 11.242]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.492, 11.242]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.492, 11.242]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.492, 11.242]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.061, 5.231]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.061, 5.231]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.061, 5.231]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.061, 5.231]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.061, 5.231]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.257, 1.982]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.574, 2.067], [-1.758, 1.569]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.464, 2.026]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.291, 0.228]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.575, 11.209]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 11.159]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.159]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 11.159]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.772, 5.329]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.772, 5.329]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.772, 5.329]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-1.968, 2.095]
Q shape: torch.Size([1, 48, 64, 64]), range: [-1.701, 1.568]
K shape: torch.Size([1, 48, 64, 64]), range: [-1.968, 2.095]
V shape: torch.Size([1, 48, 64, 64]), range: [-1.764, 1.626]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.701, 1.568]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.968, 2.095]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.764, 1.626]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.091, 0.087]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.088, 0.073]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.989, 0.978]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.005, 0.047]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.039, 0.182]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.039, 0.182]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.212, 0.238]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.482, 11.199]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.482, 11.199]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.482, 11.199]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.482, 11.199]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.482, 11.199]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.482, 11.199]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.107, 5.364]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.107, 5.364]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.107, 5.364]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.107, 5.364]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.107, 5.364]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.560, 2.247]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.799, 1.621], [-2.224, 1.932]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.739, 1.470]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.279, 0.250]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.726, 11.289]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.278, 406.665]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 490.087]

Aggreation Input shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 490.087]

SelfAttention Input shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 490.087]

SelfAttention Input shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 490.087]

SelfAttention N: 1, C: 96, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 96]), range: [-0.251, 103.022]

SelfAttention out shape: torch.Size([1, 12]), range: [0.000, 17.807]

SelfAttention out shape: torch.Size([1, 96, 1, 1]), range: [0.000, 1.000]

SelfAttention output shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 261.953]

ConvLayer Input shape: torch.Size([1, 96, 64, 64]), range: [-0.278, 261.953]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-74.229, 67.491]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-9.631, 8.687]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]

Aggreation output shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]
After first blocks - x1 shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.441, 0.442]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.441, 0.442]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.036, 3.001]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.036, 3.001]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.408, 8.687]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.408, 8.687]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.499, 5.579]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.499, 5.579]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.499, 5.579]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.499, 5.579]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.499, 5.579]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-2.599, 2.884]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-2.431, 2.279]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.327, 1.577]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.327, 1.577]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.431, 2.279]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.599, 2.884]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.083, 0.071]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.104, 0.070]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.917, 0.923]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.007, 0.051]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.169, 0.225]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.169, 0.225]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.215, 0.264]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-2.309, 8.741]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.309, 8.741]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.309, 8.741]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.309, 8.741]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.309, 8.741]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.309, 8.741]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.375, 5.575]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.375, 5.575]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.375, 5.575]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.375, 5.575]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.375, 5.575]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.700, 2.440]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.858, 2.047], [-2.533, 1.950]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.645, 1.397]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.251, 0.259]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-2.491, 8.588]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.408, 8.687]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.408, 8.687]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.499, 5.579]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.499, 5.579]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.499, 5.579]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.499, 5.579]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.441, 0.442]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.441, 0.442]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.441, 0.442]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.036, 3.001]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.036, 3.001]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.499, 5.579]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-3.036, 3.001]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-1.900, 1.670]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.900, 1.470]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-2.752, 2.282]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-2.752, 2.282]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.900, 1.470]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.425, 1.670]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.079, 0.084]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.094, 0.070]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.927, 0.925]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.006, 0.046]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.150, 0.112]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.150, 0.112]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.216, 0.140]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.545, 0.503]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.545, 0.503]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.545, 0.503]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.545, 0.503]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.545, 0.503]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.545, 0.503]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-3.204, 3.109]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-3.204, 3.109]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-3.204, 3.109]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-3.204, 3.109]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-3.204, 3.109]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.008, 2.223]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-1.147, 1.289], [-1.564, 1.276]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.426, 1.133]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.218, 0.163]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.634, 0.483]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.408, 8.687]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.408, 8.687]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.408, 8.687]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.499, 5.579]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.499, 5.579]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.499, 5.579]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.499, 5.579]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-2.499, 5.579]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-2.163, 2.205]
Q shape: torch.Size([1, 48, 64, 64]), range: [-2.163, 2.205]
K shape: torch.Size([1, 48, 64, 64]), range: [-2.025, 2.055]
V shape: torch.Size([1, 48, 64, 64]), range: [-1.761, 1.752]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.163, 2.205]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.025, 2.055]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.761, 1.752]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.077, 0.077]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.071, 0.078]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.870, 0.902]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.007, 0.046]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.118, 0.156]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.118, 0.156]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.284, 0.314]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-2.327, 8.829]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.327, 8.829]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-2.327, 8.829]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-2.327, 8.829]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-2.327, 8.829]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-2.327, 8.829]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-2.605, 5.486]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-2.605, 5.486]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-2.605, 5.486]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-2.605, 5.486]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-2.605, 5.486]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.499, 2.462]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.091, 2.774], [-2.895, 2.623]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-2.212, 1.093]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.237, 0.313]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-2.334, 8.896]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [-0.278, 431.993]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]

MAQ Input shapes - x: torch.Size([1, 48, 64, 64]), prior: torch.Size([1, 48, 64, 64])

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 213.385]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 213.385]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.015, 3.650]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.015, 3.650]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 213.385]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 213.385]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.015, 3.650]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.015, 3.650]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-1.853, 1.610]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.853, 1.610]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.199, 1.254]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.199, 1.254]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.853, 1.610]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.671, 1.355]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.077, 0.077]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.079, 0.097]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.992, 0.990]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.005, 0.047]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.124, 0.063]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.124, 0.063]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.144, 0.199]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.402, 213.349]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.402, 213.349]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.402, 213.349]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.402, 213.349]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.402, 213.349]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.402, 213.349]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.026, 3.644]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.026, 3.644]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.026, 3.644]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.026, 3.644]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-1.026, 3.644]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-1.958, 2.324]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.730, 1.904], [-1.895, 1.436]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-1.727, 1.763]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 0.333]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.544, 213.370]

CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
CrossAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 213.385]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 213.385]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.015, 3.650]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.015, 3.650]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 213.385]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 213.385]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.015, 3.650]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.015, 3.650]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]

CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]
CrossAttention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]
CrossAttention KV shape: torch.Size([1, 192, 64, 64]), range: [-1.915, 3.143]
CrossAttention K shape: torch.Size([1, 96, 64, 64]), range: [-1.731, 3.143]
CrossAttention Q shape: torch.Size([1, 96, 64, 64]), range: [-1.834, 1.351]
CrossAttention Q reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.834, 1.351]
CrossAttention K reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.731, 3.143]
CrossAttention V reshaped shape: torch.Size([1, 2, 48, 4096]), range: [-1.915, 2.672]
CrossAttention Q normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.085, 0.083]
CrossAttention K normalized shape: torch.Size([1, 2, 48, 4096]), range: [-0.085, 0.098]
CrossAttention Attention shape: torch.Size([1, 2, 48, 48]), range: [-0.991, 0.991]
CrossAttention Attention softmax shape: torch.Size([1, 2, 48, 48]), range: [0.005, 0.050]
CrossAttention Output shape: torch.Size([1, 2, 48, 4096]), range: [-0.248, 0.159]
CrossAttention Output reshaped shape: torch.Size([1, 96, 64, 64]), range: [-0.248, 0.159]
CrossAttention Output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.243, 0.207]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.462, 213.433]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.462, 213.433]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.462, 213.433]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.462, 213.433]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.462, 213.433]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.462, 213.433]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.030, 3.641]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.030, 3.641]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.030, 3.641]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.030, 3.641]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-1.030, 3.641]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.085, 2.101]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.260, 1.952], [-2.033, 1.461]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.678, 1.050]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.177, 0.187]
CrossAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.594, 213.468]

SelfAttentionTransformer Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 213.385]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.278, 213.385]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.278, 213.385]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.015, 3.650]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.015, 3.650]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]

Attention Input shape: torch.Size([1, 48, 64, 64]), range: [-1.015, 3.650]
QKV shape: torch.Size([1, 144, 64, 64]), range: [-2.067, 1.534]
Q shape: torch.Size([1, 48, 64, 64]), range: [-1.331, 1.534]
K shape: torch.Size([1, 48, 64, 64]), range: [-2.067, 1.363]
V shape: torch.Size([1, 48, 64, 64]), range: [-0.808, 0.916]
Q reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-1.331, 1.534]
K reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-2.067, 1.363]
V reshaped shape: torch.Size([1, 1, 48, 4096]), range: [-0.808, 0.916]
Q normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.088, 0.094]
K normalized shape: torch.Size([1, 1, 48, 4096]), range: [-0.063, 0.086]
Attention shape: torch.Size([1, 1, 48, 48]), range: [-0.989, 0.990]
Attention softmax shape: torch.Size([1, 1, 48, 48]), range: [0.005, 0.044]
Attention output shape: torch.Size([1, 1, 48, 4096]), range: [-0.061, 0.099]
Attention output reshaped shape: torch.Size([1, 48, 64, 64]), range: [-0.061, 0.099]
Attention output after projection shape: torch.Size([1, 48, 64, 64]), range: [-0.206, 0.191]
After attention shape: torch.Size([1, 48, 64, 64]), range: [-0.430, 213.296]

LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.430, 213.296]
LayerNorm Input shape: torch.Size([1, 48, 64, 64]), range: [-0.430, 213.296]

to_3d Input shape: torch.Size([1, 48, 64, 64]), range: [-0.430, 213.296]
to_3d Output shape: torch.Size([1, 4096, 48]), range: [-0.430, 213.296]

WithBias_LayerNorm Input shape: torch.Size([1, 4096, 48]), range: [-0.430, 213.296]
WithBias_LayerNorm Output shape: torch.Size([1, 4096, 48]), range: [-1.043, 3.650]

to_4d Input shape: torch.Size([1, 4096, 48]), range: [-1.043, 3.650]
to_4d Output shape: torch.Size([1, 48, 64, 64]), range: [-1.043, 3.650]
LayerNorm output shape: torch.Size([1, 48, 64, 64]), range: [-1.043, 3.650]

FeedForward Input shape: torch.Size([1, 48, 64, 64]), range: [-1.043, 3.650]
After project_in shape: torch.Size([1, 254, 64, 64]), range: [-2.151, 1.907]
After dwconv shape: x1: torch.Size([1, 127, 64, 64]), x2: torch.Size([1, 127, 64, 64]), range: [-2.404, 1.382], [-1.357, 1.773]
After GELU and multiplication shape: torch.Size([1, 127, 64, 64]), range: [-0.574, 0.589]
FeedForward output shape: torch.Size([1, 48, 64, 64]), range: [-0.167, 0.160]
SelfAttentionTransformer output shape: torch.Size([1, 48, 64, 64]), range: [-0.519, 213.276]
After branches - shapes: x1: torch.Size([1, 48, 64, 64]), x2: torch.Size([1, 48, 64, 64]), x3: torch.Size([1, 48, 64, 64])
After concat shape: torch.Size([1, 192, 64, 64])
After QCNN shape: torch.Size([1, 192, 64, 64]), range: [0.000, 11279.465]
MAQ output shape: torch.Size([1, 48, 64, 64]), range: [-0.278, 10195.554]

Aggreation Input shape: torch.Size([1, 144, 64, 64]), range: [-2.408, 10195.554]

SelfAttention Input shape: torch.Size([1, 144, 64, 64]), range: [-2.408, 10195.554]

SelfAttention Input shape: torch.Size([1, 144, 64, 64]), range: [-2.408, 10195.554]

SelfAttention N: 1, C: 144, H: 64, W: 64

SelfAttention out shape: torch.Size([1, 144]), range: [-0.070, 1548.449]

SelfAttention out shape: torch.Size([1, 18]), range: [0.000, 222.713]

SelfAttention out shape: torch.Size([1, 144, 1, 1]), range: [0.000, 1.000]

SelfAttention output shape: torch.Size([1, 144, 64, 64]), range: [-2.201, 6270.773]

ConvLayer Input shape: torch.Size([1, 144, 64, 64]), range: [-2.201, 6270.773]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-1142.464, 1342.790]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-9.519, 9.237]

ConvLayer out shape: torch.Size([1, 48, 64, 64]), range: [-2.380, 9.237]

Aggreation output shape: torch.Size([1, 48, 64, 64]), range: [-2.380, 9.237]
After second blocks - x2 shape: torch.Size([1, 48, 64, 64]), range: [-2.380, 9.237]

SPP Input shape: torch.Size([1, 48, 64, 64]), range: [-2.380, 9.237]

ConvLayer Input shape: torch.Size([1, 48, 16, 16]), range: [-1.794, 7.518]

ConvLayer out shape: torch.Size([1, 48, 16, 16]), range: [-10.887, 6.274]

ConvLayer out shape: torch.Size([1, 48, 16, 16]), range: [-2.722, 6.274]
SPP level 0 output shape: torch.Size([1, 48, 64, 64]), range: [-2.368, 6.005]

ConvLayer Input shape: torch.Size([1, 48, 8, 8]), range: [-1.067, 4.405]

ConvLayer out shape: torch.Size([1, 48, 8, 8]), range: [-2.884, 2.894]

ConvLayer out shape: torch.Size([1, 48, 8, 8]), range: [-0.721, 2.894]
SPP level 1 output shape: torch.Size([1, 48, 64, 64]), range: [-0.654, 2.665]

ConvLayer Input shape: torch.Size([1, 48, 4, 4]), range: [-0.539, 2.171]

ConvLayer out shape: torch.Size([1, 48, 4, 4]), range: [-1.773, 1.999]

ConvLayer out shape: torch.Size([1, 48, 4, 4]), range: [-0.443, 1.999]
SPP level 2 output shape: torch.Size([1, 48, 64, 64]), range: [-0.433, 1.947]

ConvLayer Input shape: torch.Size([1, 48, 2, 2]), range: [-0.029, 0.659]

ConvLayer out shape: torch.Size([1, 48, 2, 2]), range: [-0.668, 0.657]

ConvLayer out shape: torch.Size([1, 48, 2, 2]), range: [-0.167, 0.657]
SPP level 3 output shape: torch.Size([1, 48, 64, 64]), range: [-0.167, 0.657]

SPP output length: 4, range: [-2.368, 6.005]
SPP level 0 output shape: torch.Size([1, 48, 64, 64]), range: [-2.368, 6.005]
SPP level 1 output shape: torch.Size([1, 48, 64, 64]), range: [-0.654, 2.665]
SPP level 2 output shape: torch.Size([1, 48, 64, 64]), range: [-0.433, 1.947]
SPP level 3 output shape: torch.Size([1, 48, 64, 64]), range: [-0.167, 0.657]
SPP level 4 output shape: torch.Size([1, 48, 64, 64]), range: [-2.380, 9.237]

ConvLayer Input shape: torch.Size([1, 240, 64, 64]), range: [-2.380, 9.237]

ConvLayer out shape: torch.Size([1, 24, 64, 64]), range: [-3.570, 3.701]

ConvLayer out shape: torch.Size([1, 24, 64, 64]), range: [-0.892, 3.701]

SPP output shape: torch.Size([1, 24, 64, 64]), range: [-0.892, 3.701]
FeatureContextualizer output shape: torch.Size([1, 24, 64, 64]), range: [-0.892, 3.701]
FeatureContextualizer output shape: torch.Size([1, 24, 64, 64]), range: [-0.892, 3.701]

ScaleHarmonizer Input shape: torch.Size([1, 24, 64, 64]), range: [-0.892, 3.701]

Condition Input shape: torch.Size([1, 24, 64, 64]), range: [-0.892, 3.701]
Condition conv1 output shape: torch.Size([1, 32, 30, 30]), range: [0.000, 1.307]
Condition conv2 output shape: torch.Size([1, 32, 15, 15]), range: [0.000, 0.517]
Condition conv3 output shape: torch.Size([1, 32, 8, 8]), range: [0.000, 0.139]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.062]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.062]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.181, 0.179]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.182, 0.177]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.188, 0.168]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.181, 0.170]
ScaleHarmonizer Scale3 shape: torch.Size([1, 12]), range: [-0.133, 0.119]
ScaleHarmonizer Shift3 shape: torch.Size([1, 12]), range: [-0.164, 0.187]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 64, 64]), range: [-1.787, 1.751]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 64, 64]), range: [-2.173, 2.020]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 64, 64]), range: [0.000, 2.020]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 64, 64]), range: [-1.175, 0.724]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 64, 64]), range: [-1.310, 0.723]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 64, 64]), range: [0.000, 0.723]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 12, 64, 64]), range: [-0.259, 0.314]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 12, 64, 64]), range: [-0.225, 0.418]
First fusion output shape: torch.Size([1, 12, 64, 64]), range: [-0.225, 0.418]
Upsampling 1 output shape: torch.Size([1, 6, 128, 128]), range: [-2.121, 1.311]
Fusion 1 input shape: torch.Size([1, 12, 128, 128]), range: [-2.121, 1.321]

ScaleHarmonizer Input shape: torch.Size([1, 12, 128, 128]), range: [-2.121, 1.321]

Condition Input shape: torch.Size([1, 12, 128, 128]), range: [-2.121, 1.321]
Condition conv1 output shape: torch.Size([1, 32, 62, 62]), range: [0.000, 1.097]
Condition conv2 output shape: torch.Size([1, 32, 31, 31]), range: [0.000, 0.386]
Condition conv3 output shape: torch.Size([1, 32, 16, 16]), range: [0.000, 0.173]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.076]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.076]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.189, 0.186]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.175, 0.198]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.197, 0.164]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.218, 0.187]
ScaleHarmonizer Scale3 shape: torch.Size([1, 6]), range: [-0.144, 0.172]
ScaleHarmonizer Shift3 shape: torch.Size([1, 6]), range: [-0.154, 0.062]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 128, 128]), range: [-1.457, 1.103]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 128, 128]), range: [-1.204, 1.376]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 128, 128]), range: [0.000, 1.376]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 128, 128]), range: [-0.557, 0.505]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 128, 128]), range: [-0.577, 0.643]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 128, 128]), range: [0.000, 0.643]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 6, 128, 128]), range: [-0.195, 0.415]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 6, 128, 128]), range: [-0.308, 0.418]
Fusion 1 output shape: torch.Size([1, 6, 128, 128]), range: [-0.308, 0.418]
Upsampling 0 output shape: torch.Size([1, 3, 256, 256]), range: [-0.177, 0.261]
Fusion 0 input shape: torch.Size([1, 6, 256, 256]), range: [-0.182, 1.941]

ScaleHarmonizer Input shape: torch.Size([1, 6, 256, 256]), range: [-0.182, 1.941]

Condition Input shape: torch.Size([1, 6, 256, 256]), range: [-0.182, 1.941]
Condition conv1 output shape: torch.Size([1, 32, 126, 126]), range: [0.000, 0.571]
Condition conv2 output shape: torch.Size([1, 32, 63, 63]), range: [0.000, 0.215]
Condition conv3 output shape: torch.Size([1, 32, 32, 32]), range: [0.000, 0.090]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.065]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.065]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.187, 0.183]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.170, 0.151]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.172, 0.186]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.168, 0.183]
ScaleHarmonizer Scale3 shape: torch.Size([1, 3]), range: [-0.118, 0.065]
ScaleHarmonizer Shift3 shape: torch.Size([1, 3]), range: [0.027, 0.090]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 256, 256]), range: [-1.148, 1.301]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-1.069, 1.143]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 1.143]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 256, 256]), range: [-0.655, 0.527]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-0.575, 0.528]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 0.528]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 3, 256, 256]), range: [-0.115, 0.079]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 3, 256, 256]), range: [-0.044, 0.174]
Fusion 0 output shape: torch.Size([1, 3, 256, 256]), range: [-0.044, 0.174]
Final concatenation shape: torch.Size([1, 9, 256, 256]), range: [torch.Size([1, 9, 256, 256]), range: [-0.044, 1.000]

ScaleHarmonizer Input shape: torch.Size([1, 9, 256, 256]), range: [-0.044, 1.000]

Condition Input shape: torch.Size([1, 9, 256, 256]), range: [-0.044, 1.000]
Condition conv1 output shape: torch.Size([1, 32, 126, 126]), range: [0.000, 0.890]
Condition conv2 output shape: torch.Size([1, 32, 63, 63]), range: [0.000, 0.347]
Condition conv3 output shape: torch.Size([1, 32, 32, 32]), range: [0.000, 0.175]
Condition output shape: torch.Size([1, 32]), range: [0.000, 0.117]
ScaleHarmonizer Condition shape: torch.Size([1, 32]), range: [0.000, 0.117]
ScaleHarmonizer Scale1 shape: torch.Size([1, 64]), range: [-0.211, 0.189]
ScaleHarmonizer Shift1 shape: torch.Size([1, 64]), range: [-0.183, 0.167]
ScaleHarmonizer Scale2 shape: torch.Size([1, 64]), range: [-0.210, 0.196]
ScaleHarmonizer Shift2 shape: torch.Size([1, 64]), range: [-0.183, 0.190]
ScaleHarmonizer Scale3 shape: torch.Size([1, 3]), range: [0.027, 0.199]
ScaleHarmonizer Shift3 shape: torch.Size([1, 3]), range: [0.007, 0.081]
 ScaleHarmonizer Conv1 output shape: torch.Size([1, 64, 256, 256]), range: [-0.984, 1.187]
 ScaleHarmonizer Conv1 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-1.173, 1.243]
 ScaleHarmonizer Conv1 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 1.243]
 ScaleHarmonizer Conv2 output shape: torch.Size([1, 64, 256, 256]), range: [-0.551, 0.557]
 ScaleHarmonizer Conv2 output after calibrator shape: torch.Size([1, 64, 256, 256]), range: [-0.545, 0.762]
 ScaleHarmonizer Conv2 output after activation shape: torch.Size([1, 64, 256, 256]), range: [0.000, 0.762]
 ScaleHarmonizer Conv3 output shape: torch.Size([1, 3, 256, 256]), range: [-0.137, 0.112]
 ScaleHarmonizer Conv3 output after calibrator shape: torch.Size([1, 3, 256, 256]), range: [-0.104, 0.141]
Final output shape: torch.Size([1, 3, 256, 256]), range: [0.474, 0.535]
Model final output shape: torch.Size([1, 3, 256, 256]), range: [0.474, 0.535]
==============================================================================================================
Layer (type:depth-idx)                                       Output Shape              Param #
==============================================================================================================
Model                                                        [1, 3, 256, 256]          --
├─ColorBalancePrior: 1-1                                     [1, 3, 256, 256]          --
│    └─NAFBlock: 2-1                                         [1, 3, 256, 256]          6
│    │    └─LayerNorm2d: 3-1                                 [1, 3, 256, 256]          6
│    │    └─Conv2d: 3-2                                      [1, 6, 256, 256]          24
│    │    └─Conv2d: 3-3                                      [1, 6, 256, 256]          60
│    │    └─SimpleGate: 3-4                                  [1, 3, 256, 256]          --
│    │    └─Sequential: 3-5                                  [1, 3, 1, 1]              12
│    │    └─Conv2d: 3-6                                      [1, 3, 256, 256]          12
│    │    └─Identity: 3-7                                    [1, 3, 256, 256]          --
│    │    └─LayerNorm2d: 3-8                                 [1, 3, 256, 256]          6
│    │    └─Conv2d: 3-9                                      [1, 6, 256, 256]          24
│    │    └─SimpleGate: 3-10                                 [1, 3, 256, 256]          --
│    │    └─Conv2d: 3-11                                     [1, 3, 256, 256]          12
│    │    └─Identity: 3-12                                   [1, 3, 256, 256]          --
├─PriorGuidedRE: 1-2                                         [1, 3, 256, 256]          --
│    └─ModuleList: 2-7                                       --                        (recursive)
│    │    └─DetailRestorer: 3-13                             [1, 3, 256, 256]          147,165
│    └─ModuleList: 2-6                                       --                        (recursive)
│    │    └─Conv2d: 3-14                                     [1, 6, 128, 128]          78
│    └─ModuleList: 2-7                                       --                        (recursive)
│    │    └─DetailRestorer: 3-15                             [1, 6, 128, 128]          149,760
│    └─ModuleList: 2-8                                       --                        (recursive)
│    │    └─Conv2d: 3-16                                     [1, 6, 128, 128]          78
│    └─ModuleList: 2-6                                       --                        (recursive)
│    │    └─Conv2d: 3-17                                     [1, 12, 64, 64]           300
│    └─ModuleList: 2-7                                       --                        (recursive)
│    │    └─DetailRestorer: 3-18                             [1, 12, 64, 64]           154,950
│    └─ModuleList: 2-8                                       --                        (recursive)
│    │    └─Conv2d: 3-19                                     [1, 12, 64, 64]           300
│    └─FeatureContextualizer: 2-9                            [1, 24, 64, 64]           --
│    │    └─OverlapPatchEmbed: 3-20                          [1, 48, 64, 64]           5,184
│    │    └─OverlapPatchEmbed: 3-21                          [1, 48, 64, 64]           5,184
│    │    └─MAQ: 3-22                                        [1, 48, 64, 64]           231,539
│    │    └─MAQ: 3-23                                        [1, 48, 64, 64]           231,539
│    │    └─Aggreation: 3-24                                 [1, 48, 64, 64]           43,933
│    │    └─MAQ: 3-25                                        [1, 48, 64, 64]           231,539
│    │    └─MAQ: 3-26                                        [1, 48, 64, 64]           231,539
│    │    └─Aggreation: 3-27                                 [1, 48, 64, 64]           67,603
│    │    └─SPP: 3-28                                        [1, 24, 64, 64]           61,277
│    └─ModuleList: 2-14                                      --                        (recursive)
│    │    └─ScaleHarmonizer: 3-29                            [1, 12, 64, 64]           71,940
│    └─ModuleList: 2-13                                      --                        (recursive)
│    │    └─Sequential: 3-30                                 [1, 6, 128, 128]          288
│    └─ModuleList: 2-14                                      --                        (recursive)
│    │    └─ScaleHarmonizer: 3-31                            [1, 6, 128, 128]          51,570
│    └─ModuleList: 2-13                                      --                        (recursive)
│    │    └─Sequential: 3-32                                 [1, 3, 256, 256]          72
│    └─ModuleList: 2-14                                      --                        (recursive)
│    │    └─ScaleHarmonizer: 3-33                            [1, 3, 256, 256]          41,385
│    └─ScaleHarmonizer: 2-15                                 [1, 3, 256, 256]          --
│    │    └─Condition: 3-34                                  [1, 32]                   32,640
│    │    └─Linear: 3-35                                     [1, 64]                   2,112
│    │    └─Linear: 3-36                                     [1, 64]                   2,112
│    │    └─Linear: 3-37                                     [1, 64]                   2,112
│    │    └─Linear: 3-38                                     [1, 64]                   2,112
│    │    └─Linear: 3-39                                     [1, 3]                    99
│    │    └─Linear: 3-40                                     [1, 3]                    99
│    │    └─Conv2d: 3-41                                     [1, 64, 256, 256]         640
│    │    └─ReLU: 3-42                                       [1, 64, 256, 256]         --
│    │    └─Conv2d: 3-43                                     [1, 64, 256, 256]         4,160
│    │    └─ReLU: 3-44                                       [1, 64, 256, 256]         --
│    │    └─Conv2d: 3-45                                     [1, 3, 256, 256]          195
│    └─Sigmoid: 2-16                                         [1, 3, 256, 256]          --
==============================================================================================================
Total params: 1,815,138
Trainable params: 1,690,722
Non-trainable params: 124,416
Total mult-adds (G): 10.25
==============================================================================================================
Input size (MB): 0.79
Forward/backward pass size (MB): 1995.48
Params size (MB): 7.09
Estimated Total Size (MB): 2003.36
==============================================================================================================
[PASS] test_model_summary completed successfully.

All tests completed!


Closing log file...
odel_summary completed successfully.

All tests completed!


Closing log file...
odel_summary completed successfully.

All tests completed!


Closing log file...
