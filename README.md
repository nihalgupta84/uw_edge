## **ğŸš€ Underwater Image Enhancement**
A **PyTorch implementation** for **underwater image enhancement** using a **transformer-based architecture**.

---

## ğŸ“Œ **Table of Contents**
- [ğŸ“¥ Setup](#-setup)
- [ğŸ“‚ Dataset Preparation](#-dataset-preparation)
- [ğŸ› ï¸ Training](#ï¸-training)
- [ğŸ§ª Testing](#-testing)
- [âš™ï¸ Configuration](#ï¸-configuration)
- [ğŸ’¾ Checkpoints](#-checkpoints)
- [ğŸ“œ License](#-license)
- [ğŸ“– Citation](#-citation)
- [ğŸ™ Acknowledgments](#-acknowledgments)

---

## **ğŸ“¥ Setup**

### **1ï¸âƒ£ Clone this repository**
```bash
git clone <repository-url>
cd underwater-enhancement
```

### **2ï¸âƒ£ Install dependencies**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set up Weights & Biases (Optional)**
Create a file named **`WANDB_API_KEY.env`** in the root directory and paste your Weights & Biases API key:
```plaintext
WANDB_API_KEY=your_api_key_here
```

---

## **ğŸ“‚ Dataset Preparation**
### **ğŸ“Œ Download Paired Datasets**
The following paired datasets are available (processed and split into a **90/10** training-validation ratio):
- **EVUP**
- **LSUI**
- **UIEB**

**ğŸ”— Download:** [Google Drive Link](https://drive.google.com/drive/folders/1Qn9jf2gtsuLtHZASm-Hms7-HVL1m2OJp?usp=sharing)

### **ğŸ“Œ Dataset Structure**
We provide **two types** of dataset organizations:
1. **Paired Data** (UIEB, EVUP, LSUI) â†’ Contains **raw** images & **reference** images  
2. **Unpaired Data** (UIEB, EVUP, RUIE) â†’ Only **raw** images  

**Example structure for paired datasets:**
```
datasets/
â””â”€â”€ UIEB/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ raw/      # Raw underwater images
    â”‚   â””â”€â”€ ref/      # Corresponding reference images
    â””â”€â”€ val/
        â”œâ”€â”€ raw/
        â””â”€â”€ ref/
```

---

## **ğŸ› ï¸ Training**
### **ğŸš€ Start Training**
```bash
python train.py --config_yaml=config.yml
```

### **ğŸ”„ Resume Training**
```bash
python train.py --config_yaml=config.yml TRAINING.RESUME True
```

### **âš™ï¸ Override Configuration Parameters**
You can override **any configuration parameter** via the command line:
```bash
python train.py --config_yaml=config.yml MODEL.NAME edge_v1 OPTIM.BATCH_SIZE 8
```

---

## **ğŸ§ª Testing**
### **ğŸ“· Run Testing with Reference Images**
```bash
python test.py --config_yaml config.yml MODEL.NAME edge_v1 MODEL.DATASET_NAME "paired or unpai MODEL.SESSION trained_on_uieb TESTING.WEIGHT "checkpoint path" TESTING.VAL_DIR "testing data path"
```
### **ğŸ“· Run Testing with No Reference Images**

```bash
python test.py --config_yaml config.yml MODEL.NAME edge_v1 MODEL.DATASET_NAME "paired or unpai MODEL.SESSION trained_on_uieb TESTING.WEIGHT "checkpoint path" TESTING.VAL_DIR "testing data path"  TESTING.INPUT "" TESTING.TARGET ""
```
---

## **âš™ï¸ Configuration**
### **ğŸ”¹ Configuration Files**
The **`MODEL.SESSION`** parameter in config files defines the project name for **logging and organization**.

| **Config File** | **Description** |
|---------------|----------------|
| `config.yml` | Default configuration |
| `evup.yml` | EVUP dataset-specific settings |
| `guide.yml` | Guide model settings |

---

## **ğŸ’¾ Checkpoints**
During training, **checkpoints** are saved in the directory specified by `TRAINING.SAVE_DIR` in `config.yml`.

| **Checkpoint File** | **Purpose** |
|----------------|-----------------------------------|
| `best_psnr.pth` | Model with highest PSNR metric |
| `best_ssim.pth` | Model with highest SSIM metric |
| `best_loss.pth` | Model with lowest training loss |
| `last_checkpoint.pth` | Last saved model (for resuming training) |

---

## **ğŸ“œ License**
[Specify License Here]

---

## **ğŸ“– Citation**
If you use this repository in your research, please cite:
```bibtex
@article{YourPaper202X,
  author  = {Your Name},
  title   = {Underwater Image Enhancement using Transformers},
  journal = {Journal Name},
  year    = {202X},
  doi     = {XX.XXXX/XXXXX}
}
```

---

## **ğŸ™ Acknowledgments**
We would like to thank:
- **[Contributor 1]** for [specific contribution]
- **[Contributor 2]** for [specific contribution]
- The **research community** for open datasets & resources
